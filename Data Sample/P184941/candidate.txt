layout randomization is a powerful, popular technique for software protection. we present it and study it in programming language terms. more specifically, we consider layout randomization as part of an implementation for a high level programming language; the implementation translates this language to a lower level language in which memory addresses are numbers. we analyze this implementation, by relating low level attacks against the implementation to contexts in the high level programming language, and by establishing full abstraction results. several techniques for protection are based on randomization. the randomization may concern the layout of data and code within an address space, data representations, or the underlying instruction set. in all cases, the randomization introduces arti cial diversity that can serve for impeding attacks. in particular, layout randomization can thwart attacks that rely on knowledge of the location of particular data and functions. in addition, randomization can obfuscate program logic, against reverse engineering. for example, methods that ensure the integrity of control ow and data ow, statically or dynamically, can also regulate the use of system libraries. the static methods may be based on a preliminary version of this work was presented at the rd ieee computer security foundations symposium. authoraddress: plotkin, microsoft research silicon valley, year# pear avenue, mountain view, ca; email: gdp inf ed ac uk. permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies show this notice on the rst page or initial screen of a display along with the full citation. copyrights for components of this work owned by others than acm must be honored. to copy otherwise, to republish, to post on servers, to redistribute to lists, or to use any component of this work in other works requires prior speci. permissions may be requested from the publications dept, acm, inc, penn plaza, suite, new york, ny year#, usa, fax, or permissions acm org. year# acm year# year# art doi year# http: doi acm org year#. the dynamic methods often rely on reference monitors, whether implemented in hardware or software, at the boundaries of address spaces or inline. in addition to the diversity of their mechanisms, protection techniques vary in their goals and the underlying attack models. some aim to offer precise, general guarantees, while others stop only some speci. attack that can be easily modi ed to overcome the protection. they also vary in the dif culty of deploying them and in their costs. in this article we focus on layout randomization because it is in widespread use, it has been subject to practical attacks, and it has hardly been studied rigorously. we present layout randomization as part of an implementation for a high level programming language. the language that we consider includes higher order functions and mutable variables that hold natural numbers, which we call locations. some of the locations are designated as public while others are designated as private, with the intent that an attacker should not have direct access to the latter. for instance, consider a program that manipulates data that should remain secret or be protected from tampering, such as a value that indicates the authentication status of a communication channel. the program may store this data in a private location; it may publish a function that internally uses the private location, and this function may be invoked by untrusted pieces of code. the implementation translates the high level language to a lower level language in which memory addresses are natural numbers; layout randomization consists in mapping the private locations to random addresses in data memory. if the data memory is large enough and the randomization good enough, then even an attacker with access to all of data memory cannot nd the private locations ef ciently with high probability. we derive that the security properties that hold against attackers that cannot access the private locations directly continue to hold in this implementation, in a probabilistic sense and against resource bounded adversaries. thus, our work takes place in a programming language setting, and it draws on a line of research on protection in programming languages, and more broadly on ideas and techniques from programming language theory. these include the use of contexts for representing attackers, and of contextual equivalence and similar relations for expressing security properties. remarkably, though, this line of research has said little on randomization; a notable exception is the work of pucella and schneider, which we describe further in section #. in addition, our probabilistic results are analogous to computational soundness theorems in the analysis of security protocols. these theorems relate symbolic proofs of protocol security, in which keys and ciphertexts are formal expressions, to proofs in a computational model in which keys and ciphertexts are bitstrings subject to complexity theoretic assumptions. unlike security protocols, however, the systems that we consider neither include concurrency nor rely on cryptography, but they do include higher order functions. despite these important differences, we hope that our work will enrich the study of computational soundness, in particular by showing that some of its themes and methods are applicable beyond security protocols. the next section discusses our results in more detail but still informally. sections and are the core of this article; they treat models in which errors are fatal and recoverable, respectively. an electronic appendix contains proofs and additional technical material; it can be accessed in the acm digital library. a full formal machine checked verification of aprogram: the openssl implementation of sha. this is an interactive proof of functional correctness in the coq proof assistant, using the verifiableprogram logic. verifiableis a separation logic for thelanguage, proved sound. the operational semantics for, connected to the compcert verified optimizingcompiler. injecting binary code into a running program is a common form of attack. most defenses employ a guard the doors approach, blocking known mechanisms of code injection. randomized instruction set emulation is a complementary method of defense, one that performs a hidden randomization of an application machine code. if foreign binary code is injected into a program running under rise, it will not be executable because it will not know the proper randomization. the paper describes and analyzes rise, describing a proof of concept implementation built on the open source valgrind ia to ia translator. the prototype effectively disrupts binary code injection attacks, without requiring recompilation, linking, or access to application source code. empirical studies and a theoretical model are reported which treat the effects of executing random code on two different architectures. the paper discusses possible extensions and applications of the rise technique in other contexts. under rise, injected code essentially executes random code sequences. standardized machine instruction sets provide consistent interfaces between software and hardware, but they are a double edged sword. although they yield great productivity gains by enabling independent development of hardware and software, the ubiquity of well known instructions sets also allows a single attack designed around an exploitable software aw to gain control of thousands or millions of systems. such attacks could be stopped or greatly hindered if each protected system could be economically destandardized, so that a different attack would have to be created speci cally for each new target, using information that was dif cult or impossible for an outsider to obtain. the automatic diversi cation we explore in this paper is one such destandardization technique. many existing defenses against machine code injection attacks block the known routes by which foreign code is placed into a programexecution path. for example, stack defense mechanisms protect return addresses and defeat large classes of buffer over ow attacks. other mechanisms defend against buffer over ows elsewhere in program address space, against alternative overwriting methods, or guard from known vulnerabilities through shared interfaces. our approach is functionally similar to the pageexec feature of pax, an issue we discuss in section #. rather than focusing on any particular code injection pathway, a complementary approach would disrupt the operation of the injected code itself. with such instruction set diversi cation, each protected program has a different and secret instruction set, so that even if a foreign attack code manages to enter the execution stream, with very high probability the injected code will fail to execute properly. in general, if there are many possible instruction sets compared to the number of protected systems and the chosen instruction set in each case is externally unobservable, different attacks must be crafted for each protected system and the cost of developing attacks is greatly increased. in rise, each byte of protected program code is scrambled using pseudorandom numbers seeded with a random key that is unique to each program execution. using the scrambling constants it is trivial to recover normal instructions executable on the physical machine, but without the key it is infeasible to produce even a short code sequence that implements any given behavior. foreign binary code that manages to reach the emulated execution path will be descrambled without ever having been correctly scrambled, foiling the attack, and producing pseudorandom code that will usually crash the protected program. threat model the set of attacks that rise can handle is slightly different from that of many defense mechanisms, so it is important to identify the rise threat model clearly. this includes many real world attack mechanisms, but explicitly excludes several others, including the category of attacks loosely grouped under the name return into libc which modify data and addresses so that code already existing in the program is subverted to execute the attack. these attacks might or might not use code injection as part of the attack. most defenses against code injection perform poorly against this category as it operates at a different level of abstraction; complementary defense techniques are needed, and have been proposed, such as address obfuscation, which hide and or randomize existing code locations or interface access points. the restriction to code injection attacks excludes data only attacks such as nonhybrid versions of the return into libc class mentioned above, while focusing on binary code excludes attacks such as macro viruses that inject code written in a higher level language. finally, we consider only attacks that arrive via network communications and therefore we treat the contents of local disks as trustworthy before an attack has occurred. in exchange for these limitations, rise protects against all binary code injection attacks, regardless of the method by which the machine code is injected. by defending the code itself, rather than any particular access route into the code, rise offers the potential of blocking attacks based on injection mechanisms that have yet to be discovered or revealed. this threat model is related to, but distinct from, other models used to characterize buffer over ow attacks. it includes any attack in which native code is injected into a running binary, even by means that are not obviously buffer over ows, such as misallocated malloc headers, footer tags, and format string attacks that write a byte to arbitrary memory locations. rise protects against injected code arriving by any of these methods. on the other hand, other defense mechanisms, such as the address obfuscation mentioned above, can prevent attacks that are speci cally excluded from our code injection threat model. we envision the relatively general code based mechanism of rise being used in conjunction with data and address diversi cation based mechanisms to provide deeper, more principled, and more robust defenses against both known and unknown attacks. overview this paper describes a proof of concept rise system, which builds randomized instruction set support into a version of the valgrind ia to ia binary translator. the rise design makes few demands on the supporting emulator and could be easily ported to any binary to binary translator for which source code is available. section # reports empirical tests of the prototype and con rms that rise successfully disrupts a range of actual code injection attacks against otherwise vulnerable applications. in addition, it highlights the extreme fragility of typical attacks and comments on performance issues. a basic property of the rise defense mechanism is that if an attack manages to inject code by any means, essentially random machine instructions will be executed. section # investigates the likely effects of such an execution in several different execution contexts. experimental results are reported and theoretical analyses are given for two different architectures. we present empirical data suggesting that the majority of random code sequences will produce an address fault or illegal instruction quickly, causing the program to abort. most of the remaining cases throw the program into a loop, effectively stopping the attack. either way, an attempted takeover is downgraded into a denial of service attack against the exploitable program. unlike compiled binary code, which uses only a well de ned and often relatively small selection of instructions, random code is unconstrained. the behavior of random code execution in the ia architecture can involve the effects of undocumented instructions and whatever instruction set extensions are present, as well as the effects of random branch offsets combined with multibyte, variable length instructions. although those characteristics complicate a tight theoretical analysis of random bit executions on the ia, models for more constrained instruction set architectures, such as the powerpc, lead to a closer. section # summarizes related work, section # discusses some of the implications and potential vulnerabilities of the rise approach, and section # concludes the paper. in this paper we describe randomized instruction set emulation, which uses a machine emulator to produce automatically diversi ed instruction sets. threat model is binary code injection from the network into an executing program. section # describes a randomizing loader for valgrind that scrambles code sequences loaded into emulator memory from the local disk using a hidden random key. then, during valgrindemulated instruction fetch cycle, fetched instructions are unscrambled, yielding the unaltered ia machine code sequences of the protected application. there is always a possibility that random bits could create valid instructions and instruction sequences. finding and fixing bugs in deployed software is difficult and time consuming. applications written in unsafe languages likeandare vulnerable to memory errors such as buffer overflows, dangling pointers, and reads of uninitialized data. such errors can lead to program crashes, security vulnerabilities, and unpredictable behavior. we present diehard, a runtime system that tolerates these errors while probabilistically maintaining soundness. diehard uses randomization and replication to achieve probabilistic memory safety by approximating an infinite sized heap. diehard memory manager randomizes the location of objects in a heap that is at least twice as large as required. this algorithm prevents heap corruption and provides a probabilistic guarantee of avoiding memory errors. for additional safety, diehard can operate in a replicated mode where multiple replicas of the same application are run simultaneously. by initializing each replica with a different random seed and requiring agreement on output, the replicated version of die hard increases the likelihood of correct execution because errors are unlikely to have the same effect across all replicas. we present analytical and experimental results that show diehard resilience to a wide range of memory errors, including a heap based buffer overflow in an actual application. return oriented programming is an effective code reuse attack in which short code sequences ending in a ret instruction are found within existing binaries and executed in arbitrary order by taking control of the stack. this allows for turing complete behavior in the target program without the need for injecting attack code, thus significantly negating current code injection defense efforts. on the other hand, its inherent characteristics, such as the reliance on the stack and the consecutive execution of return oriented gadgets, have prompted a variety of defenses to detect or prevent it from happening. in this paper, we introduce a new class of code reuse attack, called jump oriented programming. this attack still builds and chains functional gadgets, each performing certain primitive operations, except these gadgets end in an indirect branch rather than ret. without the convenience of using ret to unify them, the attack relies on a dispatcher gadget to dispatch and execute the functional gadgets. we have successfully identified the availability of these jump oriented gadgets in the gnu libc library. our experience with an example shellcode attack demonstrates the practicality and effectiveness of this technique. this new attack eliminates the reliance on the stack and ret instructions seen in return oriented programming without sacrificing expressive power. network servers are under constant threat by attackers who use maliciously crafted packets to exploit software bugs and gain unauthorized control. in spite of signi cant research addressing the underlying causes of software vulnerabilities, such attacks remain one of the largest problems in the security eld. an arms race has developed between increasingly sophisticated attacks and their corresponding defenses. one of the earliest forms of software exploit is the code injection attack, wherein the malicious message includes machine code, and a bu er over ow or other technique is used permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies bear this notice and the full citation on the rst page to copyotherwise, to republish, to post on servers or to redistribute to lists, requires prior speci. to redirect control ow to the attacker supplied code. however, with the advent of cpus and operating systems that support the. guarantee, this threat has been mitigated in many contexts. in particular, enforces the property that a given memory page will never be both writable and executable at the same time. the basic premise behind it is that if a page cannot be written to and later executed from, code injection becomes impossible. unfortunately, attackers have developed innovative ways to defeat. for example, one possible way is to launch a code reuse attack, wherein existing code is re purposed to a malicious end. the simplest and most common form of this is the return into libc technique. in this scenario, the adversary uses a bu er over ow to overwrite part of the stack with return addresses and parameters for a list of functions within libc. this allows the attacker to execute an arbitrary sequence of libc functions, with a common example being a call to system to launch a shell. while return into libc is powerful, it does not allow arbitrary computation within the context of the exploited application. for this, the attacker may turn to return oriented programming. as before, rop overwrites the stack with return addresses and arguments. however, the addresses supplied now point to arbitrary points within the existing code base, with the only requirement being that these snippets of code, or gadgets, end in a ret instruction to transfer the control to the next gadget. return oriented programming has been shown to be turing complete on a variety of platforms and codebases, and automated techniques have made development of such attacks a straightforward process. the real world danger of this technique was shown when checkoway et al used it to violate the integrity of a commonly deployed electronic voting machine. since the advent of return oriented programming, a number of defenses have been proposed to either detect or prevent rop based attacks. memory space, and considers this as a ropinherent feature to be useful for its detection. the returnless approach goes a step further by eliminating all ret instructions in a program, thereby removing the existence of return oriented gadgets and precluding the possibility of a rop based attack. figure #: simpli ed layout of an stack frame. in this paper, we present an alternative attack paradigm called jump oriented programming. in a jop based attack, the attacker abandons all reliance on the stack for control ow and ret for gadget discovery and chaining, instead using nothing more than a sequence of indirect jump instructions. because almost all known techniques to defend against rop depend on its reliance on the stack or ret, none of them are capable of detecting or defending against this new approach. the one exception are systems that enforce full control ow integrity; unfortunately, such systems are not widely deployed, likely due to concerns over their complexity and negative performance impact. similar to rop, the building blocks of jop are still short code sequences called gadgets. others are not intended but present due to the density of instructions and the feasibility of unaligned execution. however, unlike rop, where a ret gadget can naturally return back the control based on the content of the stack, a jmp gadget is performing an uni directional control ow transfer to its target, making it di cult to regain control back to chain the execution of the next jump oriented gadget. we note that a code reuse attack based on indirect jmps was put forth as a theoretical possibility as early as year#. however, there always remained an open problem of how the attacker would maintain control of the programexecution. with no common control mechanism like ret to unify them, it was not clear how to chain gadgets together with uni directional jmps. such a gadget is intended to govern control ow among various jump oriented gadgets. more speci cally, if we consider other gadgets as functional gadgets that perform primitive operations, this dispatcher gadget is speci cally selected to determine which functional gadget is going to be invoked next. naturally, the dispatcher gadget can maintain an internal dispatch table that explicitly speci es the control ow of the functional gadgets. also, it ensures that the ending jmp instruction in the functional gadget will always transfer the control back to the dispatcher gadget. in order to achieve the same turing complete expressive power of rop, we also aim to identify various jump oriented gadgets for memory load store, arithmetic calculations, binary operations, conditional branching, and system calls. to do that, we propose an algorithm to discover and collect jump oriented gadgets, organize them into di erent categories, and save them in a central gadget catalog. independent of our work, a concurrent approach by checkoway et al proposes to replace ret in rop with a pop jmp. however, the based approach still relies on the stack to govern control ow among gadgets and the pop jmp sequence is rare as detailed in section #. in summary, this paper makes the following contributions: we expand the taxonomy of code reuse attacks on the to include a new class of attack: jump oriented programming. in not relying on the stack for control ow. instead, we introduce the notion of a dispatcher gadget to take the role of executing functional gadgets. our solution to this problem is the proposition of a new class of gadget, the dispatcher gadget. for example, dynima detects the consecutive execution of small instruction sequences each ending with a ret and suspects them as gadgets in a rop attack. drop observes that a rop execution continuously pops return addresses that always point to the same speci. however, instead of ending with a ret, each such gadget ends with an indirect jmp. some of these jmp instructions are intentionally emitted by the compiler. by doing so, jump oriented computation becomes feasible. when compared to existing return oriented programming, our attack has the bene. amnesia is a tool that detects and prevents sql injection attacks by combining static analysis and runtime monitoring. empirical evaluation has shown that amnesia is both effective and efficient against sql injection. companies and organizations use web applications to provide a broad range of services to users, such as on line banking and shopping. because the databases underlying web applications often contain con dential information, these applications are a frequent target for attacks. one particular type of attack, sql injection, can give attackers a way to gain access to the databases underlying web applications and, with that, the power to leak, modify, or even delete information that is stored on these databases. in recent years, both commercial and government institutions have been victims of sqlias. sql injection vulnerabilities are due to insu cient input validation. more precisely, sql injection attack can occur when a web application receives user input and uses it to build a database query without adequately validating it. an attacker can take advantage of a vulnerable application by providing it with input that contains embedded malicious sql commands that are then executed by the database. although the vulnerabilities that lead to sqlias are well understood, they continue to be a significant problem because of a lack of. conceptually, sqlias could be prevented by a more rigorous application of defensive coding techniques. in practice, however, these techniques have been less than. ective in addressing the problem because they are susceptible to human errors and expensive to apply on large legacy code bases. in our demonstration, we present amnesia, a tool that implements our technique for detecting and preventing sqlias. amnesia uses a model based approach that is speci cally designed to target sqlias and combines static analysis and runtime monitoring. it uses static analysis to analyze the web application code and au copyright is held by the author owner. tomatically build a model of the legitimate queries that the application can generate. at runtime, the technique monitors all dynamically generated queries and checks them for compliance with the statically generated model. when the technique detects a query that violates the model, it classi esthe queryasanattack, preventsitfromaccessing the database, and logs the attack information. this paper presents exe, an effective bug finding tool that automatically generates inputs that crash real code. instead of running code on manually or randomly constructed input, exe runs it on symbolic input initially allowed to be anything. as checked code runs, exe tracks the constraints on each symbolic memory location. if a statement uses a symbolic value, exe does not run it, but instead adds it as an input constraint; all other statements run as usual. if code conditionally checks a symbolic expression, exe forks execution, constraining the expression to be true on the true branch and false on the other. because exe reasons about all possible values on a path, it has much more power than a traditional runtime tool: it can force execution down any feasible program path and at dangerous operations, it detects if the current path constraints allow any value that causes a bug when a path terminates or hits a bug, exe automatically generates a test case by solving the current path constraints to find concrete values using its own co designed constraint solver, stp. because exe constraints have no approximations, feeding this concrete input to an uninstrumented version of the checked code will cause it to follow the same path and hit the same bug. exe works well on real code, finding bugs along with inputs that trigger them in: the bsd and linux packet filter implementations, the udhcpd dhcp server, the pcre regular expression library, and three linux file systems. attacker exposed code is often a tangled mess of deeplynested conditionals, labyrinthine call chains, huge amounts of code, and frequent, abusive use of casting and pointer operations. for safety, this code must exhaustively vet input received directly from potential attackers. however, attempting to guard against all possible attacks adds signi cant code complexity and requires awareness of subtle issues such as arithmetic and bu er over ow conditions, which the historical record unequivocally shows programmers reason about poorly. currently, programmers check for such errors using a combination of code review, manual and random testing, dynamic tools, and static analysis. while helpful, these techniques have signi cant weaknesses. the code features described above make manual inspection even more challenging than usual. the number of possibilities makes manual testing far from exhaustive, and even less so when compounded by programmerlimited ability to reason about all these possibilities. while random fuzz testing often nds interesting corner case errors, even a single equality conditional can derail it: satisfying a bit equality in a branch condition requires correctly guessing one value out of four billion possibilities. correctly getting a sequence of such conditions is hopeless. dynamic tools require test cases to drive them, and thus have the same coverage problems as both random and manual testing. finally, while static analysis bene ts from full path coverage, the fact that it inspects rather than executes code means that it reasons poorly about bugs that depend on accurate value information, pointers, and heap layout, among many others. ective bug nding tool built to deeply check real code. the main insight behind exe is that code can automatical ly generate its own test cases. instead of running code on manually or randomly constructed input, exe runs it on symbolic input that is initially allowed to be anything. as checked code runs, if it tries to operate on symbolic expressions, exe replaces the operation with its corresponding input constraint; it runs all other operations as usual. when code conditionally checks a symbolic expression, exe forks execution, constraining the expression to be true on the true branch and false on the other. when a path terminates or hits a bug, exe automatically generates a test case that will run this path by solving the pathconstraints for concrete values using its co designed constraint solver, stp. ect of running a single code path since the use of stp lets it reason about alpossible values that the path could be run with, rather than a single set of concrete values from an individual test case. for instance, a dynamic memory checker such as purify only catches an out of bounds array access if the index has a speci. in contrast, exe identi es this bug if there is any possible input value on the given path that can cause an out of bounds access to the array. similarly, for an arithmetic expression that uses symbolic data, exe can solve the associated constraints for values that cause an over ow or a division modulo by zero. moreover, for an assert statement, exe can reason about all possible input values on the given path that may cause the assert to fail. if the assert does not fail, then either no input on this path can cause it to fail, exe does not have the full set of constraints, or there is a bug in exe. the ability to automatically generate input to execute paths has several nice features. first, exe can test any code path it wishes, thereby getting coverage out of practical reach from random or manual testing. this ability lets it show that external forces can exploit a bug, improving on static analysis, which often cannot distinguish minor errors from showstoppers. third, the exe user sees no false positives: re running input on an uninstrumented copy of the checked code either veri es that it hits a bug or automatically discards it if not. careful co design of exe and stp has resulted in a system with several novel features. first, stp primitives let exe build constraints for allexpressions with perfect accuracy, down to a single bit. exe handles pointers, unions, bit elds, casts, and aggressive bit operations such as shifting, masking, and byte swapping. because exe is dynamic it has access to all the information that a dynamic analysis has, and a static analysis typically does not. all non symbolic operations happen exactly as they would in uninstrumented code, and produce exactly the same values: when these values appear in constraints they are correct, not approximations. in our context, what this accuracy means is that if exe has the full set of constraints for a given path, stp can produce a concrete solution from those constraints, and the path is deterministic, then rerunning the checked system on these concrete values will force the program to follow the same exact path to the error or termination that generated this set of constraints. in addition, stp provides the speed needed to make perfect accuracy useful. aggressive customization makes stp often times faster than more traditional constraint solvers while handling a broader class of examples. ciently reasons about constraints that refer to memory using symbolic pointer expressions, which presents more challenges than one may expect. for example, given a concrete pointer a and a symbolic variablewith the constraint, then the conditional expression if is essentially equivalent to a big disjunction: if. similarly, an assignment a represents a potential assignment to any element in the array between and. the result of these features is that exe nds bugs in real code, and automatically generates concrete inputs to trigger them. it generates evil packet lters that exploit bu er overruns in the very mature and audited berkeley packet filter code as well as its linux equivalent. it generates packets that cause invalid memory reads and writes in the udhcpd dhcp server, and bad regular expressions that compromise the pcre library, previously audited for security holes. in prior work, it generated raw disk images that, when mounted by a linux kernel, would crash it or cause a bu er over ow. both exe and stp are contributions of this paper, which is organized as follows. we rst give an overview of the entire system, then describe stp and its key optimizations, and do the same for exe. finally, we present results, discuss related work, and conclude. together, these three techniques constitute directed automated random testing, or dart for short. the main strength of dart is thus that testing can be performed completely automatically on any program that compiles there is no need to write any test driver or harness code. during testing, dart detects standard errors such as program crashes, assertion violations, and non termination. preliminary experiments to unit test several examples ofprograms are very encouraging. today, testing is the primary way to check the correctness of software. since writing all this testing code manually is expensive, unit testing is often either performed very poorly or skipped altogether. dynamic analysis of how the program behaves under random testing and automatic generation of new test inputs to direct systematically the execution along alternative program paths. these experimental results are discussed in detail in section #. however, we are not aware of any tool like dart which combines automatic interface extraction with random testing and dynamic test generation. has only one chance to be exercised out of ifis a bit integer program input that is randomly initialized. earlier program static checkers like lint usually generate an overly large number of warnings and false alarms, and are therefore rarely used by programmers on a regular basis. despite signi cant recent progress on techniques to separate false alarms from real errors, analyzing the results of static analysis to determine whether a warning actually corresponds to an error still involves signi cant human intervention. billions of dollars are spent on testing in the software industry, as testing usually accounts for about of the cost of software development. it was recently estimated that software failures currently cost the us economy alone about billion every year, and that improvements in software testing infrastructure might save one third of this cost. among the various kinds of testing usually performed during the software development cycle, unit testing applies to the individual components of a software system. in principle, unit testing plays an important role in ensuring overall software quality since its role is precisely to detect errors in the componentlogic, check all corner cases, and provide code coverage. yet, in practice, permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. to copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speci. unit testing is so hard and expensive to perform that it is rarely done properly. indeed, in order to be able to execute and test a component in isolation, one needs to write test driver harness code to simulate the environment of the component. more code is needed to test functional correctness, for instance using assertions checking the componentoutputs. moreover, subsequent phases of testing, such as feature, integration and system testing, are meant to test the overall correctness of the entire system viewed as a black box, not to check the corner cases where bugs causing reliability issues are typically hidden. as a consequence, many software bugs that should have been caught during unit testing remain undetected until eld deployment. in this paper, we propose a new approach that addresses the main limitation hampering unit testing, namely the need to write test driver and harness code to simulate the external environment of a software application. we describe our tool dart, which combines three main techniques in order to automate unit testing of software: automated extraction of the interface of a program with its external environment using static source code parsing; automatic generation of a test driver for this interface that performs random testing to simulate the most general environment the program can operate in; and. together, these three techniques constitute directed automated random testing, or dart for short. thus, the main strength of dart is that testing can be performed completely automatically on any program that compiles there is no need to write any test driver or harness code. during testing, dart detects standard errors such as program crashes, assertion violations, and non termination. we have implemented dart for programs written in theprogramming language. preliminary experiments to unit test several examples ofprograms are very encouraging. for instance, dart was able to nd automatically attacks in variousimplementations of a well known awed security protocol. also, dart found hundreds of ways to crash of the about externally visible functions provided in the osip library, an opensource implementation of the sip protocol. the idea of extracting automatically interfaces of software components via static analysis has been discussed before, for modelchecking purposes, reverse engineering, and compositional veri cation. dart is complementary to test management tools that take advantage of interface de nitions as part of programming languages, such as junit for java, but do not perform automatic test generation. random testing is a simple and well known technique, which can be remarkably effective at nding software bugs. yet, it is also well known that random testing usually provides low code coverage. for instance, the then branch of the conditional statement if then. the contributions of dart compared to random testing are twofold: dart makes random testing automatic by combining it with automatic interface extraction, and also makes it much more effective in nding errors thanks to the use of dynamic test generation to drive the program along alternative conditional branches. besides testing, the other main way to check correctness during the software development cycle is code inspection. over the last few years, there has been a renewed interest in static source code analysis for building automatic code inspection tools that are more practical and usable by the average software developer. the main challenge faced by the new generation of static analyzers is thus to do a better job in dealing with false alarms, which arise from the inherent imprecision of static analysis. there are essentially two main approaches to this problem: either report only high con dence warnings, or report all of them. we believe dart provides an attractive alternative approach to static analyzers, because it is based on high precision dynamic analysis instead, while being fully automated as static analysis. the main advantage of dart over static analysis is that every execution leading to an error that is found by dart is guaranteed to be sound. two areas where we expect dart to compete especially well against static analyzers are the detection of interprocedural bugs and of bugs that arise through the use of library functions, as will be discussed later in the paper. of course, dart is overall complementary to static analysis since it has its own limitations, namely the computational expense of running tests and the sometimes limited effectiveness of dynamic test generation to improve over random testing. in any case, dart offers a new trade off among existing static and dynamic analysis techniques. section # discusses implementation issues when dealing with programs written in theprogramming language. we compare dart with other related work in section # and conclude with section #. or commercial advantage and that copies bear this notice and the full citation on the rst page. for instance, the probability of taking the then branch of the statement if then. the novel dynamic test generation techniques used in dart are presented in section #. in this paper an attempt is made to explore the logical foundations of computer programming by use of techniques which were first applied in the study of geometry and have later been extended to other branches of mathematics. this involves the elucidation of sets of axioms and rules of inference which can be used in proofs of the properties of computer programs. examples are given of such axioms and rules, and a formal proof of a simple theorem is displayed. finally, it is argued that important advantage, both theoretical and practical, may follow from a pursuance of these topics. computer programming is an exact science in that all the properties of a program and all the consequences of executing it in any given environment can, in principle, be found out from the text of the program itself by means of purely deductive reasoning. deductive reasoning in volves the application of valid rules of inference to sets of valid axioms. it is therefore desirable and interesting to elucidate the axioms and rules of inference which underlie our reasoning about computer programs. the exact choice of axioms will to some extent depend on the choice of programming language. for illustrative purposes, this paper is confined to a very simple language, which is effec tively a subset of all eurrent procedure oriented languages. we describe a new, general approach for safeguarding systems against any type of code injection attack. we apply kerckhoff principle, by creating process specific randomized instruction sets of the system executing potentially vulnerable software. an attacker who does not know the key to the randomization algorithm will inject code that is invalid for that randomized processor, causing a runtime exception. to determine the difficulty of integrating support for the proposed mechanism in the operating system, we modified the linux kernel, the gnu binutils tools, and the bochs emulator. although the performance penalty is significant, our prototype demonstrates the feasibility of the approach, and should be directly usable on a suitable modified processor. our approach is equally applicable against code injecting attacks in scripting and interpreted languages, eg, web based sql injection. we demonstrate this by modifying the perl interpreter to permit randomized script execution. the performance penalty in this case is minimal. where our proposed approach is feasible, it can serve as a low overhead protection mechanism, and can easily complement other mechanisms. software vulnerabilities have been the cause of many computer security incidents. among these, buffer over ows are perhaps the permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies bear this notice and the full citation on the rst page. to copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speci. most widely exploited type of vulnerability, accounting for approximately half the cert advisories in the past few years. buffer over ow attacks exploit weaknesses in software that allow them to alter the execution ow of a program and cause arbitrary code to execute. this code is usually inserted in the targeted program, as part of the attack, and allows the attacker to subsume the privileges of the program under attack. because such attacks can be launched over a network, they are regularly used to break into hosts or as an infection vector for computer worms. in their original form, such attacks seek to over ow a buffer in the program stack and cause control to be transfered to the injected code. similar attacks over ow buffers in the program heap or use other injection vectors. such code injection attacks are by no means restricted to languages like; attackers have exploited failures in input validation of web cgi scripts to permit them to execute arbitrary sql and unix command line instructions respectively on the target system. there has been some speculation on similar attacks against perl scripts. techniques used in each attack differ, they all result in the attacker executing code of their choice, whether machine code, shell commands, sql queries, etc. the natural implication is that the attacker knows what type of code can be injected. this observation has led us to consider a new, general approach for preventing code injection attacks, instruction set randomization. by randomizing the underlying systeminstructions, foreign code introduced by an attack would fail to execute correctly, regardless of the injection approach. thus, our approach addresses not only stack and heap based buffer over ow attacks, but any type of code injection attack. what constitutes the instruction set to be randomized depends on the system under consideration: common stack or heap based buffer over ow attacks typically inject machine code that corresponds to the underlying processor. for perl injection attacks, the instruction set is the perl language, since any injected code will be executed by the perl interpreter. to simplify the discussion, we will focus on machine code randomization for the remainder of this paper, although we discuss our prototype randomized perl in section #. randomizing an arbitrary instruction set, eg, the machine code, involves three components: the randomizing element, the execution environment, and the loader. where the processor supports such functionality, our approach can be implemented without noticeable loss of performance, since the randomization process can be fairly straightforward, as we report in section #. we describe the necessary modi cations to the operating system and the randomizing element. we use a modi ed version of the bochsx pentium emulator to validate our design. generally, the loss of performance associated with an emulator is unacceptable for most applications: we present a small but concrete example of this in section #. our prototype demonstrates the simplicity of the necessary software support. in the case of interpreted languages, our approach does not lead to any measurable loss in performance. compared to previous techniques, we offer greater transparency to languages, applications and compilers, as well as a smaller impact on performance. the remainder of this paper is organized as follows. section # presents the details of our approach. section # describes two prototype implementations, for executables and perl scripts respectively. we discuss some details of the approach, limitations, and future work in section #. section # gives an overview of related work aimed at protecting against code injection attacks or their effects. it interpretively executes programs written in a simple plstyle programming language. this paper describes the symbolic execution of programs. instead of supplying the normal inputs to a program one supplies symbols representing arbitrary values. the execution proceeds as in a normal execution except that values may be symbolic formulas over the input symbols. the difficult, yet interesting issues arise during the symbolic execution of conditional branch type statements. a particular system called effigy which provides symbolic execution for program testing and debugging is also described. it includes many standard debugging features, the ability to manage and to prove things about symbolic expressions, a simple program testing manager, and a program verifier. a brief discussion of the relationship between symbolic execution and program proving is also included. the large scale production of reliable programs is one of the fundamental requirements for applying com puters to today challenging problems. however, the practical accomplishments in this area fall short of a tool for routine use. fundamental problems in reducing the theory to practice are not likely to be solved in the immediate future. al ternatively, in program proving the programmer form ally proves that the program meets its specification for all executions without being required to execute the program at all. to do this he gives a precise specifica tion of the correct program behavior and then follows a formal proof procedure to show that the program and the specification are consistent. several tech niques are used in practice; others are the focus of cur rent research. the work reported in this paper is directed at assuring that a program meets its requirements even when formal specifications are not given. the current technology in this area is basically a testing technology. that is, some small sample of the data that a program is expected to handle is presented to the program. if the program is judged to produce correct results for the sample, it is assumed to be correct. much current work focuses on the question of how to choose this sample. recent work on proving the correctness of programs by formal analysis shows great promise and appears to be the ultimate technique for producing reliable pro grams. program testing and program proving can be con sidered as extreme alternatives. while testing, a pro grammer can be assured that sample test runs work cor rectly by carefully checking the results. the correct exe cution for inputs not in the sample is still in doubt. the confidence in this method hinges on the care and accuracy employed in both the creation of the specification and in the con struction of the proof steps, as well as on the attention to machine dependent issues such as overflow, rounding etc. this paper describes a practical approach between these two extremes. from one simple view, it is an en hanced testing technique. instead of executing a program on a set of sample inputs, a program is symbolically executed for a set of classes of inputs. that is, each sym bolic execution result may be equivalent to a large num ber of normal test cases. these results can be checked against the programmer expectations for correctness either formally or informally. the class of inputs characterized by each symbolic execution is determined by the dependence of the pro gram control flow on its inputs. if the control flow of the program is completely independent of the input var iables, a single symbolic execution will suffice to check all possible executions of the program. if the control flow of the program is dependent on the inputs, one must resort to a case analysis. often the set of input communications july year# of volume the acm number classes needed to exhaust all possible cases is practicauy infinite, so this is still basically a testing methodology. however, the input classes are determined only by those inputs involved in the control flow, and symbolic test ing promises to provide better results more easily than normal testing for most programs. we present the design and implementation of asist by modifying and mapping a sparc processor onto an fpga board and running our modified linux kernel to support the new features. code injection attacks continue to pose a threat to today computing systems, as they exploit software vulnerabilities to inject and execute arbitrary, malicious code. instruction set randomization is able to protect a system against remote machine code injection attacks by randomizing the instruction set of each process. this way, the attacker will inject invalid code that will fail to execute on the randomized processor. however, all the existing implementations of isr are based on emulators and binary instrumentation tools that incur a significant runtime performance overhead, limit the ease of deployment of isr, cannot protect the underlying operating system kernel, and are vulnerable to evasion attempts trying to bypass isr protection. to address these issues we propose asist: an architecture with hardware and operating system support for isr. the operating system loads the randomization key of each running process into a newly defined register, and the modified processor decodes the process instructions with this key before execution. moreover, asist protects the system against attacks that exploit kernel vulnerabilities to run arbitrary code with elevated privileges, by using a separate randomization key for the operating system. we show that asist transparently protects all applications and the operating system kernel from machine code injection attacks with less than runtime overhead, while only requiring additional hardware. the processor decrypts at runtime every instruction of the respective process with the same key. existing isr implementations use binary transformation tools to encrypt the programs. however, they have several limitations: they incur a signi cant runtime performance overhead due to the software emulator or instrumentation tool. this overhead is prohibitive for a wide adoption of such techniques. hardware extensions to enhance security have been proposed in the past. to support runtime decryption at the cpu, we propose the use of two new registers in the asist enabled processor: the oskey and usrkey registers, which contain the kernelkey and the user level key of the running process. whenever a trap to kernel is called, the cpu enters into supervisor mode and the value of the oskey register is used to decrypt instructions. we discuss and evaluate the advantages of each approach in terms of security and performance. the main contributions of this work are: we propose asist: the rst hardware based support for isr to prevent machine code injections without any performance overhead. code injection attacks exploit software vulnerabilities to inject and execute arbitrary malicious code, allowing the attacker to obtain full access to the vulnerable system. there are several ways to achieve arbitrary code execution through the exploitation of a software vulnerability. the vast majority of code injection attacks exploit vulnerabilities that allow the diversion of control ow to the injected malicious code. arbitrary code execution is also possible through the modi cation of non control data. the most commonly exploited vulnerabilities for code injection attacks are buffer over ows. despite considerable research efforts, buffer over ow vulnerabilities remain a major security threat. other vulnerabilities that allow the corruption of critical data are format string errors and integer over ows. remotely exploitable vulnerabilities are continuously being discovered in popular network applications and operating system kernels. thus, code injection attacks remain one of the most common security threats, exposing signi cant challenges to current security systems. for instance, the massive outbreak of the con cker worm in year# infected more than million machines worldwide. like most of the internet worms, con cker was based on a typical code injection attack that exploited a vulnerability in windows rpc. along with the continuous discovery of new remotely exploitable vulnerabilities and zero day attacks, the increasing complexity and sophisticated evasive methods of attack techniques has signi cantly reduced the effectiveness of attack detection systems. instruction set randomization has been proposed to defend against any type of code injection attack. isr randomizes the instruction set of a processor so that an attacker is not able to know the processorlanguage to inject meaningful code. therefore, any injected code will fail to accomplish the desirable malicious behavior, probably resulting in invalid instructions. to prevent successful machine code injections, isr techniques encrypt the instructions of a possibly vulnerable program with a program speci. this key actually de nes the valid instruction set for this program. only the correctly encrypted instructions will lead to the intended code execution after decryption. any injected code that is not encrypted with the correct key will result in irrelevant or invalid instructions. for runtime decryption they use emulators, or dynamic binary instrumentation tools. deployment is limited by the necessity of several tools, like emulators, and manual encryption of the programs that are protected with isr. they are vulnerable to code injection attacks into the underlying emulator or instrumentation tools. more importantly, they do not protect against attacks targeting kernel vulnerabilities, which are becoming an increasingly attractive target for attackers. most isr implementations are vulnerable to evasion attacks aiming to guess the encryption key and bypass isr protection. to address these issues we propose asist: a hardware software scheme to support isr on top of an unmodi ed isa. we advocate that hardware support for isr is essential to guard against code injection attacks, at both user and kernellevel, without incurring signi cant performance penalty at runtime. asist uses distinct per process keys and another key for the operating system kernelcode. these registers are memory mapped and they are only accessible by the operating system via privileged instructions. our implementation for the sparc architecture maps these registers into a new address space identi er. the operating system is responsible for reading or generating the key of each program at load time, and associating it with the respective process. it is also responsible for storing at the usrkey register the key of the next process scheduled for execution at a context switch. when the cpu is not in supervisor mode, it decrypts each instruction using the usrkey register. we explore two possible choices for implementing the decryption unit at the instruction fetch pipeline stage of the modi ed processor. we also implement two different encryption algorithms, xor and transposition, and use different key sizes. additionally, we compare two alternative techniques for encrypting the executable code: statically, by adding a new section in elf that contains the key and encrypting all code sections with this key using a binary transformation tool, and dynamically, by generating a random key at load time and encrypting with this key at the page fault handler all the memory mapped pages that contain code. the dynamic encryption approach can support dynamically linked shared libraries, whereas static encryption requires statically linked binaries. our modi ed processor can also encrypt the return address at each function call and decrypt it before returning to caller. this way, asist protects the system from return oriented programming attacks, but not from jump oriented programming attacks. to demonstrate the feasibility of our approach we present the prototype implementation of asist by modifying the leon sparc processor, a bit open source synthesizable processor. we also modi ed the linux kernel to support the implemented hardware features for isr and evaluate our prototype. our experimental evaluation results show that asist is able to prevent code injection attacks practically without any performance overhead, while adding less than of additional hardware to support isr with our design. our results also indicate that the proposed dynamic code encryption at the page fault handler does not impose any signi cant overhead, due to the low page fault rate for pages with executable code. this outcome makes our dynamic encryption approach very appealing, as it is able to transparently encrypt any executable program, it generates a different random key at each execution, and it supports shared libraries with negligible overhead. we demonstrate the feasibility of hardware based support for isr by presenting the design, implementation, and experimental evaluation of asist. we introduce a dynamic code encryption technique that transparently encrypts pages with executable code at the page fault handler, using a randomly generated key for each execution. we show that this technique supports shared libraries and does not impose signi cant overhead to the system. we explore different choices for the decryption unit in hardware, we compare static and dynamic encryption, as well as different encryption algorithms and key sizes in order to improve the resistance of isr against evasion attempts. we show that a hardware based isr implementation, like asist, is able to protect the system against attacks that exploit os kernel vulnerabilities. we evaluated our prototype implementation with hardwareenabled isr and we showed that it is able to prevent code injection attacks with negligible overhead. in unit testing, a program is decomposed into units which are collections of functions. a part of unit can be tested by generating inputs for a single entry function. the entry function may contain pointer arguments, in which case the inputs to the unit are memory graphs. the paper addresses the problem of automating unit testing with memory graphs as inputs. the approach used builds on previous work combining symbolic and concrete execution, and more specifically, using such a combination to generate test inputs to explore all feasible execution paths. the current work develops a method to represent and track constraints that capture the behavior of a symbolic execution of a unit with memory graphs as inputs. moreover, an efficient constraint solver is proposed to facilitate incremental generation of such test inputs. finally, cute, a tool implementing the method is described together with the results of applying cute to real world examples ofcode. unit testing is a method for modular testing of a programs functional behavior. a program is decomposed into units, where each unit is a collection of functions, and the units are independently tested. such testing requires speci cation ofvaluesfortheinputs to the unit. manual speci cation of such values is labor intensive and cannot guarantee that all possible behaviors of the unit will be observed during the testing. in order to improve the range of behaviors observed, severaltechniqueshavebeenproposedto automatically generate values for the inputs. one such tech permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies bear this notice and the full citation on the rst page. to copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speci. nique is to randomly choose the values over the domain of potentialinputs. theproblemwith such random testingistwofold: rst, many setsofvaluesmay leadtothe same observable behavior and are thus redundant, and second, theprobability ofselectingparticularinputsthatcause buggybehaviormay be astronomically small. one approach which addresses the problem of redundant executions and increases test coverage is symbolic execution. insymbolic execution, aprogram is executed using symbolic variables in place of concrete values for inputs. each conditional expression in the program represents a constraint that determines an execution path observethatthefeasibleexecutions ofaprogram can be represented as a tree, where the branch points in a program are internal nodes of the tree. the goal is to generate concrete values for inputs which would result in di erent paths being taken. the classic approach is to use depth rst exploration of the paths by backtracking. unfortunately, for large or complex units, it is computationally intractable to precisely maintain and solve the constraints required for test generation. to the best of our knowledge, larson and austin were the rst to propose combining concrete and symbolic execution. intheirapproach, theprogramisexecuted on some user provided concrete input values. symbolic path constraints are generated for the speci. these constraints are solved, if feasible, to see whether there are potential input values that would have led to a violation along the same execution path. this improves coverage while avoiding the computational cost associated with fullblown symbolic execution which exercises all possible execution paths. godefroid et al proposed incrementally generating test inputsby combining concrete and symbolic execution. in godefroid et alapproach, during a concrete execution, a conjunction of symbolic constraints along the path of the execution is generated. these constraints are modi ed and then solved, iffeasible, to generatefurthertestinputswhich would direct the program along alternative paths. speci cally, they systematically negate the conjuncts in the path constraint to provide a depth rst exploration of all paths in the computation tree. if it is not feasible to solve the modi ed constraints, godefroid et al propose simply substituting random concrete values. a challenge in applying godefroid et alapproach is to provide methods which extract and solve the constraints generated by a program. this problem is particularly complexforprograms whichhavedynamicdata structures using pointer operations. becausealias analysismay only beapproximateinthepresenceofpointer arithmetic, using symbolicvaluestoprecisely track suchpointers may resultin constraintswhose satisfaction is undecidable. this makes the generation of test inputsbysolving such constraintsinfeasible. in thispaper, we provide a method for representing and solving approximate pointer constraints to generate test inputs. our method is thus applicable to a broad class of sequential programs. the key idea of our method is to represent inputs for the unit under test using a logical input map that represents all inputs, including memorygraphs, asacollectionof scalar symbolic variables and then to build constraints on these inputs by symbolically executing the code under test. we rst instrument the code being tested by inserting function calls which perform symbolic execution. we then repeatedly run the instrumented code as follows. the logical input mapis used to generate concrete memory input graphs for the program and two symbolic states, one for pointervalues and oneforprimitivevalues. thecodeisrun concretely on the concrete input graph and symbolically on the symbolic states, collecting constraints that characterize theset ofinputsthatwould takethesameexecution path as thecurrentexecution path. the resulting constraint system is solved to obtain a new logical input mapthat is similar tobut leads the execution through a di erent path. since the goal of this testing approach is to explore feasible execution paths as much as possible, it can be seen as explicit path model checking. an important contribution of our work is separating pointer constraints from integer constraints and keeping the pointer constraints simple to make our symbolic execution light weight and our constraint solving procedure not only tractable but also. the pointer constraints are conceptually simpli ed using the logical input map to replace complex symbolic expressions involving pointers with simple symbolicpointer variables. for example, ifis an input pointer to a struct with. eld, then a constraint onf will be simpli ed to a constraint on, where is the symbolic variable corresponding to theinput value. althoughthissimpli cationintroducessome approximationsthatdonotprecisely capture all executions, it results in simple pointer constraints of the formy or, whereandare either symbolic pointer variables or the constant null. ciently solved, and the approximations seem to su ce in practice. we implemented our method in a tool called cute. cute is available at http: osl cs uiuc edu ksen cute. cute implements a solver for both arithmetic and pointer constraintstoincrementallygeneratetestinputs. thesolver exploitsthedomain ofthisparticularproblemtoimplement three novel optimizations which help to improve the testing time by several orders of magnitude. our experimental results con rm that cute can. in particular, it exposed software bugs that result in assertion violations, segmentation faults, or in nite loops. typedef struct cell cell; int int testme figure #: examplecode and inputs that cute generates for testing the function testme thispaperpresentstwocasestudies oftesting codeusing cute. the rst study involves thecode of the cute tool itself. the second case study found two previously unknown errors in sglib, a populardata structure library used in a commercial tool. we reported the sglib errors to the sglib developers who xed them in the next release. address space randomization is a technique used to fortify systems against buffer overflow attacks. the idea is to introduce artificial diversity by randomizing the memory location of certain system components. this mechanism is available for both linux and openbsd. we study the effectiveness of address space randomization and find that its utility on bit architectures is limited by the number of bits available for address randomization. in particular, we demonstrate aderandomization attackthat will convert any standard buffer overflow exploit into an exploit that works against systems protected by address space randomization. the resulting exploit is as effective as the original exploit, although it takes a little longer to compromise a target machine: on average seconds to compromise apache running on a linux pax aslr system. the attack does not require running code on the stack. we also explore various ways of strengthening address space randomization and point out weaknesses in each. surprisingly, increasing the frequency of re randomizations adds at most bit of security. furthermore, compile time randomization appears to be more effective than runtime randomization. we conclude that, on bit architectures, the only benefit of pax like address space randomization is a small slowdown in worm propagation speed. the cost of randomization is extra complexity in system support. randomizing the memory address space layout of software has recently garnered great interest as a means of diversifying the monoculture of software. it is widely believed that randomizing the address space layout of a software program prevents attackers from using the same exploit code. ectively against all instantiations of the program containing the same aw. exploit for each instance of a randomized program or perform brute force attacks to guess the address space layout. brute force attacks are supposedly thwarted by constantly randomizing the address space layout each time the program is restarted. in particular, this technique seems to hold great promise in preventing the exponential propagation of worms that scan the internet and compromise hosts using a hard coded attack. ectiveness of addressspace randomization in preventing an attacker from using the same attack code to exploit the same aw in multiple randomized instances of a single software program. in particular, we implement a novel version of a return to libc attack on the apache http server on a machine running linux with pax address space layout randomization and write or execute only pages. traditional return to libc exploits rely on knowledge of addresses in both the stack and the textsegments. with pax aslr in place, such exploits must guess the segment. sets from a search space of either bits or bits. in contrast, our return to libc technique uses addresses placed by the target program onto the stack. attacks using our technique need only guess the libc text segment. set, reducing the search space to an entirely practical bits. attack uses only a single entry point in libc, the exploit technique is also applicable to chained return to libc attacks. our implementation shows that bu er over ow attacks are as. ective on code randomized by pax aslr as on non randomized code. experimentally, our attack takes on the average seconds to obtain a remote shell. brute force attacks, like our attack, can be detected in practice, but reasonable countermeasures are di cult to design. ine results in a denial of service attack, and leaving them online while. is sought allows the vulnerability to be exploited. the problem of detecting and managing a brute force attack is especially exacerbated by the speed of our attack. while pax aslr appears to provide a slowdown in attack propagation, work done by staniford et al suggests that this slowdown may be inadequate for inhibiting worm propagation. to pax aslr, the attack is generic and applies to other address space randomization systems such as that in openbsd. the attack also applies to any software program accessible locally or through a network connection. our attack demonstrates what we call a derandomization attack; derandomization converts any standard bu er over ow exploit into an exploit that works against systems protected by address space randomization. on the other hand, the slowdown is not su cient to prevent its being used in worms or in a targeted attack. in the second part of the paper, we explore and analyze the. ectiveness of more powerful randomization techniques such as increasing the frequency of re randomization and also ner grained randomizations. we show that subsequent re randomizations after the initial address space randomization improve security against a brute force attack by at most a factor of. this result suggests that it would be far more bene cial to focus on increasing the entropy in the address space layout. furthermore, this result shows that our brute force attacks are still feasible against network servers that are restarted with different randomization upon crashing. our analysis suggests that runtime address space randomization is far less. compile time address space randomization can be more. ective than runtime randomization because the address space can be randomized at a much ner granularity at compile time than runtime. we note that bu er over ow mitigation techniques can prevent some attacks, including the one we present in this paper. however, over ow mitigation by itself without any address space randomization also defeats many of these attacks. thus, the security provided by over ow mitigation is largely orthogonal to address space randomization. we speculate that the most promising solution appears to be upgrading to a bit architecture. randomization comes at a cost: in both and bit architectures, randomized executables are more di cult to debug and support. bu er over ow exploits started with simple stack smashing techniques where the return address of the current stack frame is overwritten to point to injected code. after the easy stack smashing vulnerabilities were discovered and exploited,urry of new attacks emerged that exploited over ows in the heap, format string errors, integer over ows, and double free errors. several techniques were developed to counter stack smashing stackguard by cowan et al detects stack smashing attacks by placing canary values next to the return address. stackshield by vendicator makes a second copy of the return address to check against before using it. ective for reducing the number of exploitable bu er over ows but does not completely remove the threat. for example, bulba and kil show how to bypass these bu er over ow defenses. propolice by etoh extends the ideas behind stack guard by reordering local variables and function arguments, and placing canaries in the stack. propolice also copies function pointers to an area preceding local variable bu ers. propolice is packaged with the latest versions of openbsd. pointguard by cowan et al prevents pointer corruption by encrypting them while in memory and only decrypting values before dereferencing. the techniques described so far aim to stop attackers from seizing control of program execution. nulli es attacks that inject and execute code in a processaddress space. is based on the observation that most of the exploits so far inject malicious code into a processaddress space and then circumvent program control to execute the injected code. x, pages in the heap, stack, and other memory segments are marked either writable or executable, but not both. stackpatch by solar designer is a linux kernel patch that makes the stack non executable. the latest versions of linux and of openbsd contain implementations of. our sample attack works on a system running pax with. memory pages, attackers cannot inject and execute code of their own choosing. instead, they must use existing executable code either the programown code or code in libraries loaded by the program. for example, an attacker can overwrite the stack above the return address of the current frame and then change the return address to point to a function he wishes to call. when the function in the current frame returns, program control ow is redirected to the attackerchosen function and the overwritten portions of the stack are treated as arguments. traditionally, attackers have chosen to call functions in the standardlanguage library, libc, which is an attractive target because it is loaded into every unix program and encapsulates the system call api by which programs access such kernel services as forking child processes and communicating over network sockets. this class of attacks, originally suggested by solar designer, is therefore known as return to libc. on cpus whose memory management units lack a per page execute bit for example, current chips incur a signi cant performance penalty. another defense against malicious code injection is randomized instruction sets. on the other hand, randomized instruction sets are ine ective against return tolibc attacks for the same reasons as those given above for. observe that a returnto libc attack needs to know the virtual addresses of the libc functions to be written into a function pointer or return address. if the base address of the memory segment containing libc is randomized, then the success rate of such an attack signi cantly decreases. this idea is implemented in pax as aslr. pax aslr randomizes the base address of the stack, heap, code, and mmap ed segments of elf executables and dynamic libraries at load and link time. we implemented our attack against a pax hardened system and will give a more detailed description of pax in sect. previous projects have employed address randomization as a security mechanism. yarvin et al develop a lowoverhead rpc mechanism by placing bu ers and executablebut unreadable stubs at random locations in the address space, treating the addresses of these bu ers and stubs as capabilities. their analysis shows that a bit address space is insu cient to keep processes from guessing such capability addresses, but that a bit address space is, assuming a time penalty is assessed on bad guesses. bhatkar et al de ne and discuss address obfuscation. their implementation randomizes the base address of the stack, heap, and code segments and adds random padding to stack frame and malloc function calls. they implemented a binary tool that rewrites executables and ob ject les to randomize addresses. randomizing addresses at link and compilation time xes the randomizations when the system is built. this approach has the shortcoming of giving an attacker. xed address space layout that she can probe repeatedly to garner information. their solution to this problem is periodically to re obfuscate executables and libraries that is, periodically relink and recompile executables and libraries. as pointed out in their paper, this solution interferes with host based intrusion detection systems based on les integrity checksums. our brute force attack works just as well on the published version of this system because their published implementation only randomizes the base address of libraries alapax. xu et al designed a runtime randomization system that does not require kernel changes, but is otherwise similar to pax. the primary di erence between their system and pax is that their system randomizes the location of the global. set table and patches the procedural linkage table accordingly. our attack also works against their system because: their system uses bits of randomness, and our attack does not need to determine the location of the got. ectiveness of crash detectors in mitigating such attacks. the lack of memory safety inc often leads to vulnerabilities. code injection attacks exploit these vulnerabilities to gain control over the execution flow of applications. these attacks have played a key role in many major security incidents. consequently, a huge body of research on countermeasures exists. we provide a comprehensive and structured survey of vulnerabilities and countermeasures that operate at runtime. these countermeasures make different trade offs in terms of performance, effectivity, compatibility, etc, making it hard to evaluate and compare countermeasures in a given context. we define a classification and evaluation framework on the basis of which countermeasures can be assessed. more speci cally, implementation errors that allow an attacker to break memory safety and execute foreign code are addressed in this survey. bounds checkers perform bounds checks on array and pointer operations and detect when the program tries to perform an out of bounds operation and take action accordingly. hardened libraries replace library functions with versions that perform extra checks to ensure that the parameters are correct. software vulnerabilities have been a major cause of computer security incidents since the advent of multiuser and networked computing. most of these software vulnerabilities can be traced back to a few mistakes that programmers make over and over again. even though many papers and books attempt to teach programmers how to program more securely, the problem persists and will most likely continue to be a major problem in the foreseeable future. subclass of software vulnerabilities implementation errors inandas well as the countermeasures that have been proposed and developed to deal with these vulnerabilities. several preventive and defensive countermeasures have been proposed to combat exploitation of common implementation errors, and this article examines many of these. we also describe several ways in which some of the proposed countermeasures can be circumvented. this article focuses on runtime countermeasures, that is, only countermeasures that have some effect at runtime are in the scope. this includes countermeasures that perform additional runtime checks or harden thec runtime environment. it excludes purely static countermeasures: for instance, those that try authors address: younan, joosen, and. piessens, katholieke universiteit leuven; email: yyounan fort knox org. permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies show this notice on the rst page or initial screen of a display along with the full citation. copyrights for components of this work owned by others than acm must be honored. to copy otherwise, to republish, to post on servers, to redistribute to lists, or to use any component of this work in other works requires prior speci. permissions may be requested from publications dept, acm, inc, penn plaza, suite, new york, ny year# usa, fax, or permissions acm org. year# acm year# art doi year# http: doi acm org year#. younan et al to detect vulnerabilities using static analysis or program veri cation. it also excludes testing approaches such as fuzzers. these areas are also very active research areas and deserve their own survey. preliminary attempts at such a survey can be found in wilander and kamkar and pozza et al. although some countermeasures examined here protect against the more general case of buffer over ows, this article focuses on protection against attacks that speci cally attempt to execute code that an application would not execute in normal circumstances. such attacks subvert the control ow of the application either to injected code or to existing code which is then executed in a different context. given the large number of runtime countermeasures that have been proposed to deal with such attacks, and given the wide variety in techniques used in the design of these countermeasures, it is hard for an outsider of the research eld itself to get a good understanding of existing solutions. this article aims to provide such an understanding to software engineers and computer scientists without speci. security expertise by providing a structured classi cation and evaluation framework. at the top level, we classify existing countermeasures based on the main technique they use to address the problem. safe languages are languages in which most of the implementation vulnerabilities do not exist or are hard to exploit. these languages generally require a programmer to speci cally implement a program in this language or to port an existing program to this language. we will focus on languages that are similar to, that is, languages that stay as close toandas possible. these are mostly referred to as safe dialects of. programs written in these dialects generally have some restrictions in terms of memory management: the programmer no longer has explicit control over the dynamic memory allocator. probabilistic countermeasures make use of randomness to make exploitation of vulnerabilities harder. separators and replicators of information exist in two types: the rst type will try to replicate valuable control ow data or will separate this data from regular data. replication can be used to verify the original value, while separation prevents an attacker from overwriting the separated data because it is no longer adjacent to the vulnerable object. the second type relies on replication only, but replicates processes with some diversity introduced. if the processes act differently for the same input, then an attack has been detected. vmm based countermeasures make use of properties of the virtual memory manager to build countermeasures. some monitors will try to limit the damage of a successful attack on a vulnerability on the underlying system by limiting the actions a program can perform. others will detect if a program is exhibiting unexpected behavior and will provide alerts if this occurs. the rst type of runtime monitor is called a sandbox, while the second type of monitoring is called anomaly detection. runtime taint trackers will instrument the program to mark input as tainted. if such tainted data is later used in the program where untainted data is expected or is used to modify a trusted memory location, then a fault is generated. section # contains an overview of the implementation errors that the countermeasures in section # defend against. it also describes typical ways in which these implementation errors can be abused. section # contains a description of the properties that we will assign to the various countermeasures that are examined in section #. section # contains our survey of countermeasures and the ways in which they can be circumvented.