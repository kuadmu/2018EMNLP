there is extensive use of formal methods in the security context, especially for protocol analysis. in particular, they analyze address obfuscation, a defense mechanism against memory corruption attacks, that uses a secret key to randomize the offsets of code and data in heap memory. the equivalences capture indistinguishability in the presence of an arbitrary attacker, represented as the context of the programs. in our setting, someone has to prove for a given class of programs, that the defense mechanism is effective for that class. agten et al describe a compiler that implements full abstrac tion, ie, the compiler guarantees that standard security features in languages such as java are compiled correctly down to the lower level language and the security at the low level is enforced via ne grained access control. this work is orthogonal to ours since, unlike our approach, they donanalyze probabilistic defense mechanisms. they compute the probability of a successful code injection attack on a program protected by the isr mechanism presented in. their attacker model was similar to our in the sense that the attacker had knowledge about the vulnerabilities in the target program and only had remote access to the target machine. this attack is highly effective on bit systems where, aslr only randomizes the base address of memory pages which are kbs in size. therefore, there are only bits of memory which can be randomized. there is also considerable prior work on dynamic information ow leakage, and on analysis of implementation of cryptographic primitives. our work is differ ent in that we propose the combination of such analyses to formally establish the effectiveness of defense mechanisms with respect to clearly speci ed attackers. pucella and schneider have also formally investigated the effectiveness of randomized defenses in the context of memory safety. their main result is to characterize such defenses as to be probabilistically equivalent to a strong typing which would guarantee memory safety for buffers, thus reducing the security of the defense mechanism to the strength of strong typing. their idea is to treat address obfuscation as a probabilistic type checker, which has a certain probabilityof crashing the program when a buffer over ow occurs. differently from our discussion on the attacreita ncof isr against code injection attacks in section #, by relating to a type checker that catches out of bound access, they automatically consider a wider range of possible attacks. however, also due to this abstract charachterization, they acknowledge the dif culty on computing the probability of a successful attack, as we propose to do. we believe that different from, the attacreita ncframework proposed in this work can also be used to compute the probability of a successful buffer over ow against address obfuscation if we combine this defense technique with other techniques, such as sme or quantitative information ow analysis, that prevent substantial leakage of the secret key. abadi and plotkin also formally investigate the effective ness of memory layout randomization in programming language terms. speci cally, they consider layout randomization as part of the low level implementation of a high level language. this implementation is analyzed by mapping low level attacks against it to context in the high level programming language. their re sults are phrased as full abstraction theorems that say that two programs are equivalent in the high level language if and only if their translations are equivalent in the lowlevel language. these equivalences are powerful enough to express both secrecy and integrity properties. jagadeesan et al, ex tend the work of abadi and plotkin by considering return to libc attacks as well as dynamic memory allocation features in programming languages. while these are very powerful results, they are less general than our approach because we consider a wider variety of defense mechanisms and attacks, and do not. by contrast, the results of are restricted to aslr. on the other hand, if a programmer were to write their programs in the high level language of, then they would get the protection of aslr for free without having to explicitly prove them. sovarel et al and weiss et al also perform an analysis of the attacks against isr presented in table #. differently from our analysis they only give numeric values for these attacks on intel architectures under additional assumptions, without offering a more general overview of this probability in terms of the size of the key and the size of the instruction set and instruction sizes. shacham et al presented a study regarding the assessment of randomization based software defenses. their study consisted of a concrete attack on any program containing a buffer over ow vulnerability protected by aslr. however, one key factor in their attack was the assumption that the remote machine is running a certain version of an apache server, whose behavior is used as a side channel. more speci cally, if the correct offset of a libc function is sent to the apache server, then it has a different behavior than when the guess was incorrect. of course the attack is not dependent on apache itself, but on a side channel which leaks the rss of aslr. brute forcing a randomization space of this size is practical on current hardware. therefore, the straightforward solution to this attack is to switch to a bit system.