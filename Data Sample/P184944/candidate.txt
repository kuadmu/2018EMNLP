using the arithmetic mean to summarize normalized benchmark results leads to mistaken conclusions that can be avoided by using the preferred method: the geometric mean. we present a pointer and array access checking technique that provides complete error coverage through a simple set of program transformations. our technique, based on an extended safe pointer representation, has a number of novel aspects. foremost, it is the first technique that detects all spatial and temporal access errors. its use is not limited by the expressiveness of the language; that is, it can be applied successfully to compiled or interpreted languages with subscripted and mutable pointers, local references, and explicit and typeless dynamic storage management, eg, because it is a source level transformation, it is amenable to both compile and run time optimization. finally, its performance, even without compile time optimization, is quite good. we implemented a prototype translator for thelanguage and analyzed the checking overheads of six non trivial, pointer intensive programs. execution overheads range from to; with text and data size overheads typically below. the approach, which we call secure virtual architecture, defines a virtual, low level, typed instruction set suitable for executing all code on a system, including kernel and application code. a virtual machine implementing sva achieves these goals by using a novel approach that exploits properties of existing memory pools in the kernel and by preserving the kernel explicit control over memory, including custom allocators and explicit deallocation. sva also defines a set of os interface operations that abstract all privileged hardware instructions, allowing the virtual machine to monitor all privileged operations and control the physical resources on a given hardware platform. sva is able to prevent out of memory safety exploits previously reported for the linux kernel for which exploit code is available, and would prevent the fifth one simply by compiling an additional kernel library. this paper describes an efficient and robust approach to provide a safe execution environment for an entire operating system, such as linux, and all its applications. sva code is translated for execution by a virtual machine transparently, offline or online. sva aims to enforce fine grained memory safety, control flow integrity, type safety for a subset of objects, and sound analysis. furthermore, the safety properties can be encoded compactly as extensions to the sva type system, allowing the safety checking compiler to be outside the trusted computing base. we have ported the linux kernel to sva, treating it as a new architecture, and made only minimal code changes to the machine independent parts of the kernel and device drivers. theprogramming language is at least as well known for its absence of spatial memory safety guarantees as it is for its high performance. unchecked pointer arithmetic and array indexing allow simple programming mistakes to lead to erroneous executions, silent data corruption, and security vulnerabilities. many prior proposals have tackled enforcing spatial safety inprograms by checking pointer and array accesses. however, existing software only proposals have significant drawbacks that may prevent wide adoption, including: unacceptably high run time overheads, lack of completeness, incompatible pointer representations, or need for non trivial changes to existingsource code and compiler infrastructure. inspired by the promise of these software only approaches, this paper proposes a hardware bounded pointer architectural primitive that supports cooperative hardware software enforcement of spatial memory safety forprograms. this bounded pointer is a new hardware primitive datatype for pointers that leaves the standardpointer representation intact, but augments it with bounds information maintained separately and invisibly by the hardware. the bounds are initialized by the software, and they are then propagated and enforced transparently by the hardware, which automatically checks a pointer bounds before it is dereferenced. one mode of use requires instrumenting only malloc, which enables enforcement of perallocation spatial safety for heap allocated objects for existing binaries. when combined with simple intraprocedural compiler instrumentation, hardware bounded pointers enable a low overhead approach for enforcing complete spatial memory safety in unmodifiedprograms. theprogramming language is the de facto standard for systems programming, and software written in makes up the majority of code running on most platforms. this success is due in part to the low level control over data representation, memory management, and performance thatgives programmers. de this work done while joe devietti was at the university of pennsylvania. permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies bear this notice and the full citation on the rst page. to copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speci. bounded pointers: using full base bound metadata and compressed. spite this widespread use, there is a price to pay: is the source of a range of software vulnerabilities that permeate our computing infrastructure. the root of the problem is that thelanguage is inherently unsafe. its unchecked array operations lead to buffer over ows; the con ation of pointers and arrays allows hazardous pointer arithmetic and dereferencing; unsafe casts allow programs to accidentally write to or read from arbitrary memory addresses. there have been many proposals that ameliorate the problems caused bys unchecked pointer and array accesses by partially or fully detecting violations of spatial memory safety. a violation of spatial memory safety occurs when a program uses a variable to access memory that is outside the bounds of the object associated with the variable. spatial errors include accessing the nth element of anelement array when, erroneously indexing off a nonarray pointer, or casting a pointer to a struct larger than the region originally allocated and then accessing. eld that is beyond the bounds of the original allocation. to help detect and diagnose spatial errors inprograms, many software only tools and hardwaresupported techniques have been proposed. although these techniques are useful, many of them do not provide complete spatial memory safety. likewise, many special purpose techniques address restricted classes of security exploits made possible by spatial memory safety violations. these approaches focus on protecting the return address, protecting data pointers or code pointers, detecting anomalous program ow, protecting heap metadata, or preventing memory attacks by tracking untrusted inputs via tainting. although effective in many cases, these targeted proposals mostly focus on speci. attacks or symptoms and not on the root cause of the problem. instead of relying on this patchwork of incomplete and indirect solutions, other approaches have directly attacked the source of the problem: s lack of spatial memory safety. just as type safe languages like java andeliminate all of the vulnerabilities mentioned above, an implementation ofthat enforces spatial safety will also avoid them. several promising software only approaches for enforcing full or almost full spatial safety forhave been proposed. unfortunately, these software only proposals all suffer from one or more de ciencies that may prevent wide adoption, such as: unacceptably high runtime overheads, incomplete detection of spatial violations, incompatible pointer representations, or requiring non trivial changes to existingsource code. moreover, the software only schemes with the lowest performance overheads generally require sophisticated wholeprogram compiler analyses. section # discusses these software techniques in detail. this paper describes hardbound, a new hardware design that overcomes the de ciencies of these software only approaches by providing architectural support for a new primitive datatype a hardware bounded pointer inspired by the pointers used in safe, ccured, and cyclone. these software based schemes replace some or all of the pointers in the program with three word fat pointers that encode the actual pointer, the base address of the associated object, and its bound. unlike the purely software approaches to implementing fat pointers, our proposed hardbound support maintains memory layout compatibility by encoding the bounds information in a disjoint shadow space, implicitly checks and propagates the bounds information as the bounded pointer is dereferenced, incremented, and copied to and from memory, and reduces storage and runtime overheads by caching compressed pointer encodings, thereby allowing many bounded pointers to be ef ciently represented using just a few additional bits of state. hardware bounded pointers are intended to facilitate software enforcement of spatial memory safety the software is responsible for communicating valid bounds metadata to the hardware via calls to a new setbound instruction. this design permits exible use of hardbound primitives, ranging from simple bounds protection at the heap allocated object granularity and is binary compatible with legacy code to ccured style complete spatial safety. to summarize, this paper makes the following contributions: we describe hardbound a hardware bounded pointer primitive and accompanying compiler transformations that together enforce complete spatial safety forprograms. section # describes the hardware bounded pointer model, hardware bounds propagation, and their use for spatial safety. the hardbound approach strives to minimize changes to the compiler infrastructure, and it retains compatibility with legacycode with respect to memory layout. we propose an ef cient implementation of hardware bounded pointers that opportunistically uses a compressed metadata encoding. in the uncommon case, the full base and bound metadata are stored in a reserved portion of virtual memory. in the common case of pointers to small objects and nonpointer data, the hardware encodes the bounded pointer metadata using just a few bits. these bits are stored either in memory or in unused bits of the pointer itself. in both cases, the hardware performs the encoding and decoding, making the speci. we experimentally evaluate both the functional correctness and performance of our approach. hardbound accurately detects all spatial memory violations in an extensive suite of spatial violation test cases with no false positives. performance measurements of a simulated processor on a variety of benchmarks indicate that the runtime overhead is just to on average depending on the pointer encoding. although spatial safety enforcement eliminates a large class of bugs and security vulnerabilities, it does not eliminate all of them. as discussed in section #, hardbound provides just enough type safety to enforce full spatial safety, but it does not provide full type safety. hardbound also does not address temporal memory safety errors. section # considers temporal safety issues and suggests how hardbound may be used in conjunction with existing temporal safety protection mechanisms. before describing our hardware bounded pointers, we rst overview the prior software only approaches for detecting spatial memory violations inthat motivated and inspired this work. the problem of enforcing correct usage of array and pointer references inandprograms remains unsolved. the approach proposed by jones and kelly is the only one we know of that does not require significant manual changes to programs, but it has extremely high overheads of and in the two versions. in this paper, we describe a collection of techniques that dramatically reduce the overhead of this approach, by exploiting a fine grain partitioning of memory called automatic pool allocation. together, these techniques bring the average overhead checks down to only for a set of benchmarks. we show that the memory partitioning is key to bringing down this overhead. we also show that our technique successfully detects all buffer overrun violations in a test suite modeling reported violations in some important real world programs. this paper addresses the problem of enforcing correct usage of array and pointer references inandprograms. this remains an unsolved problem despite a long history of this work is supported in part by the nsf embedded systems program, the nsf next generation software program, and an nsf career award. permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies bear this notice and the full citation on the rst page. to copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speci. work on detecting array bounds violations or bu er overruns, because the best existing solutions to date are either far too expensive for use in deployed production code or raise serious practical di culties for use in real world development situations. the fundamental di culty of bounds checking inandis the need to track, at run time, the intended target object of each pointer value. unlike safe languages like java, pointer arithmetic inandallows a pointer to be computed into the middle of an array or string object and used later to further index into the object. because such intermediate pointers can be saved into arbitrary data structures in memory and passed via function calls, checking the later indexing operations requires tracking the intended referent of the pointer through in memory data structures and function calls. the compiler must transform the program to perform this tracking, and this has proved a very di cult problem. more speci cally, there are three broad classes of solutions: use an expanded pointer representation to record information about the intended referent with each pointer: this approach allows. cient lookup of the pointer but the non standard pointer representation is incompatible with external, unchecked code, eg, precompiled libraries. the di culties of solving this problem in existing legacy code makes this approach largely impractical by itself. the challenges involved are described in more detail in section #. store the metadata separately from the pointer but use a map from pointers to metadata: this reduces but does not eliminate the compatibility problems of fat pointers, because checked pointers possibly modi ed by an external library must have their metadata updated at a library call. furthermore, this adds a potentially high cost for searching the maps for the referent on loads and stores through pointers. store only the address ranges of live objects and ensure that intermediate pointer arithmetic never crosses out of the original object into another valid object: this approach, attributed to jones and kelly, stores the address ranges in a global table and looks up the table for the intended referent before every pointer arithmetic operation. this eliminates the incompatibilities caused by associating metadata with pointers themselves, but current solutions based on this approach have even higher overhead than the previous two approaches. jones and kelly report overheads of for most programs. ruwase and lam extend the jones and kelly approach to support a larger class ofprograms, but report slowdowns of a factor of if enforcing bounds for all ob jects, and of for several signi cant programs even if only enforcing bounds for strings. these overheads are far too high for use in production code, which is important if bounds checks are to be used as a security mechanism. for brevity, we refer to these two approaches as jk and jkrl in this paper. note that compile time checking of array bounds violations via static analysis is not su cient by itself because it is usually only successful at proving correctness of a fraction of array and pointer references. therefore, such static checking techniques are primarily useful to reduce the number of run time checks. an acceptable solution for production code would be one that has no compatibility problems, but has overhead low enough for production use. a state of the art static checking algorithm can and should be used to reduce the overhead but we view that as reducing overhead by some constant fraction, for any of the run time techniques. the discussion above shows that none of the three current run time checking approaches come close to providing such an acceptable solution, with or without static checking. in this paper, we describe a method that dramatically reduces the run time overhead of jones and kellyreferent table method with the ruwase lam extension, to the point that we believe it can be used in production code. we propose two key improvements to the approach: we exploit a compile time transformation called automatic pool allocation to greatly reduce the cost of the referent lookups by partitioning the global splay tree into many small trees, while ensuring that the tree to search is known at compile time. the transformation also safely eliminates many scalar objects from the splay trees, making the trees even smaller. we present a compiler intermediate representation that allows dynamic speculative optimizations for high level languages. the ir is graph based and contains nodes fixed to control flow as well as floating nodes. side effecting nodes include a framestate that maps values back to the original program. guard nodes dynamically check assumptions and, on failure, deoptimize to the interpreter that continues execution. guards implicitly use the framestate and program position of the last side effecting node. therefore, they can be represented as freely floating nodes in the ir. exception edges are modeled as explicit control flow and are subject to full optimization. we use profiling and deoptimization to speculatively reduce the number of such edges. the ir is the core of a just in time compiler that is integrated with the java hotspot vm. we evaluate the design decisions of the ir using major java benchmark suites. speculative optimizations in a just in time compiler rely on pro ling feedback that characterizes program behavior. the compiler can focus on the most likely paths taken through permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies bear this notice and the full citation on the rst page. copyrights for components of this work owned by others than acm must be honored. to copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speci. http: dx doi org year# the program and cut off cold branches that are highly unlikely to be taken. this reduces code size and opens additional optimization opportunities, because the cold branch and its in uence on program state need not be taken into account when compiling a method. in high level languages such as java, a single operation can include an implicit control ow split. for example,eld access includes a null check on the receiver that can throw an exception. this control ow path is not visible in the original source program, but the compiler still has to handle it. in this context, the speculative reduction of those control ow paths is important. even more from this reduction, because an operation in such a language typically has a more complex control ow structure. when one of the cold branches is still taken, program execution must continue in the interpreter. this mechanism to jump from the optimized machine code back to the interpreter is called deoptimization. it requires bookkeeping in the compiled code that allows the reconstruction of the interpreter state at deoptimization points. this state includes the values of local variables and the operand stack. due to escape analysis, some of those values may reference virtual objects that need to be allocated during deoptimization. the design of an ir largely in uences whether a compiler writer can express optimizations in a simple way. in the context of speculative optimizations, it also decides whether such optimizations are possible at all and how much additional footprint is required for enabling deoptimization. this paper contributes the description and evaluation of a novel ir with the following properties: speculative optimizations using deoptimization points which map optimized program state back to interpreter state. insertion, movement, and coalescing of deoptimization points without any constraints. explicit representation of exception edges as normal control ow and omits them speculatively based on pro ling feedback. speculative optimizations are used in most just in time compilers in order to take advantage of dynamic runtime feedback. these speculative optimizations usually require the compiler to produce meta data that the virtual machine can use as fallback when a speculation fails. this meta data can be large and incurs a significant memory overhead since it needs to be stored alongside the machine code for as long as the machine code lives. the design of the graal compiler leads to many speculations falling back to a similar state and location. in this paper we present deoptimization grouping, an optimization using this property of the graal compiler to reduce the amount of meta data that must be stored by the vm without having to modify the vm. we compare our technique with existing meta data compression techniques from the hotspot virtual machine and study how well they combine. in order to make informed decisions about speculation meta data, we present an empirical analysis of the origin, impact and usages of this meta data. deoptimization is a concept used in modern vms that allows program execution to fall back from an optimized state to a less optimized state, eg, from compiled code to interpreted code. the ability to deoptimize the running program at almost any position allows the jit compiler of a vm to perform aggressive optimizations based on speculative assumptions. if those assumptions turn permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies bear this notice and the full citation on the rst page. copyrights for components of this work owned by others than acm must be honored. to copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speci. http: dx doi org year# out to be wrong later, the optimized compiled program falls back to an unoptimized interpreted execution or a baseline compiler. however deoptimization usually imposes memory costs because it require meta data to be stored alongside the optimized machine code. while virtual machines may encode this data in a way that minimizes these costs, we believe that compilers can also improve on the amount of meta data they handout to the vm. in this paper, we present deoptimization grouping, a vm independent compiler optimization that helps reducing the amount of generated deoptimization information without compromising any speculative optimizations performed by the compiler. we also want to gather empirical data on reduction of metadata overhead using our technique and using existing compression techniques from the hotspot vm. in particular, we want to see if both techniques can be combined constructively. we also collect empirical data about deoptimization information throughout the vm: its production by the compiler, its memory overhead while stored and nally its usage in the vm. to summarize, the contributions of this paper are: an analysis of the origin of deoptimization, its impact on associated deoptimization information and its usage in the java hotspot vm. a vm independent compiler optimization that reduces the amount of deoptimization information that needs to be stored by the vm. we propose a novel approach for composing multiple language implementations in a seamless way. foreign objects of one language can be used like regular objects in another language. however, multi language programs often suffer from poor performance, complex cross language interfaces, or insufficient flexibility. for accessing foreign objects we generate foreign language specific ir patterns that we insert into the ir of the host application. programs often consist of parts that are written in different languages because sub problems lend themselves to being implemented in a particular language. thus we avoid converting or marshalling foreign objects at the language border. our interoperability mechanism targets language implementations that run on the same vm and have the same style of intermediate representation, eg, an abstract syntax tree. our mechanism also allows the just in time compiler of the host vm to inline and optimize across language borders. ast specialization relies on optimistic assumptions and allows us to build inline caches for polymorphic function pointer calls, to profile runtime values and to potentially replace them with constants, or to speculatively remove code that was not executed yet. rather than producing a static build of aapplication, trufflec is a self optimizing abstract syntax tree interpreter combined with a just in time compiler. our self optimizing interpreter specializes the ast based on run time feedback. this evaluation showed that trufflec outperforms the code produced by industry standard compilers such as gcc or clang llvm. the evaluation of other benchmarks showed that the trufflec performance is on average only slower than the best performance out of the gcc and clang llvm performances. this paper presents trufflec, ainterpreter that allows the dynamic execution ofcode on top of a java virtual machine. the machine code uses dynamic deoptimization points at which the control switches back to the interpreter in case of a violated assumption. we evaluated trufflec using amicro benchmark in terms of peak performance. after ast specialization, the jit compiler translates the ast to highly optimized machine code. in this paper we present truf ec, ainterpreter written in java, which is based on the truf. truf ec is a self rewriting ast interpreter, ie, it replaces nodes and sub trees with specialized versions to perform high level optimizations based on optimistic assumptions derived from runtime feedback. function pointer inline caches: truf ec caches the targets of function pointer calls, speculates on the target being constant, and potentially inlines these functions. to the best of our knowledge, truf ec is the rst system that allows to runcode ef ciently atop of a jvm. other languages atop of the jvm can use truf ec to execute components of a user program that are written in, rather than using a foreign function interface. this paper explains truf ec using a smallapplication. the evaluation of this application in terms of peak performance shows that truf ec outperforms the code produced by industry standard compilers such as the gnucompiler or the clanglvm compiler. we also evaluate truf ec on the computer language benchmarks game. the evaluation on these independent benchmarks shows that truf ec is on average only slower than gcc or clang llvm and can even beat the industry standard compilers on selected benchmarks. we explain truf ecmemory model which allows us to exchange data with precompiled native libraries. source les are compiled to platform dependent object les which are subsequently combined permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies bear this notice and the full citation on the rst page. instead of creating machine code upfront, industry standard vms start interpreting this ir and compile frequently executed parts of the program at runtime to machine code, a process which is called just in time compilation a jit compiler can bene. from runtime information collected during the interpretation of the code, which is used to guide optimizations. value pro ling: truf ec pro les values of variables at runtime and potentially replaces them by constants if they do not change. jit compiler translates the asts of frequently executedfunctions to highly optimized machine code. the machine code contains deoptimization points that can invalidate the machine code and can switch execution back to the ast interpreter. in summary, this paper contributes the following: we describe the implementation of a portableinterpreter on top of the jvm using the truf. the benchmarks include examples where dynamic compilation has signi cant advantages compared to static compilation. is a statically typed language that is usually compiled ahead of time instead of being interpreted. copyrights for components of this work owned by others than acm must be honored. to copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speci. http: dx doi org year# hanspeterossenb ock johannes kepler university, austria moessenboeck ssw jku at by a so called linker producing executable machine code. static compilation does not allow the compiler to incorporate pro le information from the programexecution in order to do aggressive optimizations or to inline functions from dynamic link libraries. modern programming languages such as java follow a different approach: these languages allow the programmer to compile the source code to an intermediate representation, often in the form of bytecode. this ir is executed on top of a virtual machine. these optimizations include: pro le guided function inlining: truf ec pro les function calls and uses the pro le information to guide inlining at the ast level. inlining is even possible for functions that are contained in shared libraries. we build an inline cache for polymorphic function pointer calls at runtime, ie, we cache multiple targets for one call site. truf ec uses these deoptimization points for all cases where an optimistic specialization of an ast node would have to be reverted to its generic and unspecialized version. we show how we dynamically apply optimistic ast specializations while executing aprogram before we compile the ast to highly optimized machine code using the graal jit compiler. we present a benchmark evaluation that compares truf ec to industry standardcompilers in terms of peak performance. we present a novel approach for allowing javascript applications to accessdata structures without performance overhead or additional boiler plate code. dynamic languages such as javascript do not have a fixed memory layout for run time data nor do they allow low level memory accesses, which makes interoperability with languages such ashard. our approach allows javascript applications to transparently usepointers as receivers of object accesses or array accesses, thus the programmer can accessdata structures as if they were javascript objects. we describe how we modified an existing javascript interpreter so that it generates different access operations at run time depending on whether the receiver is a javascript object or apointer. we evaluated our prototype using benchmarks that measure array access performance. the evaluation of our javascript interpreter shows that usingarrays from within javascript is on average faster than using regular javascript arrays and faster than using typed arrays. xed memory layout for variables at run time. one possibility are typed arrays, which allow permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. typed arrays associate type information with the contents of a byte buffer and allow programmers to access this data in a typed way. an arraybuffer object represents a generic, xed length binary data buffer and cannot be accessed directly. the second typed array starts at offset and accesses the second member of thestruct. however, the eld alignment in astruct is platform dependent, hence precautions for padding differences are required. based interoperability mechanism that combines the javascript and theimplementations that already exist on top of truf e. we describe how a javascript programmer can accessarrays and structs from javascript transparently. our intuitive way of accessing struct members makes the error prone usage of multiple typed arrays on the same byte buffer super uous. in summary this paper contributes the following: we explain how a truf. based javascript interpreter can use apointer as the receiver of a property or element access and therefore transparently accessarrays and structures. we demonstrate that our approach is the fastest of these alternatives. javascript is a dynamically typed language lacking static type information, low level memory access and. however, javascript apis such as webgl, fileapi, filewriter, or xhr need high performance access to lowleveldata. or commercial advantage and that copies bear this notice and the full citation on the rst page. copyrights for components of this work owned by others than acm must be honored. to copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speci. http: dx doi org year# programmers to overcome the missing low level memory access in javascript. instead, typed arrays provide a view on them and associate types with the contents. for example, the typed array int array interprets the contents of an arraybuffer as a sequence of bit signed integers. by combining multiple views on one buffer, programmers can also allocate and access complex data structures such asstructs. for example, figure # shows how typed arrays allow programmers to allocate thestructure complex. the rst typed array starts at offset and has length. this array can access the rst member of thestruct complex. struct: struct complex; javascript: var buffer new arraybuffer; read structure varnew float array; varnew float array; access via or figure #: using astructure in javascript. typed arrays are certainly a big step towards interoperability between javascript and statically typed languages such as. a framework for implementing guest language interpreters, we can provide a more intuitive interoperability mechanism between javascript anddata. our mechanism allows a javascript application and aprogram to exchange arrays and structs via memory pointers. our technique allows the programmer to accessarrays like regular javascript arrays without the indirection via typed arrays. also, structures are accessed in the same way as regular javascript objects. thus, the difference between javascript data anddata becomes completely opaque to the programmer. based prototype shows that accessingdata via pointers in javascript is faster than the typed array approach and also more intuitive from the developerpoint of view. javascript implementation creates the access operations at runtime. we evaluate our approach by comparing it to accesses via regular javascript arrays and via typed arrays. many dynamic languages such as ruby, python and perl offer some kind of functionality for writing parts of applications in a lower level language such as. theseextension modules are usually written against the api of an interpreter, which provides access to the higher level languageinternal data structures. alternative implementations of the high level languages often do not support suchextensions because implementing the same api as in the original implementations is complicated and limits performance. in this paper we describe a novel approach for modular composition of languages that allows dynamic languages to supportextensions through interpretation. we propose a flexible and reusable cross language mechanism that allows composing multiple language interpreters, which run on the same vm and share the same form of intermediate representation in this case abstract syntax trees. this mechanism allows us to efficiently exchange runtime data across different interpreters and also enables the dynamic compiler of the host vm to inline and optimize programs across multiple language boundaries. we evaluate our approach by composing a ruby interpreter with ainterpreter. we run existing rubyextensions and show how our system executes combined ruby andmodules on average over faster than the conventional implementation of ruby with nativeextensions, and on average over faster than an existing alternate ruby implementation on the jvm calling compiledextensions through a bridge interface. we demonstrate that cross language inlining, which is not possible with native code, is performance critical by showing how speedup is reduced by around when it is disabled. self debugging system provides complete source level debugging with globally optimized code. again, the system provides expected behavior: it is possible to change a running program and immediately observe the effects of the change. it shields the debugger from optimizations performed by the compiler by dynamically deoptimizing code on demand. deoptimization only affects the procedure activations that are actively being debugged; all other code runs at full speed. deoptimization requires the compiler to supply debugging information at discrete interrupt points; the compiler can still perform extensive optimizations between interrupt points without affecting debuggability. at the same time, the inability to interrupt between interrupt points is invisible to the user. our debugging system also handles programming changes during debugging. dynamic deoptimization transforms old compiled code into new versions reflecting the current source level state. to the best of our knowledge, self is the first practical system providing full expected behavior with globally optimized code. but an interactive programming environment also demands rapid turnaround time and complete source level debugging. provide interpreter semantics at compiled code speed, combining expected behavior with global optimization. section # describes how optimized code can be deoptimized, and section # explains how running programs can be changed. section # relates this paper to previous work, and section # contains our conclusions. without aggressive procedure integration, for example, performance would be abysmal. most existing systems do not support the debugging of optimized code. programs can either be optimized for full speed, or they can be compiled without optimization for full source level debugging. recently, techniques have been developed that strive to make it possible to debug optimized code. however, none of these systems is able to provide full source level debugging. for example, it generally is not possible to obtain the values of all source level variables, to single step through the program, or to change the value of a variable. to the best of our knowledge, self is the first practical system providing full expected behavior with globally optimized code. compared to previous techniques, our use of dynamic deoptimization and interrupt points permits us to place fewer restrictions on the kind of optimizations that can be performed while still preserving expected behavior. the remainder of this paper is organized as follows. section # discusses the optimization performed by the self compiler and how they affect debugging. section # discusses the implementation of common debugging operations, section # discusses the benefits and limita tions of our approach, and section # examines its run time and space cost. to make self practical, the system must this work has been supported in part by the swiss national science foundation, an ibm graduate student fellowship, nsf presidential young investigator award ccr, and by sun, ibm, apple, cray, tandem, ti, and dec. permission to copy without fee all or part of this material is granted provided that the copies are not made or distributed for direct commercial advantage, the acm copyright notice and the title of the publication and its date appear, and notice is given that copying is by permission of the association for computing machinery. to copy otherwise, or to republish, requires a fee and or specific permission. optimization is given priority over debugging, and consequently these systems provide only restricted forms of debugging. self is a pure object oriented language designed for rapid prototyping, increasing programmer productivity by maximizing expressiveness and malleability. selfpure message based model of computation requires extensive optimization to achieve good performance. the serious bugs and security vulnerabilities facilitated byc lack of bounds checking are well known, yetandremain in widespread use. unfortunately, arbitrary pointer arithmetic, conflation of pointers and arrays, and programmer visible memory layout make retrofittingc with spatial safety guarantees extremely challenging. existing approaches suffer from incompleteness, have high runtime overhead, or require non trivial changes to thesource code. thus far, these deficiencies have prevented widespread adoption of such techniques. this paper proposes softbound, a compile time transformation for enforcing spatial safety of. inspired by hardbound, a previously proposed hardware assisted approach, softbound similarly records base and bound information for every pointer as disjoint metadata. this decoupling enables softbound to provide spatial safety without requiring changes tosource code. unlike hardbound, softbound is a software only approach and performs metadata manipulation only when loading or storing pointer values. a formal proof shows that this is sufficient to provide spatial safety even in the presence of arbitrary casts. softbound full checking mode provides complete spatial violation detection with runtime overhead on average. to further reduce overheads, softbound has a store only checking mode that successfully detects all the security vulnerabilities in a test suite at the cost of only runtime overhead on average. temporal memory safety errors, such as dangling pointer dereferences and double frees, are a prevalent source of software bugs in unmanaged languages such as. existing schemes that attempt to retrofit temporal safety for such languages have high runtime overheads and or are incomplete, thereby limiting their effectiveness as debugging aids. this paper presents cets, a compile time transformation for detecting all violations of temporal safety inprograms. inspired by existing approaches, cets maintains a unique identifier with each object, associates this metadata with the pointers in a disjoint metadata space to retain memory layout compatibility, and checks that the object is still allocated on pointer dereferences. a formal proof shows that this is sufficient to provide temporal safety even in the presence of arbitrary casts if the program contains no spatial safety violations. our cets prototype employs both temporal check removal optimizations and traditional compiler optimizations to achieve a runtime overhead of just on average. when combined with a spatial checking system, the average overall overhead is for complete memory safety. unmanaged languages such asc are the defacto standard for implementing operating systems, virtual machine monitors, language runtimes, database management systems, embedded software, and performance critical software of all kinds. such languages provide low level control of memory layout, explicit memory management, and proximity to the underlying hardware. however, all of this control comes at a price lack of bounds checking leads tobufferover ows and manual memory management leads to dangling pointer and double free errors. both types of memory errors can result in crashes, silent data corruption, and severe security vulnerabilities. recognizing the gravity of the problem, there have been many proposals for detecting or preventing one or both kinds of errors. this paper focuses on debugging tools for runtime prevention of temporal safety violations temporal safety errors include: dangling pointer dereferences, double free on the same object multi permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies bear this notice and the full citation on the rst page to copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speci. int, int; malloc; void foo free; int main figure #. dangling pointer errors involving the heap and stack. the memory pointed to bycould be reallocated by any subsequent call to malloc. on the right, foo assigns the address of stackallocated variable a to global variable. after foo returns, its stack frame is popped, therebypoints to a stale region of the stack, which anyintervening function call could alter. ple times, and invalid frees with a non heap addressor pointertothe middleofa heap allocated region. figure shows two examples of common kinds of temporal memory safety errors, including a dangling reference to a re allocated heap locations and a dangling pointer to the stack. although there has been considerable effort in detecting temporal errors, challenges remain. for example, consider the widely usedvalgrind memcheck tool. although an important debugging aid, memcheckfails to detect dangling pointers to reallocated data locations, and it exhibits runtime overheads in excess of, partly due to its use of dynamic binary instrumentation. other approaches modify malloc to allocate only one object per page and unmap the page at deallocation time, thus using the processorvirtual address translation hardware to detect dangling pointers dereferences. for programs with manysmall objects, this approach can in ate memory use dramatically. recent work has reduced physical memory usage, but such approachesdo not detect dangling references to stack locations, and the system calls per allocation deallocation can result in signi cant runtime overheads for programs that frequently allocate memory. conservativegarbage collection side steps this problem for heap allocations, however it also fails to detect dangling pointers to the stack, and it is not suitable for all applications domains. furthermore, it typically masks such errors, which is less useful in the context of a debugging tool. overall, prior proposals suffer from one or more of the following de ciencies: high runtime overheads, high memory overheads, failure to detect all temporal errors, requiring annotations inserted by the programmer, or altering memory layout. these drawbacks have typically led developers to employ such techniques selectively rather than using them by default throughout the software development and testing process. our proposal, cets, is built upon the hypothesis that compiler based instrumentation and ef cient metadata structures can yield a low overhead and highly compatible system for detecting all violations of temporal safety. cets addresses the above de ciencies through a synergistic combination of two existing techniques. first, cets uses an identi er based scheme, which assigns a unique key for each allocation region to identify dangling pointers. second, this per pointer metadata is tracked using a disjoint shadowspace, yielding high compatibility because memory layout is unchanged. such shadowspace approaches for tracking per pointer metadata have been applied previously in the context of spatial safety. we demonstrate the correctness of this approach by describing a machine checked formal proof that cets instrumented programs detect all temporal errors fora small, but realistic, fragmentofc. our experiments show that such static optimizations reduce the number of checks by on average. the combination of these optimizations and standard optimizations applied after instrumentation results in a runtime overhead of on average for a set of spec benchmarks. furthermore, when coupled with our prior work on spatial safety, the average runtime overhead is for detecting all spatial and temporal errors. to explore the design alternatives, we compare cets temporal checking to an allocation shadow bits scheme that is similar to the best effort temporal checking performedbyvalgrindmemcheck, but implemented within the compiler rather than by binary instrumentation. although the approach has lower overhead than when implemented using binary instrumentation, it is less complete and has higher runtime overhead than cets. these results show the effectiveness of compiler based instrumentation and optimization for creating checking tools with ef ciencyand compatibility suf cient for use in all stages of the software development life cycle. for our cets prototype implementation, we developed several simple temporal check elimination optimizations. on the left, freeingcausesto become a dangling pointer. languages such asanduse unsafe manual memory management, allowing simple bugs to become the root cause of exploitable security vulnerabilities. this paper proposes watchdog, a hardware based approach for ensuring safe and secure manual memory management. inspired by prior software only proposals, watchdog generates a unique identifier for each memory allocation, associates these identifiers with pointers, and checks to ensure that the identifier is still valid on every memory access. this use of identifiers and checks enables watchdog to detect errors even in the presence of reallocations. watchdog stores these pointer identifiers in a disjoint shadow space to provide comprehensive protection and ensure compatibility with existing code. to streamline the implementation and reduce runtime overhead: watchdog uses micro ops to access metadata and perform checks, eliminates metadata copies among registers via modified register renaming, and uses a dedicated metadata cache to reduce checking overhead. furthermore, this paper extends watchdog mechanisms to detect bounds errors, thereby providing full hardware enforced memory safety at low overheads. languages such asandare the gold standard for implementing low level systems software such as operating systems, virtual machine monitors, language runtimes, embedded software, and performance critical software of all kinds. although safer languages exist, these low level languages persist partly because they provide low level control over memory layout and use explicit manual memory management. unfortunately, the unsafe attributes of these languages result in nefarious bugs that cause memory corruption, program crashes, and serious security vulnerabilities. this paper focuses primarily on eliminating memory corruption and security vulnerabilities caused by one speci. aspect of low level languages: memory deallocation errors, which directly result in dangling pointer dereference bugs this research was funded in part by the. the views and conclusions contained in this document are those of the authors and should not be interpreted as representing the of cial policies, either expressed or implied, of the. this research was funded in part by darpa contract hr, onr award, and nsf grants cns year#, ccf year#, and ccf. dangling pointer errors involving the heap and stack. on the left, freeingcausesto become a dangling pointer. on the right, foo assigns the address of stack allocated variable a to global variable. after foo returns, its stack frame is popped, andpoints to a stale region of the stack, which any intervening function call could alter. in both cases, dereferencingcan result in garbage values or data corruption. in essence, we seek to enforce safe manual memory management and thereby eliminate an entire class of security vulnerabilities and uncaught memory corruption bugs. figure # shows two use after free errors, including a dangling reference to a reallocated heap location and a dangling pointer to the stack. use after free errors have proven to be just as severe and exploitable as buffer over ow errors: they too potentially allow an attacker to corrupt values in memory, inject malicious code, and initiate return to libc attacks. use after free vulnerabilities have been used in real world attacks, and many such vulnerabilities in mainstream software include cve year# in microsoftinternet explorer, cve year# year# in applesafari and googlechrome browsers, and cve year# year# in mozillafirefox browser. the number of use after free vulnerabilities reported has been increasing in recent years, in contrast with the decline in buffer over ow vulnerabilities reported. the fundamental cause of use after free vulnerabilities is that programming languages providing manual memory management do not ensure that programmers use those features safely. unfortunately, the commonly advocated alternative developing software in garbagecollected languages is not always easily applicable in all domains where real time response or low level control over memory is required. porting legacy code to these safer languages is not always cost effective, and using conservative garbage collection is not always feasible due to pause times and observed memory leaks in long running software. given their importance, there has been increased effort in detecting these use after free errors, but signi cant challenges remain. one approach is to randomize the location of heap objects to probabilistically transform dangling pointer dereferences into hard to exploit non deterministic errors. although useful for mitigating some use after free exploits, such approaches fail to detect use after free errors on the stack and suffer from locality destroying memory fragmentation. other approaches seek to detect errors by tracking the allocation deallocation status of regions of memory. alternative approaches track and check unique identi ers either completely with software or with hardware acceleration. in general, prior approaches generally suffer from one or more of the following issues: failure to detect all use after free errors, incompatibilities, require signi cant changes to the tool chain, high memory overheads, or high performance overheads. such overheads typically limit the use of software only approaches to only debugging contexts rather than being used all the time in deployed code. given that manual memory management in low level languages likeis still ubiquitous, we seek a highly compatible means of eliminating use after free vulnerabilities completely with low enough overheads to be used all the time. this paper proposes watchdog, a hardware proposal that enforces safe and secure manual memory management even in the presence of reallocations. the watchdog hardware performs the majority of the work, relying on the software runtime to inform it about memory allocations and deallocations. watchdog associates a unique identi er with every memory allocation, and it marks the identi er as invalid on memory deallocations. for pointers resident in memory, these identi ers are maintained in a disjoint metadata space. watchdog performs use afterfree checks to ascertain that the identi er associated with the pointer is still valid before every memory access. as identi ers are never reused, watchdog detects all use after free errors even in the presence of reallocations. the watchdog hardware employs several optimizations to reduce the performance penalties of identi er based checking. second, watchdog uses an identi er metadata encoding that reduces the validity check to a single load and compare op. third, watchdog identi es memory operations that load or store pointers conservatively in unmodi ed binaries or more precisely using isa assisted identi cation, which allows the compiler to annotate loads and stores of pointers. fourth, the hardware uses copy elimination via register remapping to eliminate metadata copies within the core. performance measurements of a simulated processor on twenty benchmarks indicate that the runtime overhead is on an average for detecting all use after free errors. furthermore, this paper shows that the basic mechanisms in watchdog are easily extended to include pointer based bounds checking in hardware, further supporting the applicability and utility of the approach. many of the same optimizations apply directly, resulting in a system with average performance overhead that enforces full memory safety and thus provides comprehensive prevention of all use after free and buffer over ow vulnerabilities. the memory pointed to bycould be reallocated by any subsequent call to malloc. watchdog builds upon prior proposals for identi er based use after free checking using disjoint metadata. every pointer has an associated identi er that is propagated on pointer operations. first, watchdog uses micro op injection to perform metadata propagation and checking. lack of memory safety inis the root cause of a multitude of serious bugs and security vulnerabilities. numerous software only and hardware based schemes have been proposed to enforce memory safety. among these approaches, pointer based checking, which maintains per pointer metadata in a disjoint metadata space, has been recognized as providing comprehensive memory safety. software approaches for pointer based checking have high performance overheads. in contrast, hardware approaches introduce a myriad of hardware structures and widgets to mitigate those performance overheads. this paper proposes watchdoglite, an isa extension that provides hardware acceleration for a compiler implementation of pointer based checking. this division of labor between the compiler and the hardware allows for hardware acceleration while using only preexisting architectural registers. by leveraging the compiler to identify pointers, perform check elimination, and insert the new instructions, this approach attains performance similar to prior hardware intensive approaches without adding any hardware structures for tracking metadata. andare the languages of choice for implementing infrastructure code and all kinds of low level software. such languages remain in common usage both for legacy reasons and because they provide low level access to underlying hardware, explicit control over memory management, and high performance. however, a longstanding problem with code written inc is the lack of memory safety: accessing beyond the bounds and accessing unallocated deallocated memory locations. the lack of memory safety causes simple programming errors to become the root cause of a multitude of memory corruption bugs and security vulnerabilities. permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies bear this notice and the full citation on the rst page. copyrights for components of this work owned by others than the author must be honored. to copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speci. cgo february year#, orlando, fl, usa copyright is held by the owner authors. martin steve zdancewic university of pennsylvania milom cis upenn edu stevez cis upenn edu ef ciently and comprehensively detecting and protecting against memory safety violations is unsurprisingly a well researched topic with numerous proposals over the years. these include both software only tools and hardware instantiations. beyond academia, recent tools from industry such as googleaddress sanitizer in the llvm compiler and intelpointer checker compiler, patent application, and recently an nounced mpx isa extensions illustrate the importance of detecting memory safety violations. these proposals make tradeoffs along the dimensions of performance, protection, and compatibility with existing applications. szekeres et al sur veyed the entire space of memory safety vulnerabilities and enforcement mechanisms and identi ed pointer based checking as the only approach to provide comprehensive and non probabilistic detection of memory safety vulnerabilities. pointer based checking gives every pointer a view of memory that it can legally access by maintaining per pointer metadata. the per pointer metadata is prop agated on pointer operations. comprehensive memory safety requires detecting both spatial violations and temporal violations. temporal violations may be detected using unique identi er based checking on memory accesses or by invalidating the bounds of all pointers to an object when deallocating the object so that subsequent bounds checks will fail. pointer based checking can be implemented in various parts of the system stack via source code rewriting, the compiler, and or in hardware. recent compiler based implementations have reduced the performance overhead for comprehensive memory safety to approximately on average. these overheads are attained by instrumenting optimized code and using information available to the compiler. unfortunately, this overhead is likely still too large for production use. as a consequence, researchers have proposed using hardware to accelerate pointer checking, but these hardware proposals including watchdog, our own prior proposal introduce signi cant hardware complexity and require various hardware structures dedicated to recording metadata state. see section # for a comparison of these strategies. this paper proposes watchdoglite, an isa extension to accelerate pointer based checking without adding any new hardware for maintaining metadata state. the proposed instructions accelerate the three key memory safety checking operations: loading and storing metadata, bounds checking, and use after free checking. the instructions operate on the isapreexisting architectural registers. the compiler explicitly inserts these instructions, uses preexisting static optimizations to eliminate many checks, and performs in register metadata propagation by copy elimination and standard register allocation. relying on the compiler to perform these tasks largely eliminates the need for various previously proposed dedicated hardware structures that track and cache metadata. experiments based on extensions to our softbound cets compiler instrumentation show that the performance overhead for enforcing comprehensive memory safety is reduced on average from to. this overhead is similar to prior hardware schemes, which use extensive hardware structures to track and propagate metadata state, which indicates that the proposed isa extension is a more pragmatic approach for hardware acceleration of memory safety enforcement than prior hardware centric proposals. concurrent with this work, intel developed memory protection extensions and released the isa speci cation in year#. the work described in this paper was largely completed in year#. the watchdoglite isa exten sions described in this work and intelmpx are similar in many ways, including: using pointer based checking with disjoint metadata, adding new instructions for ef ciently accessing the metadata shadow space, and adding instruction for accelerating bounds checking. one difference is that mpx does not include support for accelerating use after free checking. the differences and similarities are discussed further in section #. prior proposals for detecting memory safety violations provide a wide spectrum of protection ranging from partial countermeasures to comprehensive memory safety. to retain memory layout compatibility, some proposals place this per pointer metadata in a disjointmetadata space. conceptually, every pointer dereference is checked using its metadata. to detect spatial safety violations, base and bounds metadata is maintained with each pointer. pointer metadata propagation with pointer arithmetic, metadata propagation through memory with metadata lookups on loads, metadata lookups with pointer stores, pointer metadata creation on memory allocations, identi er metadata being invalidated on memory deallocations, lock and key checking using identi er metadata, and spatial check performed using bounds metadata. this article describes ccured, a program transformation system that adds type safety guarantees to existingprograms. ccured attempts to verify statically that memory errors cannot occur, and it inserts run time checks where static verification is insufficient ccured extendstype system by separating pointer types according to their usage, and it uses a surprisingly simple type inference algorithm that is able to infer the appropriate pointer kinds for existingprograms. ccured uses physical subtyping to recognize and verify a large number of type casts at compile time. additional type casts are verified using run time type information. ccured uses two instrumentation schemes, one that is optimized for performance and one in which metadata is stored in a separate data structure whose shape mirrors that of the original user data. this latter scheme allows instrumented programs to invoke external functions directly on the program data without the use of a wrapper function we have used ccured on real world security critical network daemons to produce instrumented versions without memory safety vulnerabilities, and we have found several bugs in these programs. the instrumented code is efficient enough to be used in day to day operations. permissions may be requested from publications dept, acm, inc, year# broadway, new york, ny year# usa, fax: or permissions acm org. year# acm the program, essentially by enforcing a strong type system. ccured is a program transformation system that adds memory safety guarantees toprograms. it rst attempts to nd a simple proof of memory safety for this research was supported in part by the national science foundation grants ccr, ccr, ccr, ccr, ccr, ccr, and gifts from microsoft research. the information presented here does not necessarily re ect the position or the policy of the government and no of cial endorsement should be inferred. authors addresses: electrical engineering and computer science dept, soda hall, university of california, berkeley, berkeley, ca year#; email: cs berkeley edu. permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or direct commercial advantage and that copies show this notice on the rst page or initial screen of a display along with the full citation. copyrights for components of this work owned by others than acm must be honored. to copy otherwise, to republish, to post on servers, to redistribute to lists, or to use any component of this work in other works requires prior speci. then, the portions of the program that do not adhere to the ccured type system are checked for memory safety at run time. since ccured enforces memory safety, which is an implicit requirement of everyprogram, it is a good debugging aid. we were able to nd several bugs in the spec benchmark suite and in network daemons by running the instrumented programs on their own test suites. memory safety is also bene cial in extensible systems, such as the apache web server or an operating system kernel, which support pluggable modules and device drivers. by instrumenting modules with ccured, the failure of an individual component cannot contaminate the system as a whole. perhaps the greatest potential impact of ccured is in the domain of securitycritical software. memory safety is an absolute prerequisite for security, and it is the failure of memory safety that is most often to blame for insecurity in deployed software. further, ccuredrelatively modest performance cost makes it plausible for security critical production systems to use binaries compiled with ccuredrun time checks enabled. the work described in this article is based on two main premises. first, we believe that, even in programs written in unsafe languages like, a large part of the program can be veri ed as type safe at compile time. the remaining part of the program can be instrumented with run time checks to ensure that the execution is memory safe. the second premise of our work is that, in many applications, some loss of performance due to run time checks is an acceptable price for type safety, especially when compared to the alternative cost of redesigning the system in a type safe language. the main contribution of this article is the ccured type system, a re nement of thetype system with separate pointer kinds for different pointer usage modes. in a typicalprogram, ccured discovers that most pointers are used safely, requiring just a null check before dereference. they are as cheap to use as a reference in a type safe language such as java. for other pointers, ccured discovers that they are involved in pointer arithmetic and thus require bounds checks before dereference. finally, some pointers are involved in type casts that prevent ccured from tracking the type of the referenced data at compile type. for these wild pointers, ccured adds both bounds checking and run time type checking, in a manner similar to references in a dynamically typed language like lisp. in general, the ccured type system is similar to lisp or scheme soft typing. ccured treatsas a dynamically typed language but optimizes away most of the run time checks and the state needed to make such checks by recognizing most pointers as safe rather than seq or wild. since scheme andare very different, we introduce a novel types and a new inference algorithm to achieve this goal. ccured can type check and instrument programs annotated with pointer quali ers. since the ccured typing rules are very close to those of, we believe that it would be easy forprogrammers to use ccuredtype system in newly written programs. however, it is impractical to make pervasive changes in large existing programs. to address this problem, we designed a pointer kind inference algorithm that performs a simple linear time whole program analysis to discover the best pointer quali er for each pointer in the program. speci cally, our algorithm chooses a set of pointer quali ers that minimize run time overhead while still providing memory safety guarantees. an early version of ccured, including only the pointer quali ers described above, was already usable on existingprograms. however, we discovered that there were some serious usability problems that made it dif cult to apply ccured to system software and to large security critical network daemons. the major problem was due to incompatibilities between the ccured representation of types and the ordinaryrepresentation used by precompiled libraries. one notable example is the multiword representation of the ccured seq and wild pointers, which contain additional information necessary for performing the run time checks. also, objects referenced by wild pointers must contain tags used to perform ccuredrun time checks, which makes the problem of library compatibility especially challenging in the presence of wild pointers. even a small number of casts that ccured considers bad can result in a large number of wildpointers, because any pointer that is obtained from a wildpointer through assignment or dereference must be wild as well. we designed a three point solution to alleviating the incompatibility problem. first, we observed that in the presence of structures and arrays, most type casts could be classi ed as either upcasts or downcasts. to avoid treating these casts as bad, and thus to reduce the number of wild pointers, we extended the ccured type system with a physical subtyping mechanism for handling the upcasts and with a special kind of pointer that carries run time type information for handling the downcasts. these two mechanisms, described in detail in section #, allow ccured to handle object oriented techniques such as subtyping polymorphism, dynamic dispatch, and checked downcasts, which are surprisingly common in largeprograms. second, we developed a notation that allows a programmer to specify the conversions and run time checking operations that must occur at the boundary between the code processed with ccured and precompiled libraries. in section #, we describe our technique for automatically instantiating userspeci ed wrappers in many contexts. finally, to address the remaining compatibility problems, we devised a new representation for wide pointers in which ccuredmetadata is not interleaved with the program data. rather, the metadata is stored in a separate data structure whose shape mirrors that of the program data itself. this separation incurs a slight performance penalty due to lost locality and to an increase in the overall amount of metadata; thus, the ccured inference algorithm has been extended to limit the use of this new representation to those types where it is required in order to preserve both soundness and compatibility. this mechanism is described in more detail in section #. even with ccuredsimple and intuitive type system, we can limit the use of expensive pointer kinds to a relatively small number of pointers. in most programs, static counts indicate that less than of all the pointers in the program are wildand that less than of all pointers in the program are seq. in addition, we have produced ccured transformed versions of several popular network servers. we have veri ed that ccured prevents known security exploits, and most importantly, we have produced memory safe versions of these applications that should eliminate any further vulnerabilities due to memory safety violations. we describe our experience using ccured for these applications in section #. perhaps if these instrumented binaries saw wide adoption we might see an end to the cycle of vulnerability reports and patches that has become all too common with security critical infrastructure software. the rest of this article is organized as follows. we start with a description of the ccured type system and instrumentation in section #. in section # we re ne this type system with the notion of physical subtyping and pointers with run time type information. in section # we describe formally the invariants that are maintained by the typing rules and we state the type soundness theorem. in section # we describe informally the handling of additionalprogramming constructs, and in section # we describe the mechanisms used for ensuring compatibility with existing libraries. section # gives an overview of the work involved in applying ccured to a typicalprogram. then, section # shows the performance of ccured instrumented programs; in addition, we discuss bugs we found and techniques we applied. finally, we compare ccured with related work in section #, and present our conclusions in section #. several existing dynamic binary analysis tools use shadowmemory they shadow, in software, every byte of memory used by a program with another value that says something about it. shadow memory is difficult to implement both efficiently and robustly. nonetheless, existing shadow memory implementations have not been studied in detail. this is unfortunate, because shadow memory is powerful for example, some of the existing tools that use it detect critical errors such as bad memory accesses, data races, and uses of uninitialised or untrusted data. in this paper we describe the implementation of shadow memory in memcheck, a popular memory checker built with valgrind, a dynamic binary instrumentation framework. this implementation has several novel features that make it efficient: carefully chosen data structures and operations result in a mean slow down factor of only and moderate memory usage. this may sound slow, but we show it is times faster and times smaller on average than a naive implementation, and shadow memory operations account for only about half of memcheck execution time. equally importantly, unlike some tools, memcheck shadow memory implementation is robust: it is used on linux by thousands of programmers on sizeable programs such as mozilla and openoffice, and is suited to almost any memory configuration. this is the first detailed description of a robust shadow memory implementation, and the first detailed experimental evaluation of any shadow memory implementation. the ideas within are applicable to any shadow memory tool built with any instrumentation framework. they analyse a client program at the level of machine code as it runs. this is also the rst detailed description of any robust shadow memory implementation. this paper describes how to create dynamic analysis tools that use shadow memory tools that shadow every byte of memory used by a program with another value, in software that are both ef cient and robust. permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies bear this notice and the full citation on the rst page. to copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speci. what is shadow memory programming tools such as pro lers and checkers make programming easier and improve software quality. dynamic binary analysis tools are one class of such tools. they can be built from scratch, but nowadays are usually implemented using a dynamic binary instrumentation framework such as pin or valgrind. this paper focuses on a class of dba tools that use shadow memory, ie, they shadow, in software, every byte of memory used by a program with a shadow memory value that says something about it. we call these tools shadow memory tools ashadow memory value may describe the value within a memory location, or it may describe the memory location itself. the analysis code added by the tool updates the shadow memory in response to memory accesses, and uses the shadow memory to report information to the programmer. the granularity of the shadowing can vary, but usually every used memory byte or word has a shadow memory value, and each shadow memory value may itself be one bit, a few bits, one byte, or one word, for example. some tools that use shadow memory also shadow every register with an extra value. shadow registers are challenging to implement in their own right but their implementation details are beyond the scope of this paper. shadow memory is useful shadow memory lets a tool remember something about the history of every memory location and or value in memory. consider the following motivating list of shadow memory tools; the descriptions are brief but demonstrate that shadow memory is powerful, and can be used in a wide variety of ways. it remembers what allocation deallocation operations have affected each memory location, and can thus detect accesses of unaddressable memory. it also remembers which values are unde ned and can therefore detect dangerous uses of unde ned values. it remembers which values are from untrusted sources and which values were subsequently derived from them, and can thus detect dangerous uses of tainted values. it remembers which locks are held when each memory location is accessed, and can thus detect when a memory location is accessed without a consistent lock set, which may imply a data race. drd is another race detector that uses a different race detection algorithm. it remembers what operations have been performed on each value, and can thus detect any later operations that are inappropriate for a value of that type. it remembers which values are array pointers, and can thus detect bounds errors. it remembers which operation created each value, and its inputs, and records these in a dynamic data ow graph which can be viewed at program termination. pinsel automatically extracts system call side effects from benchmarks so that architectural simulators do not have to emulate system calls when running those benchmarks. it shadows each memory location with a copy of itself, and does a memory diff between original and shadow memory values after each system call executes in order to determine how the system call affected memory. all of these tools rely crucially on shadow memory. eraser, drd and pinsel use shadow memory but not shadow registers, the others use both shadow memory and shadow registers. the shadow memory is implemented entirely in software and so these tools run on stock hardware. shadow memory is hard to implement well speed. the speed of a shadow memory implementation is important. although programmers will use slow tools if the bene ts are high enough, they prefer fast tools. large amounts of extra state must be maintained; one shadow byte per byte of live original memory is typical. most or all loads and stores must be instrumented to keep the shadow memory state up to date, as must operations that affect large regions of memory, such as allocations and deallocations, reads writes of large areas by system calls, and the loading of the program image into memory at start up. these requirements unavoidably increase the total amount of code that is run, increase a programmemory footprint, and degrade the locality of its memory accesses. shadow memory tools thus typically slow down programs by a factor of, and shadow memory operations cause much more of this slow down than other well studied aspects of tools built with dbi frameworks such as hot trace formation and code cache management. the robustness of a shadow memory implementation is also important, arguably even more so than its speed. realworld tools must cope with large, uncooperative programs, and if they are to be portable, cannot rely on particular operating system characteristics such as memory layouts. the shadow memory must be squeezed into the address space alongside the original memory in a way that does not con ict with it and does not change the programbehaviour. this requires considerable exibility in the shadow memory structure and layout. it also unavoidably reduces the amount of address space a program can use itself, which is an important issue on embedded platforms and even bit machines. obviously, this becomes less of an issue if shadow memory can be made smaller, so compact shadow memory is desirable. in summary, we want shadow memory to be: fast; structured exibly; compact. not surprisingly, these desires con ict and we will see that trade offs must be made. contributions in this paper we make four contributions. the rst three arise because we delve more deeply into the topic of shadow memory than previous publications have. these aspects are more important for lightweight tools where the cost of analysis is small relative to the cost of running the original code. memcheck is a widely used tool, and this is the rst detailed description of its shadow memory implementation. previous publications have discussed in detail every signi cant aspect of memcheck except its shadow memory implementation. first detailed description of any robust shadow memory implementation. this is more important than it may seem, because shadow memory is a topic where details matter. high level descriptions are not suf cient; lowerlevel implementation details such a data representations are crucial, as they make the difference between a toy and a real world tool. most published descriptions of shadow memory implementations have been minimal, and the three that have been discussed in detail are not robust enough, in our opinion, for use in a widely used tool like memcheck. this is the rst paper that has evaluated and compared multiple versions of a shadow memory implementation. the fourth and nal contribution advances the state of the art in shadow memory implementations. memcheckbasic shadow memory data structure is similar to that used in several other shadow memory tools. however, memcheck adds several novel optimisations that speed up common cases, and compress shadow memory at coarse grained and negrained levels. together they reduce memcheckmean slow down factor by and shrink its mean shadow memory size by a factor of over a naive implementation. the reduction in shadow memory size also improves robustness because it allows programs with larger memory footprints to be run in the same amount of address space. although the paper is centred around the implementation of memcheck, the ideas within are general and apply to any shadow memory tool implemented with any framework. paper structure this introduction has discussed several aspects of shadow memory: what it is, that it is useful and used in several existing tools, that it is dif cult to implement well, and that it has not been studied closely. section # describes the most basic form of memcheckshadow memory implementation, and section # describes the optimisations that improve its performance to an acceptable level. section # evaluates memcheckrobustness, speed and memory usage. finally, section # discusses related work and section # describes future work and concludes. debugging support for highly optimized execution environments is notoriously difficult to implement. the truffle graal platform for implementing dynamic languages offers an opportunity to resolve the apparent trade off between debugging and high performance. truffle graal implemented languages are expressed as abstract syntax tree interpreters. they enjoy competitive performance through platform support for type specialization, partial evaluation, and dynamic optimization deoptimization. a prototype debugger for ruby, implemented on this platform, demonstrates that basic debugging services can be implemented with modest effort and without significant impact on program performance. prototyped functionality includes breakpoints, both simple and conditional, at lines and at local variable assignments. the debugger interacts with running programs by inserting additional nodes at strategic ast locations; these are semantically transparent by default, but when activated can observe and interrupt execution. by becoming in effect part of the executing program, these wrapper nodes are subject to full runtime optimization, and they incur zero runtime overhead when debugging actions are not activated. conditions carry no overhead beyond evaluation of the expression, which is optimized in the same way as user code, greatly improving the prospects for capturing rarely manifested bugs. when a breakpoint interrupts program execution, the platform automatically restores the full execution state of the program, as if running in the unoptimized ast interpreter. this then allows full introspection of the execution data structures such as the ast and method activation frames when in the interactive debugger console. our initial evaluation indicates that such support could be permanently enabled in production environments. although debugging and code optimization are both essential to software development, their underlying technologies typically con ict. deploying them together usually demands compromise in one or more of the following areas: performance: static compilers usually support debugging only at low optimization levels, and dynamic compilation may also be limited. functionality: years of research on the topic have most often given priority to optimization, resulting in debugging services that are incomplete and or unreliable. complexity: debuggers usually require compiler support, in particular the generation of additional information the debugger might need when deciphering execution state. this strategy can strongly couple their respective implementations. inconvenience: putting a system under observation by a debugger requires some form of debug mode, for example using the xdebug option when starting the java virtual machine. as a consequence, debugging is seldom enabled in production environments. defects that arise must be investigated in a separate development environment that di ers enough from production that reproducing the issue may be hard. the vm research group at oracle labs proposes to eliminate this con ict in optimized dynamic runtimes by making production quality code debug aware without adding overhead. a newly developed platform for constructing high performance implementations of dynamic languages. based language implementation is expressed as an abstract syntax tree oracle and java are registered trademarks of oracle and or its. other names may be trademarks of their respective owners. interpreter, to which the framework applies aggressive dynamic optimizations including type specialization, inlining, and many other techniques. the grouprecently developed implementation of ruby has already shown promising results and is now being integrated with the existing implementation of ruby on the jvm, jruby. as part of a larger inquiry into techniques for adding developer tool support to tru, the ruby ast was experimentally extended to include support for a simple yet useful debugger, as well as for rubybuilt in tracing facility. both extensions exhibit essentially zero runtime overhead until enabled, at which time the debugging tracing logic accrues overhead proportional to the speci. this strategy was rst explored for the self debugger, where debugging support is tightly integrated with execution machinery. a signi cant consequence of this strategy is that the representation of logic implementing debugging functionality becomes indiscernible from the representation of ordinary application code and thus subject to all the optimization capabilities the vm. the next section describes the background for this experiment in more detail: the underlying tru. based implementation of ruby, the combination of ruby tru. in section #, we introduce our use of ast wrapper nodes in the debugger. section # gives details about the implementation in the tru. framework, and about the mechanisms of the underlying vm including the graal compiler that it uses. in section #, we discuss our implementation in comparison to alternatives, in terms of impact on peak performance. sections and discuss related work and conclude the paper. java virtual machines are optimized for performing well on traditional java benchmarks, which consist almost exclusively of code generated by the java source compiler. code generated by compilers for other languages has not received nearly as much attention, which results in performance problems for those languages. one important specimen of another language is scala, whose syntax and features encourage a programming style that differs significantly from traditional java code. it suffers from the same problem its code patterns are not optimized as well as the ones originating from java code. jvm developers need to be aware of the differences between java and scala code, so that both types of code can be executed with optimal performance. this paper presents a detailed investigation of the performance impact of a large number of optimizations on the scala dacapo and the java dacapo benchmark suites. it describes the optimization techniques and analyzes the differences between traditional java applications and scala applications. we performed these experiments on the work in progress graal compiler. graal is a new dynamic compiler for the hotspot vm which aims to work well for a diverse set of workloads, including languages other than java. the results help compiler engineers in understanding the characteristics of scala. the java virtual machine was originally developed as the target machine for the java language. however, it soon became apparent that the virtual machine is useful as a target for other languages as well. current versions of the jvm speci cation explicitly mention that java is not the sole language to be compiled to java bytecode. scala and clojure are examples of language implementations that run directly on top of the jvm without additional infrastructure, while language implementations like jruby, jython or rhino rely on a signi cant amount of additional infrastructure. their development and maintenance includes a tremendous amount of. ort, however, focuses almost entirely on the performance of certain types of applications: small number crunching applications, tools, enterprise level server applications, or combinations thereof. all of these benchmarks almost exclusively run code written in java. while users of jvms want to know the ideal jvm con guration for their application, a compiler engineer needs to understand which parts of the compiler, which optimizations, contribute most to the overall performance of an application. while there are attempts to analyze the in uence of optimizations on java code, there are no detailed analyses about the performance impact of optimizations on non java application code. our work addresses this de ciency by providing a thorough analysis of the performance impact of a selected suite of optimizations. this analysis was performed on both the java dacapo and the scala dacapo benchmark suites, in order to compare the characteristics of java and non java code. the fact that both benchmark suites use the same underlying infrastructure helps minimize outside. this paper provides detailed accounts of the results of the analysis, along with a description of how to replicate them. it discusses the results for the scala dacapo benchmarks in detail. it is also intended to solicit input from the scala community on the types of scala workloads the graal compiler should be optimized for. production quality virtual machines are heavily optimized pieces of software. escape analysis allows a compiler to determine whether an object is accessible outside the allocating method or thread. this information is used to perform optimizations such as scalar replacement, stack allocation and lock elision, allowing modern dynamic compilers to remove some of the abstractions introduced by advanced programming models. the all or nothing approach taken by most escape analysis algorithms prevents all these optimizations as soon as there is one branch where the object escapes, no matter how unlikely this branch is at runtime. this paper presents a new, practical algorithm that performs control flow sensitive partial escape analysis in a dynamic java compiler. it allows escape analysis, scalar replacement and lock elision to be performed on individual branches. we implemented the algorithm on top of graal, an open source java just in time compiler, and it performs well on a diverse set of benchmarks. in this paper, we evaluate the effect of partial escape analysis on the dacapo, scaladacapo and specjbb benchmarks, in terms of run time, number and size of allocations and number of monitor operations. it performs particularly well in situations with additional levels of abstraction, such as code generated by the scala compiler. it reduces the amount of allocated memory by up to, and improves performance by up to. state of the art virtual machines employ techniques such as advanced garbage collection, alias analysis and biased locking to make working with dynamically allocated objects as. but even if allocation is cheap, it still incurs some overhead. even if alias analysis can remove most object accesses, some of them cannot be removed. and although acquiring a biased lock is simple, it is still more complex than not acquiring a lock at all. escape analysis can be used to determine whether an object needs to be allocated at all, and whether its lock can ever be contended. this can help the compiler to get rid of the objectallocation, using scalar replacement to replace the object. escape analysis checks whether an ob ject escapes its allocating method, ie, whether it is accessible outside this method. an object escapes, for example, if it is assigned to a static eld, if it is passed as an argument to another method, or if it is returned by a method. in these cases the object needs to exist on the heap, because it will be accessed as an object in some other context. in many cases, however, an object escapes just in a single unlikely branch. ow sensitive escape analysis which we call partial escape analysis. the idea behind partial escape analysis is to perform optimizations such as scalar replacement in branches where the object does not escape, and make sure that the object exists in the heap in branches where it does escape. additionally, our partial escape analysis works not on bytecodes but on the compilerintermediate representation, so that it can be applied, possibly multiple times, at any point during compilation. this paper contributes the following novel aspects: a control ow sensitive partial escape analysis algorithm that checks the escapability of objects for individual branches. the integration of our partial escape analysis in a java compiler based on ssa form, speculative optimization, and deoptimization. an evaluation of this algorithm on a set of current benchmarks, in terms of run time, number and size of allocations and number of monitor operations, showing that our algorithm performs well on a variety of benchmarks. this not only leads to potential code duplication, but also impacts the actual time needed to develop a fully fledged runtime. it is extensible, featuring built in support for custom extension mechanisms. it is also high performance, as it is designed to benefit from the optimizing compiler in the truffle framework. our initial evaluation indicates that the truffle osm can be used to implement high performance language runtimes, with no performance overhead when compared to language specific solutions. truffle is a java based framework for developing high performance language runtimes. language implementers aiming at developing new runtimes have to design all the runtime mechanisms for managing dynamically typed objects from scratch. in this paper we address this issue by introducing a common object storage model for truffle that can be used by language implementers to develop new runtimes. the osm is generic, language agnostic, and portable, as it can be used to implement a great variety of dynamic languages. is an open source framework for the implementation of high performance language runtimes using java and the java virtual machine. more precisely, the ast interpreter is the language runtime. copyrights for components of this work owned by others than acm must be honored. to copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speci. http: dx doi org year# oracle com eral truf. based implementations for dynamic languages exist, including javascript, ruby, python, smalltalk, and. this core component is the object storage model, that is, the runtime support for implementing dynamic objects. model for representing objects, and then have to optimize the language runtime accordingly in order to optimize the ast interpreter for the characteristics of a certain languageobject model. requiring language implementers to develop the object storage model of their new language from scratch is not only a waste of resources, but could also lead to questionable software engineering practices such as code duplication and non modular design. framework and with the aim of supporting language developers with a richer shared infrastructure, this paper introduces a new, language independent, object storage model for truf e. framework as well as in the domain of similar frameworks as it provides language implementers with a common shared component that can be used to obtain support for new language runtimes having the following properties: generality. osm can be used by language implementers as the basis for developing the object model of their new or existing guest languages. based language runtimes of ruby and javascript have been implemented sharing the same type specialization and inline caching mechanisms. the extension mechanism javascript program ruby program javascript runtime ruby runtime truffle runtime java virtual machine written in guest language written in java written in java written in, java figure #: system structure of guest language implementations on top of the truf. osm be shared across multiple language runtimes, but it also offers them the same competitive performance characteristics. osm is designed to be a core runtime component for any new language runtime based on the truf. platform, offering automatic built in support for runtime mechanisms such as type specialization and polymorphic inline caches. using truf, a language runtime can be developed just by implementing an ast interpreter. the ast can be automatically optimized by truf. and can nally be compiled into very ef cient machine code. can be used conveniently for developing the runtime support for dynamically typed languages. as of today, sev permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies bear this notice and the full citation on the rst page. all of the existing implementations offer very competitive performance when compared to other state of the art implementations, and have the notable characteristics of being developed in pure java. to further sustain and widen the adoption of truf. as a common java based platform for language implementation, truf. offers a number of shared apis that language implementers can use to optimize the ast interpreter in order to produce even more optimized machine code. in order to obtain high performance, however, there has still been one core component that the truf. platform did not offer to language implementers, and that had to be implemented manually. platform have to implement their own language speci. with the goal of solving the above limitation of the truf. the new object storage model represents a notable progress in the truf. its design allows common mechanisms to be reused across language runtimes, providing developers with a set of built in optimizations. languages requiring custom operations on object instances can extend the osm by simply adding the new feature to the speci. platform is designed to take advantage of truf. in the next section we give background information on the truf. section # introduces the design and the main characteristics of the truf. section # presents the implementation details, while section # presents a performance evaluation. section # presents related work, while sections and conclude this paper. whenever an array element is accessed, java virtual machines execute a compare instruction to ensure that the index value is within the valid bounds. this reduces the execution speed of java programs. array bounds check elimination identifies situations in which such checks are redundant and can be removed. we present an array bounds check elimination algorithm for the java hotspot; vm based on static analysis in the just in time compiler. the algorithm works on an intermediate representation in static single assignment form and maintains conditions for index expressions. it fully removes bounds checks if it can be proven that they never fail. whenever possible, it moves bounds checks out of loops. the static number of checks remains the same, but a check inside a loop is likely to be executed more often. if such a check fails, the executing program falls back to interpreted mode, avoiding the problem that an exception is thrown at the wrong place. the evaluation shows a speedup near to the theoretical maximum for the scientific scimark benchmark suite. the algorithm also improves the execution speed for the specjvm benchmark suite. to ensure safe execution of programs within a virtual machine, every illegal memory access must be intercepted. for eld accesses, this is done by type checking and veri cation of the eld. array accesses, however, require a run time check to verify that the speci ed index is within the bounds of the array. in case of java, the lower bound of an array is always zero, while the upper bound is the length of the array minus one. if the index is not within this range, an arrayindexoutofboundsexception must be thrown. the overhead introduced by such checks can be signi cant, especially for mathematical applications, but checks fail only in rare cases. when it can be proven at compile time that a check never fails, it can be omitted. such a check is said to be fully redundant. there can also be situations where checks are not fully redundant, but the total number of executed checks can be reduced by moving checks or combining several checks into a single one. for example, a check performed within a loop is likely to be executed more often than a check before the loop. the total number of dynamically performed checks can be reduced by replacing such a check with another one. in this case, the check is said to be partially redundant. one important property that must be kept in mind when eliminating or moving checks in java programs is that the semantics must stay the same. when a check fails, the exception must be thrown at the correct code position of the failing array access. it is not allowed to just stop the program when an array is accessed out of its valid bounds. this paper describes our array bounds check elimination algorithm that tries to minimize the total number of dynamically executed checks in average java programs. it works as an additional optimization step on the just in time compilerintermediate language, which is in static single assignment form. it eliminates checks that can be proven to be fully redundant and inserts additional instructions to be able to remove partially redundant checks by grouping multiple checks or moving checks out of loops. to avoid loop versioning, ie, the duplication of code, and nevertheless retain the exception semantics of java, we use the facilities of the java hotspottm vm to switch back from compiled to interpreted code. our algorithm focuses on program structures that are common to java programs and eliminates the checks with a low impact on the compile time. this is important because it is integrated into a fast just in time compiler where the additional time needed for compilation decreases the total execution speed. we integrated our analysis in the client compiler of the java hotspottm vm. this paper contributes the following: we present a fast algorithm for array bounds check elimination that is suitable for a just in time compiler. we preserve the exception semantics of java by using deoptimization. we show how to handle integer over ow when checking bound conditions. we compare our results to the speedup theoretically achievable by array bounds check elimination. the evaluation shows the impacts of our algorithm on several benchmarks. an abstract syntax tree interpreter is a simple and natural way to implement a programming language. however, it is also considered the slowest approach because of the high overhead of virtual method dispatch. language implementers therefore define bytecodes to speed up interpretation, at the cost of introducing inflexible and hard to maintain bytecode formats. we present a novel approach to implementing ast interpreters in which the ast is modified during interpretation to incorporate type feedback. our system is implemented in java and uses the static typing and primitive data types of java elegantly to avoid the cost of boxed representations of primitive values in dynamic programming languages. this tree rewriting is a general and powerful mechanism to optimize many constructs common in dynamic programming languages. when designing and implementing a new programming language, the rst and easiest choice is to implement an abstract syntax tree interpreter. the interpreter is often embedded in a virtual machine that provides other services such as memory management. parsers for context free grammars process source code in a tree like fashion, so creating an ast feels natural and can even be automated. making an ast executable, ie, writing an ast interpreter, just requires adding an execute method to every ast node. a common argument against ast interpreters is performance: calling the execute method for every node requires a virtual method dispatch that is costly, and call sites within the execute methods are highly polymorphic and therefore dif cult to optimize. for this reason, language implementers de ne bytecodes to speed up interpretation. bytecode interpreters are well understood, and many variants with varying dispatch costs have been permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies bear this notice and the full citation on the rst page. to copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speci. bytecodes are a virtual instruction set,e, they can be de ned freely by language implementers without worrying about hardware constraints. there are two different strategies when de ning bytecodes. we believe that both are cumbersome when implementing a new language: language independent bytecodes aim to provide an instruction set that is suitable for many languages. javatm bytecodes, originally designed primarily for the java programming language, are now used for many languages. the common intermediate language, which is used by the net system, was speci cally designed for multiple languages. languageindependent bytecodes provide only general instructions whose semantics do not match the language semantics exactly. long bytecode sequences are potentially required to achieve the desired language behavior. for example, java bytecodes are statically typed, so compiling dynamically typed javascript requires frequent type checks. a simple addition in javascript requires checking whether the operands are numbers, strings, or arbitrary objects, which all require different handling. therefore, implementations of javascript that run on a java vm often call a method for a seemingly simple addition. bytecodes are usually used internally by a vm, often even without a clearly de ned speci cation. they closely resemble the semantics of the programming language, so little can be reused from existing language implementations when implementing a new language. when the language evolves, the bytecodes also have to evolve. in any case, bytecodes are dif cult to modify once they are emitted. exploiting pro ling information, such as types that were observed during execution, is not only useful for just in time compilers but can also improve the performance of interpreters. however, the compact binary encoding of bytecodes makes this dif cult. for example, to replace one generic bytecode with a short sequence of typespecialized bytecodes requires adjusting offsets in branch instructions that jump over the replaced code. it is possible to incorporate pro ling information immediately after it is discovered, by rewriting the ast. for example, a tree node for a type agnostic addition can be replaced with a specialized integer addition node after the rst execution of the addition reveals that the operands were integers. this is based on the observation that types are mostly stable, even in dynamically typed languages. in this paper, we show that while naive interpretation of an ast is slower compared to bytecodes, use of pro ling and ast guest language application written in javascript javascript vm guest vm written in java java vm host vm written inos figure #. rewriting allow an ast interpreter to achieve speeds comparable to the speed achievable with language independent bytecodes. we use java and the java vm for our implementation, and javascript as the interpreted language. however, we are more interested in the general concepts than in the speci cs of javascript, therefore our prototype does not implement the full language semantics of javascript. while we believe that our rewritten type specialized asts are excellent input for a jit compiler, we leave a detailed investigation of this for future work. in summary, this paper contributes the following: the de nition of a simple yet ef cient ast interpreter only execution of a guest language on top of an existing statically typed vm. tree rewriting as a way to optimize and type specialize ast interpreters at run time. an evaluation showing that our ast interpreter achieves performance similar to other, more complicated, implementations that generate language independent bytecodes. system structure of our guest vm on top of a host vm. building high performance virtual machines is a complex and expensive undertaking; many popular languages still have low performance implementations. we describe a new approach to virtual machine construction that amortizes much of the effort in initial construction by allowing new languages to be implemented with modest additional effort. the approach relies on abstract syntax tree interpretation where a node can rewrite itself to a more specialized or more general node, together with an optimizing compiler that exploits the structure of the interpreter. the compiler uses speculative assumptions and deoptimization in order to produce efficient machine code. our initial experience suggests that high performance is attainable while preserving a modular and layered architecture, and that new high performance language implementations can be obtained by writing little more than a stylized interpreter. high performance vm implementations for object oriented languages have existed for about twenty years, as pioneered by the self vm, and have been in widespread use for fteen years. permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies bear this notice and the full citation on the rst page. copyrights for components of this work owned by others than the author must be honored. to copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speci. http: dx doi org year# these implementations can be characterized in the following way: their performance on typical applications is within a small multiple of the best statically compiled code for most equivalent programs written in an unsafe language such as. they are usually written in an unsafe, systems programming language. they implement a single language, or provide a bytecode interface that advantages a narrow set of languages to the detriment of other languages. in contrast, there are numerous languages that are popular, have been around for about years, and yet still have no implementations that even approach this level of performance. examples are php, python, ruby, perl, mat lab, smalltalk, and apl. the computer language benchmarks game provides some insights into the performance of various languages. performance was lackluster until year#, but signi cant effort has since been invested in several competing implementations to make performance respectable. we believe that the recent history of javascript explains why the other languages have lesser performance: until industrial scale investment becomes available, the complexity of a traditional high performance vm is too high for small scale efforts to build and maintain a high performance implementation for multiple hardware platforms and operating systems. we present a new approach and architecture, which enables implementing a wide range of languages within a common framework, reusing many components. this brings excellent performance for all languages using our framework. our approach relies on a framework that allows nodes to rewrite themselves during interpretation, a speculatively optimizing compiler that can we use node rewriting in a sense that is distinct from rewriting in the context of the lambda calculus, formal semantics, or term rewriting systems. exploit the structure of interpreters written using this framework, and deoptimization to revert back to interpreted execution on speculation failures. in this paper, we describe the overall approach and the structure of our implementation, with particular attention to the interaction between the interpreter, the compiler, and deoptimization. additionally, we describe the variety of language implementations we are undertaking, with speci. our focus is on dynamically typed, imperative programming languages such as javascript, ruby, and python; as well as languages for technical computing such asand. this paper presents a forward looking viewpoint on work in progress. we have a working prototype implementation of the interpreter framework and the compilation infrastructure. a detailed description of the node rewriting appears elsewhere; a brief summary of that paper appears at the beginning of section #. the ast and machine code of the example presented in the subsequent sections are produced by our actual system. we are therefore convinced that the approach can be successful. however, more implementation work is necessary to get larger industry standard benchmarks running for multiple languages. our language implementation framework, called truf, as well as our compilation infrastructure, called graal, are available as open source in an openjdk project. we encourage academic and open source community contributions, especially in the area of new innovative language features and language implementations. language implementations that are started now, using our framework, will automatically pro. from our compilation infrastructure when it is nished, so we envision multiple language implementations being developed by third parties simultaneously to our efforts. in summary, this paper contributes the following: we present a new vm architecture and our implementation, which can be used to construct high performance implementations of a wide range of languages at modest incremental cost. we show how the combination of node rewriting during interpretation, optimizing compilation, and deoptimization delivers high performance from an interpreter without requiring a language speci. we show how features of a variety of programming languages map on our framework. we describe how our system supports alternative deployment strategies; these enhance developer productivity and separate language speci. examples are high performance java vms such as oraclejava hotspot vm and ibmjava vm, as well as microsoftcommon language runtime. reference to their unique attributes and the challenges posed.