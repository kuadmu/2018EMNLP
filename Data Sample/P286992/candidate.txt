technology scaling non idealities, already apparent in the transitions between previous technology generations, will become even more pronounced as the world moves from the nm node to the nm node. digital logic designers working on high performance microprocessors and similar projects will face significant new challenges as the basic fet structure is changed in a fundamental way, in order to squeeze more performance from scaled devices. new design constraints and new sources of variability will have to be understood, and new methodologies will be required to enable robust, high speed designs. in addition, the metal interconnects between devices will also be stressed. scaled wire rc will likely increase, and new tools and methods will be needed to ensure reliable designs. tiled architectures provide a paradigm for designers to turn silicon resources into processors with burgeoning quantities of programmable functional units and memories. the architecture has a dual responsibility: first, it must expose these resources in a way that is programmable. second, it needs to manage the power associated with such resources we present the power management facilities of the tile raw microprocessor. this design selectively turns on and off sram macros, functional unit clusters, fetch units, and over unique processor pipeline stages, all according to the needs of the computation and environment at hand. the rapid shrinking of vlsi feature sizes brings the promise of both increasing frequencies and larger numbers of general purpose functional units for high performance microprocessors. the harsh realities of interconnect delay and power consumption seriously challenge the ability of microprocessor designers to fulfill these promises. a case in point is the itanium processor, which consumes watts and sports a zero cycle fully bypassed way issue integer execution core. despite occupying less than two percent of the processor die, this execution core spends half of its critical path in the bypass paths between the alus. current wide issue processor designs rely on huge, global, centralized structures such as associative instruction windows, register renamers, heavily ported register files, zero cycle bypassed alu clusters, and heavily ported caches. as these structures scale up in size, internal interconnect delay becomes the dominant factor. this delay is due to increasing wire lengths, capacitive loads and effective logic levels. the desire to minimize delay keeps these structures centralized, and compounds the power distribution problem, because it clusters like components together. this all but ensures that the high power consumption components will be situated near to each other. moreover, architectural features required to extract parallelism from permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. to copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and or a fee. serial instruction streams require substantially more logic, resulting in reduced energy efficiency. microprocessor designers have recently found that the exponentially rising thermal dissipation of high performance microprocessors has begun to affect these systems applicability even in non mobile environments. high thermal dissipation precludes the manufacture of rack mount systems that contain early itanium ii or pentium processors. heat production also affects the cost of these systems: the price of an appropriate cooling solution increases drastically with rising microprocessor temperatures. these power concerns have lead the pentium architects to include a thermal monitor and a mechanism to stop the processorclock in order to prevent overheating. if this trend continues, it appears as if all processors, whether high performance or mobile, will soon need to be, in some sense of the term, low power. in this paper, we propose a novel noc architecture, called darknoc, where multiple layers of architecturally identical, but physically different routers are integrated, leveraging the extra transistors available due to dark silicon. each layer is separately optimized for a particular voltage frequency range by the adroit use of multi vt circuit optimization. at a given time, only one of the network layers is illuminated while all the other network layers are dark. we provide architectural support for seamless integration of multiple network layers, and a fast inter layer switching mechanism without dropping in network packets. our experiments on a mesh with multi programmed real application workloads show that darknoc improves energy delay product by up to compared to a traditional single layer noc with state of the art dvfs. this illustrates darknoc can be used as an energy efficient communication fabric in future dark silicon chips. network on chips provide a scalable communication fabric for connecting large number of resources within a chip. noc can contribute signi cantly to the total chip power, eg, up to and in intel scc and raw architectures, respectively. to address this issue, various power saving techniques for noc at system, architecture and circuit level have emerged, among which dynamic voltage and frequency scaling is very prominent. system level dvfs managers apply reduced voltage and frequency levels in a noc to save power. according to several recent studies, the energy saving potential of dvfs has been diminishing due to a number of reasons: with shrinking node size, the difference between nominal voltage and the threshold voltage is decreasing. as the nominalapproaches threshold voltage, the transistor delay increases exponentially, resulting in huge performance penalties. this limits the factor by whichcan be scaled down. transistors with lower threshold voltages can be used in the circuit to increase the gap between the nominal and threshold voltages, but that results in an increased leakage power. dvfs does not in uence the intrinsic physical properties of the circuit such as gate sizes, capacitances, etc. multivt optim ization target latency: lvt nvt hvt figure #: an example of multi vt circuit optimization. with the help of the following noc synthesis case study, we show how the problem of diminishing returns of dvfs can be alleviated. motivational example: most fabrication foundries characterize cell libraries for various gate threshold voltage values such as normal vt, low vt, and high vt. lvt cells can switch at a much faster speed than hvt cells. however, lvt cells can be up to leakier than their hvt counterparts. modern cad tools exploit the power delay characteristics of multi vt cell libraries and slacks in path delays to synthesize power ef cient circuits. a typical cad tool optimizes the circuit by using lvt cells on critical paths to meet the target latency, while inserting hvt cells on the non critical paths to reduce leakage power. for example, in figure #, a circle and its annotation represents the type of cell and its delay. with multi vt circuit optimization, a mix of lvt, nvt and hvt cells is used to meet the target latency rather than just the nvt cells. thus, the circuit on the right will have different intrinsic properties such as gate sizes, capacitances and leakage power than the circuit on the left. we exploited the multi vt circuit optimization available in cad tools to synthesize architecturally identical noc routers for a set of target vf levels: and. figure # reports the network power for operation at and. we can observe that for operation at, the noc designed particularly for vf level is on average and more power ef cient than applying dvfs on a noc designed for and, respectively. similarly, for operation at, the noc designed particularly for vf level is on average and more power ef cient router designed mhz router designed mhz the author is now af liated with google inc. permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies bear this notice and the full cita tion on the rst page. copyrights for components of this work owned by others than acm must be honored. to copy otherwise, or re injection rate publish, to post on servers or to redistribute to lists, requires prior speci. dac year#, june year#, san francisco, ca, usa figure #: noc power for transpose traf. vf level, vf level http: dx doi org year# than dvfs applied to noc designed for and, respectively. this observation shows that, unlike traditional noc with a single layer of routers, it may be bene cial in terms of power to have multiple layers of routers in a noc such that each layer is optimized for a particular vf level. the provision of multiple layers of routers in a noc may cost a signi cant amount of silicon; however, we can leverage dark silicon to alleviate this overhead. several researchers have proposed to leverage dark silicon to provide extra application speci. in fact, the authors of state that in eight years, we will be faced with designs that are dark, and, we will spend exponentially increasing amounts of silicon area to buy energy ef ciency. therefore, even with the addition of extra accelerators and processors, we believe that there will still be dark silicon available which could be exploited for energyef cient design of other system components such as noc. we propose a novel noc architecture, where architecturally homogenous routers that have been optimized speci cally for particular vf ranges, are seamlessly integrated at the architecture level to complement system level dvfs managers, and exchange dark silicon for energy ef ciency in noc. for the rest of the two problems, we provide our initial insights from extensive experiments, and leave their comprehensive solutions as future work. in particular, our key contributions are: we propose a novel noc architecture, named darknoc, where multiple network layers consisting of architecturally identical routers, but optimized to operate within different voltage and frequency ranges during synthesis are used. only one network layer is illuminated at a given time while the rest of the network layers are dark. we propose an ef cient hardware based mechanism to transition from one network layer to another. our network layer switch over mechanism preserves the lossless communication property of a packet switched buffered noc, and is transparent to the software. further, we investigate and report the factors that can potentially affect the time and energy overhead of switch over mechanism. finally, to illustrate the potential of our darknoc architecture, we show how a state of the art dvfs manager is deployed. further, we compare our darknoc architecture having different number of network layers with a traditional single network layer noc, where both the architectures have the same dvfs manager. the widespread proliferation of the chip multi processor paradigm has cemented the criticality of the on chip interconnection fabric. as technology feature sizes diminish into the nanoscale regime, reliability and process variability artifacts within the noc start to become prominent. finally, hardware synthesis results using commercial nm technology libraries indicate minimal area and power overhead of and less than, respectively, and negligible impact on the router critical path. the network on chip is becoming increasingly susceptible to emerging reliability threats. the need to detect the occurrence of faults at run time is steadily becoming imperative. in this work, we propose nocalert, a comprehensive on line and real time fault detection mechanism that demonstrates false negatives within the interconnect, for the fault model and stimulus set used in this study. based on the concept of invariance checking, nocalert employs a group of lightweight micro checker modules that collectively implement real time hardware assertions. the checkers operate seamlessly and concurrently with normal noc operation, thus eliminating the need for periodic, or triggered based, self testing. more importantly, of the faults are detected instantaneously. extensive cycle accurate simulations in a node cmp demonstrate the efficacy of the proposed technique. this unprecedented abundance of on chip resources, coupled with thinning instruction level parallelism, have urged designers to switch their attention to another computational archetype: the chip multi processor. packet based networks on chip are widely viewed as the de facto communication medium of future multi many core cpus, primarily due to their inherent scalability attributes and modular nature. the extreme downscaling trends of cmos technology have rendered transistors more susceptible to both permanent and transient faults. the underlying principle of this technique is inspired by prior efforts to protect the microprocessor by using invariances. diminutive technology feature sizes have enabled microprocessors with billions of transistors on a single chip die. the presence of multiple on chip processing entities has precipitated a shift from computation centric to communication centric micro architectures. as a result, the onchip interconnection fabric is fast becoming a mission critical component. however, the march towards cmps with tens or even hundreds of processing cores has been marred by the emergence of an ominous threat: waning reliability. moreover, digital circuits are increasingly affected by growing process variability artifacts and accelerated aging effects, all of which are consequences of dwindling feature sizes. just like any on chip component, the interconnection backbone is also affected by decreasing reliability. in fact, a single fault in the on chip network may paralyze an otherwise healthy cmp. faults within the noc may result in such showstopping predicaments as network disconnections, network level deadlocks, protocol level deadlocks, lost packets, and severely degraded on chip communication performance. architects and designers have proposed a multitude of techniques, mechanisms, and design modi cations to increase the fault tolerance and reliability of the noc. however, the vast majority of the related work found in the literature concentrates on fault prevention and or recovery. the equally important aspect of fault detection has not been adequately addressed. traditionally, fault detection is undertaken by built in self test mechanisms that predominantly assume a disruption in the systemoperation. the bist process may be executed by the manufacturer prior to shipment, or it may constitute part of system bootup. runtime bist is also possible, but system operation is halted while the module under test is examined. bist usually entails the use of prede ned test vectors, patterns, or routines, which tend to be pure overhead. regardless, detecting faults at run time is rapidly becoming a necessity, in light of the aforementioned decline in reliability. when bist or bist like methodologies are employed within the context of on line testing, the process is usually triggered periodically. choosing the length of the period between two consecutive test sessions is certainly non trivial: if testing is conducted too frequently, the impact on performance will be more pronounced, due to excessive interruptions; if testing is rarely performed, then faults may go unnoticed for a prolonged period of time. furthermore, periodic testing often implies the use of checkpointing, which adds further overhead. near instantaneous fault detection may be achieved in the datapath of the interconnect through the use of error detecting codes. simple parity checks or more elaborate coding will detect errors affecting the contents of in ight packets. while this methodology guarantees protection of the message contents, faults within the control logic of the noc may still wreak havoc with the operation of the entire cmp. hence, what is needed to guarantee functional correctness within the noc and, by extension, within the cmp is to protect the noccontrol logic. this thesis statement marks the central theme of our work. realizing the signi cance of accurate and timely run time detection of faults within the noccontrol logic, we hereby propose a comprehensive on line fault detection mechanism, aptly called nocalert, which provides full fault coverage for all on chip network control logic components and achieves instantaneous detection of any erroneous behavior. depending on the applicationcriticality, instantaneous detection may be of paramount signi cance. the no calert mechanism is based on the notion of invariance checking, whereby the system is continuously checked for illegal outputs as a result of upsets. an illegal output is de ned here as an operational decision that violates the functional correctness rule of a particular component. nocalert comprises several checker micro modules distributed throughout the noc router, which seamlessly and concurrently monitor all noc modules for illegal activity. the checkers never interfere with or interrupt the operation of the noc and they provide real time on line fault detection. in essence, nocalert implements an allencompassing collection of extremely lightweight real time hardware assertions that can detect illegal outputs within the noccontrol logic. in particular, the main contributions of this work are: the development of a comprehensive on line and real time fault detection mechanism for the control logic of the noc of multi core cmps. the proposed nocalert checker modules operate seamlessly and concurrently with normal noc operation, thus obviating the need for testing epochs and periodic triggering of testing sessions that may interrupt impede normal system operation. current network on chip designs in chip multiprocessors are agnostic to application requirements and hence are provisioned for the general case, leading to wasted energy and performance. we propose the use of two separate networks on chip, where one network is optimized for bandwidth and the other for latency, and the steering of applications to the appropriate network. we further observe that not all bandwidth sensitive applications are equally sensitive to network bandwidth. hence, within each network, we prioritize packets based on the relative sensitivity of the applications they belong to. we introduce two metrics, network episode height and length, as proxies to estimate bandwidth and latency sensitivity, to classify and rank applications. our evaluations show that the resulting heterogeneous two network design can provide significant energy savings and performance improvements across a variety of workloads compared to a single one size fits all single network and homogeneous multiple networks. we observe that applications can generally be classified as either network bandwidth sensitive or latency sensitive. network on chips are envisioned to be a scalable communication substrate for building multicore systems, which are expected to execute a large number of different applications and threads concurrently to maximize system performance. a noc is a critical shared resource among these concurrently executing applications, signi cantly affecting each applicationperformance, system performance, and energy ef ciency. traditionally, nocs have been designed in a monolithic, one size ts all manner, agnostic to the needs of different access patterns and application characteristics. two common solutions are to design a single noc for the common case, or average case, application behavior or the nearworst case application behavior, by over provisioning the design as much as possible to maximize network bandwidth and to minimize network latency. however, applications have widely different demands from the network, eg, some require low latency, some high bandwidth, some both, and some neither. as a result, both design choices are suboptimal in either performance or energy ef ciency. the average case network design cannot provide good performance for applications that require more than permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies bear this notice and the full citation on the rst page. to copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speci. both network designs, especially the over provisioned design, are power and energy inef cient for applications that do not need high bandwidth or low latency. hence, monolithic, one size ts all noc designs are suboptimal from performance and energy standpoints. ideally, we would like a noc design that can provide just the right amount of bandwidth and latency for an application such that the applicationperformance requirements are satis ed, while the systemenergy consumption is minimized. this can be achieved by dedicating each application its own noc that is dynamically customized for the applicationbandwidth and latency requirements. unfortunately, such a design would not only be very costly in terms of die area, but also requires innovations to dynamically change the network bandwidth and latency across a wide range. instead, if we can categorize applications into a small number of classes based on similarity in resource requirements, and design multiple networks that can ef ciently execute each class of applications, then we can potentially have a cost ef cient network design that can adapt itself to application requirements. building upon this insight and drawing inspiration from the embedded and asic designs where a single network is customized for a single application, this paper proposes a new approach to designing an on chip interconnect that can satisfy the diverse performance requirements of generalpurpose applications in an energy ef cient manner. we observe that applications can be divided into two general classes in terms of their requirements from the network: bandwidth sensitive and latency sensitive. two different noc designs, each of which is customized for high bandwidth or low latency, can, respectively, satisfy requirements of the two classes in a more power ef cient manner than a monolithic single network. we, therefore, propose designing two separate heterogeneous networks on a chip, dynamically monitoring executing applications bandwidth and latency sensitivity, and steering injecting network packets of each application to the appropriate network based on whether the application is deemed to be bandwidth sensitive or latency sensitive. we show that such a heterogeneous design can achieve better performance and energy ef ciency than current average case one size ts all noc designs. to this end, based on extensive application pro ling, we rst show that a high bandwidth, low frequency network is best suited for bandwidthsensitive applications and a low latency, high frequency network is best for latency sensitive applications. next, to steer packets into a particular network, we identify a packetsensitivity to network latency or bandwidth. for this, we propose a new packet classi cation scheme that is based on an applicationintrinsic network requirements. we introduce two new metrics, network episode length and height, to dynamically identify the communication requirements of applications. observing that not all applications are equally sensitive to latency or bandwidth, we propose. thus, our mechanism consists of rst dynamically classifying an application as latency or bandwidth sensitive, then steering it into the appropriate network and, nally within each network prioritizing each applicationpackets based on its relative potential to improve overall system performance and reduce energy. our evaluations on a core mesh architecture, considering design alternatives with diverse applications, show that our heterogeneous two network noc design consisting of a link width latency monolithic network design. when compared to a baseline link width monolithic network, our proposed design provides weighted instruction throughput improvement and energy reduction. ne grained prioritization mechanism for applications within the bandwidth and latency optimized networks. dark silicon refers to the observation that in future technology nodes, it may only be possible to power on a fraction of on chip resources in order to stay within the power budget and safe thermal limits, while the other resources will have to be kept powered off or dark. in other words, chips will have an abundance of transistors, ie, more than the number that can be simultaneously powered on. heterogeneous computing has been proposed as one way to effectively leverage this abundance of transistors in order to increase performance, energy efficiency and even reliability within power and thermal constraints. however, several critical challenges remain to be addressed including design, automated synthesis, design space exploration and run time management of heterogeneous dark silicon processors. the hardware software co design and synthesis community has potentially much to contribute in solving these new challenges introduced by dark silicon and, in particular, heterogeneous computing. in this paper, we identify and highlight some of these critical challenges, and outline some of our early research efforts in addressing them. for decades, the dennard scaling model has allowed chip designers to keep power density constant when moving from one technology node to another. more recently, however, the exponential dependence of leakage power consumption on threshold voltage has constrained further threshold and supplyvoltage scaling. as a result, the power density is now increasing with technology scaling, such that it can no longer be cooled down in cost. ective ways considering the physical limitations imposed by cooling technologies and packaging. this gives rise to the so called dark silicon problem. permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies bear this notice and the full citation on the rst page. copyrights for components of this work owned by others than acm must be honored. to copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speci. request permissions from permissions acm org esweek, october, year#, new delhi, india. dark silicon refers to the constraint that a signi cant fraction of transistors on a chip cannot be powered on at the nominal voltage for a thermal design power budget and have to remain dark, ie, power gated. the tdp is the maximum power budget supplied to a chip while keeping the chip temperature below the thermal safe temperature. in case the tdp is exceeded, the chip temperature will start rise beyond the cooling capacity, resulting in either thermal run away or activation of dynamic thermal management mechanisms that will throttle the chip. using technology data from itrs and intel, prior studies have predicted that at the nm technology node, of the chip area will be dark for both cpu and gpu based systems executing massively parallel workloads. given this scenario, the question posed for the architecture, design automation, and hardware software co design communities is: can the abundance of transistors on dark silicon chips be harnessed to improve important design metrics like performance, energy power. ciency or even reliability under tdp constraints, andifso, how recent work in this context has explored dark silicon chip with: a multitude of application speci. and general purpose accelerators, exploiting architectural heterogeneity and near threshold computing. moreover, the available dark silicon can also be leveraged to mitigate reliability threats in the nano era that include soft errors, aging and process variations. in all the instances above, the key idea is to overprovision the chip with heterogeneous computing resources for instance, application speci. accelerators or cores with di ering power, performance and reliability characteristics and to select the subset of computing resources at run time that maximize the desired ob jective within the tdp budget. in fact, problems relating to the design and run time mamagement of heterogeneous computing platforms have been extensively addressed by the hardware software co design and systems synthesis communities, particularly in the context of application speci. motivated by the dark silicon challenge, heterogeneity is now beginning to nd a foothold in generalpurpose processor architectures including some commercially available chips like the arm big little processor. however, because the general purpose computing domain is substantively di erent from the application speci. domain, existing solutions cannot simply be reused and new methodologies are required. in this paper, we identify some critical challenges introduced by dark silicon and highlight promising solutions to these challenges, with a speci. focus on the design and run time management of future generation heterogeneous dark silicon processors. our broader goal is to spur greater awareness and discussion of these challenges in the hardware software co design and systems synthesis community, and to position the dark silicon problem as one that this community can have a large impact on solving. critical challenges in the dark silicon era to fully exploit the the abundance of transistors in the dark silicon era using heterogeneity, the following critical challenges must be addressed: heterogeneous architecture synthesis and design space exploration challenge: at design time, the challenge is how to optimally synthesize a chip given a library of heterogeneous cores and application speci. accelerators, in other words, how many cores and accelerators of each type should the processor be provisioned with the constraints are the total chip area, tdp and peak temperature while the optimization ob jectives can include performance, energy. since the design space is large, automated algorithms are to. ciently navigate this design space and provide high quality solutions. in section #, we will discuss one such approach to address this challenge. this paper describes the polymorphous trips architecture which can be configured for different granularities and types of parallelism. trips contains mechanisms that enable the processing cores and the on chip memory system to be configured and combined in different modes for instruction, data, or thread level parallelism. to adapt to small and large grain concurrency, the trips architecture contains four out of order, wide issue grid processor cores, which can be partitioned when easily extractable fine grained parallelism exists. this approach to polymorphism provides better performance across a wide range of application types than an approach in which many small processors are aggregated to run workloads with irregular parallelism. our results show that high performance can be obtained in each of the three modes ilp, tlp, and dlp demonstrating the viability of the polymorphous coarse grained approach for future microprocessors. we develop detailed area and energy models for on chip interconnection networks and describe tradeoffs in the design of efficient networks for tiled chip multiprocessors. using these detailed models we investigate how aspects of the network architecture including topology, channel width, routing strategy, and buffer size affect performance and impact area and energy efficiency. we simulate the performance of a variety of on chip networks designed for tiled chip multiprocessors implemented in an advanced vlsi process and compare area and energy efficiencies estimated from our models. we demonstrate that the introduction of a second parallel network can increase performance while improving efficiency, and evaluate different strategies for distributing traffic over the subnetworks. drawing on insights from our analysis, we present a concentrated mesh topology with replicated subnetworks and express channels which provides a improvement in area efficiency and a improvement in energy efficiency over other networks evaluated in this study. ectively using the resources available in advanced vlsi technologies. the remainder of this paper is organized as follows. chip multiprocessors use increasing transistor budgets to integrate multiple processors on a single die. tiled architectures provide a scalable solution for managing design complexity and. cient, scalable on chip communication mechanisms will continue to increase as advances allow more processors to be integrated on a single die; furthermore, power dissipation and wire delay will continue to increase in signi cance as limiting design constraints. or commercial advantage and that copies bear this notice and the full citation on the rst page. to copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speci. ciently used while maintaining well controlled electrical characteristics. cient on chip networks for tiled cmp architectures. we address the broader issue of the complete networkperformance and. we develop comprehensive analytical area and energy models for on chip networks. the energy models extend those presented in by incorporating the impacts of physical design and layout on energy dissipation. our area and energy models incorporate design space attributes including topology, routing, channel design, switch architecture, and bu er sizing with su cient detail to explore a broad design space. we demonstrate that using multiple onchip networks to increase bandwidth and path diversity substantially improves performance without adversely. ciency as measured by the area delay product and energy delay product, respectively. drawing on insights from our analysis, we propose a concentrated mesh architecture which. ciency over other architectures evaluated in this work. in section # we present network performance and technology models. in section # we detail the motivating system archi tecture and constraints imposed by the vlsi technology. in section # we present a canonical network architecture and develop our energy and area models. in section # we de scribe the design space and present our architectures. in sections and we describe evaluation methodologies and present results and analysis. performance and power are the first order design metrics for network on chips that have become the de facto standard in providing scalable communication backbones for multicores cmps. however, nocs can be plagued by higher power consumption and degraded throughput if the network and router are not designed properly. towards this end, this paper proposes a novel router architecture, where we tune the frequency of a router in response to network load to manage both performance and power. we propose three dynamic frequency tuning techniques, freqboost, freqthrtl and freqtune, targeted at congestion and power management in nocs. as enablers for these techniques, we exploit dynamic voltage and frequency scaling and the imbalance in a generic router pipeline through time stealing. experiments using synthetic workloads on a wormhole switched mesh interconnect show that freqboost is a better choice for reducing average latency while, freqthrtl provides the maximum benefits in terms of power saving and energy delay product. the freqtune scheme is a better candidate for optimizing both performance and power, achieving on an average reduction in latency, savings in power, and savings in edp. with application benchmarks, we observe ipc improvement up to using our design. the performance and power benefits also scale for larger nocs. on chip interconnects or network on chip architectureshavebecome animportantresearchfocus inrecent years for designingmulticores chip multi processors and system on chip architectures that can scale to hundreds of cores in the future. this isbecause an on chip network plays a critical role in determining the performance and power behavior of a multicore soc architecture. while the performance implications of the underlying communication architecture is well understood in designing multipro permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies bear this notice and the full citation on the rst page. to copyotherwise, to republish, to post on servers or to redistribute to lists, requires prior speci. rst order design metric speci cally in the nanometer regime. it is predicted that noc power can be a signi cant part of the entirechippowerand can accountforupto to watts with technology scaling for a mesh based network with nodes. a few commercial designs also support this trend, where up to of the entire chip power is devoted to the interconnect. thus, on chip interconnects that can optimize both performance and power pose intriguing research challenges. this is evident from the large body of literature covering multiple facets of noc design. router frequency is one of the critical design parameter that directly. ects both performance and power, albeit in a contradictory fashion. with a sophisticated design of a router pipeline, it ispossible to increase the operating frequency, but higher router frequency leads to higher power consumption. on the other hand, a mismatchbetween processor and router network frequency can result in significantperformance penalties. thus, a prudent control of therouterfrequency canhelpin optimizingbothperformance and power. we motivate the ne balance that exists between power andperformanceinan on chip network witharelativepowerperformance trade. figure # shows the relative growth of network power versus network latency for an mesh with a synthetic tra. mixture of uniform random, transpose, nearest neighbor and self similar tra. the bars indicate network latency power normalized with respect to the network latency power at no load. at low load, the networkpower consumption is less. however, the rate of growth of network power is much higher as compared to the rate of growth of network latency. for example, as shown in figure #, the network power grows to as the injection rate varies from to, whereas the network latency grows only x. we leverage our insights from these trends to optimize the network at low load for performance and at high load for power. an activity based power management technique, which was recently implemented in the intel core routers, shares a similar view of optimizing the networkpower based on activity, albeit in a di erent fashion by clock gating the idle ports. since performance and power are directly proportional to frequency, we dynamically modulate the router frequency in response to network load to facilitate these optimizations, and demonstrate the advantages at system level. speci cally, at low load we operate the routers at peak frequency. at high load, we dynamically determine the operating frequency of individual routers in the network. the dynamic schemes that determine the operating frequencies of the routers are designed to a reduce power consumption andmanage injection ratio figure #: average network latency andpowerbehavior of an mesh network. congestion in the network, by selectively stepping up and down the frequency of a subset of routers in the congested regions of a network. we propose a two prong approach to vary the baseline router frequency: clock scaling and timestealing we employdynamicvoltage andfrequency scaling to scale up and down the router clock frequencybelow the nominal frequencyby switching the operating voltage levels. the time stealing technique is employed to boost the baseline router frequency by exploiting the timing imbalance between router pipeline stages, such that a router can operate at the average cycle time of all the pipeline stages in contrast to the delay of the worst case pipeline stage. we explore three techniques for dynamic frequency tuning to simultaneously address power performance trade. the rst technique, called freqboost, initially employs timestealing to operate all routers at a boosted frequency. this helps in enhancing the performance at low load conditions, while slightly increasing the power consumption. however, as the network gets congested, power consumptionbecomes a key challenge. hence, it throttles the frequency voltage of selected routers using dvfs. the second mechanism, called freqthrtl, initially operates all routers at the baseline frequency and selectively employs time stealing anddvfs to either increase or decrease the frequency at the onset of congestion. this scheme, unlike freqboost, can modulate frequency of routers bi directionally and consequently can help reduce power and manage congestion at high load more. using this technique, the frequency of a congested router is boosted at the onset of congestion and the frequency of a router adjacent to this congested router is throttled. freqtune is a hybrid of the above two schemes that dynamically switches between freqboost and freqthrtl as the network load varies from low to high. we evaluate the performance and power implications of the proposed techniques using a wormhole switched mesh interconnect with synthetic and application benchmarks and compare them with respect to a baseline router network. cacy of our approach, we compare our results with adaptive routing and with a baseline design that employs time stealing but no congestion management. the primary contributions of this paper are the following: we propose novel frequency tuning algorithms to reduce latency and power consumption in noc by distributed throttling andboostingofrouterfrequenciesdependingupon network load. to the best of our knowledge, this is the rst work to propose a distributed congestion management scheme that is based on operating individual routers at different frequency levels. our proposal leads to reduction in latency at high load, savings inpower and average reduction in energy delayproduct. with application benchmarks, we achieve ipc improvements up to using our schemes. moreover, thepower performance bene ts increase when these techniques are applied to large networks. our analysis corroborates the pipeline stage imbalance found in other routers proposed in. while this imbalance canberemoved usingpower optimizations such as variable voltage and gate sizing optimizations, we focus on time stealing techniques to boost performance. time stealing in noc routers can lead to reduction in zero load latency. in addition, we use the well known dvfs technique at the granularity of an individual router to tune the router frequency and power based on its load. webelieve, this is the rst paper to apply time stealing and dvfs techniques forperformance andpower management in on chip routers. we demonstrate that the proposed techniques are not only much more. ective in delivering better performance and reducing power consumption compared to the monolithic, single frequency design, but also can outperform other pureperformance enhancementtechniques such as using adaptive routing and simply increasing the operating frequency without any congestion management. moreover, we also show how coarse grain frequency tuning can help in reducing the overheads involved in these techniques. all these results make a strong case for implementing variable frequency routers in on chip interconnects. therestofthispaperisorganizedas follows: thethreeperformance andpower management techniques are presented in section #. in section #, we elaborate on clockscaling and time stealing techniques for deploying these schemes, and the required hardware support. prior work is discussed in section #, followed by the concluding remarks in section #. figure #: an example showing actions taken by a congested router. as the core count in processor chips grows, so do the on die, shared resources such as on chip communication fabric and shared cache, which are of paramount importance for chip performance and power. several new techniques for monitoring and control are developed, and validated through full system simulations on the parsec benchmarks. these techniques reduce energy delay product by compared to a state of the art prior work. this paper presents a method for dynamic voltage frequency scaling of networks on chip and last level caches in multicore processor designs, where the shared resources form a single voltage frequency domain. together these constraints conspire to reinforce one another. a large cache in turn demands an increase of on chip communication bandwidth. indeed, on chip communication fabrics and shared, last level caches have grown to occupy a large portion of the overall die area, as much as of chip area in recent intel chip multiprocessors. networks on chip are recognized as a scalable approach to addressing the increasing demand for on chip communication bandwidth. one study shows that nocs can achieve energy savings compared to conventional bus design in a core system. nonetheless, the noc still accounts for a considerable portion of total chip power, eg, in mit raw architecture. however, noc and llc need to stay active for serving the small workload and therefore their power proportion is even greater. dvfs has been in permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies bear this notice and the full citation on the rst page. to copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speci. tensively studied for individual microprocessor cores as well as the noc. the shared resources are then divided and allocated to the core based partitions according to physical proximity. while such con guration allows a large freedom off tunings, the interdomain interfacing overhead can be quite large. this work focuses on a realistic scenario where the entire noc and llc belong to a singlef domain. as such, the interfacing overhead can be largely prevented and there is a coherent policy covering the whole of these shared resources. to the best of our knowledge, only two works have addressed dvfs for such scenario. liang and jantsch propose a rule based control scheme, using network load as the measured system performance metric. chen et al examine the motivation and advantages of the single sharedf domain in detail. they use a pi controler based on amat and a low overhead amat monitoring technique is proposed. of dvfs, there are two critical hurdles that have not been well solved. first, the impact of the noc llcf level on the chip energy performance tradeo. these prior works shy away from this problem by evaluating only parts of the chip system. is dynamic at runtime while the controls of these prior approaches are based on xed reference points. in this paper, we present remarkable progress on overcoming these hurdles. first, a throughput driven controller with dynamic reference point is examined. simultaneously, we achieve our target of performance loss. compared to the competing design, the although supply voltage change may. ect sram read write stability, kirolos and massoud show that dvfs for sram is feasible. modern multicore processor designs face challenges across multiple fronts, including: the communication bottleneck, chip and on chip, and the approaching fundamental limits of chip power density. recent designs have resorted to increasing cache size to circumvent the. when the workload is small, some cores can be shut down to save leakage power. ciency of noc and llc can be improved by dynamic voltage and frequency scaling, with the rationale that power should be provided based on dynamic need instead of a constant level. much of this prior work assumes a core centric voltage frequency domain partitioning. and cache slice occupancy, per slicef tunings makes little sense. second is a model assisted pi controller based on a new metric that bridges the gap between the noc llcf level and the chip energyperformance tradeo. the last one is a pi controller with a dynamic reference point based on the new metric. these methods are evaluated in full system simulation on the par sec benchmarks. the experimental results show that our techniques can reduce noc llc energy by and compared to a baseline xedf level and the state of the art prior work, respectively. dac, may june year#, austin, tx, usa copyright year# acm year#. furthermore, as these shared resources are utilized as a whole, with cache line interleaving homogenizing tra. in this paper, we consider the case of network on chip based multiple processor systems on chip implemented using multiple voltage and frequency islands that rely on fine grained dynamic voltage and frequency scaling for run time control of the system power dissipation. specifically, we present a framework to compute theoretical bounds on the performance of dvfs controllers for such systems under the impact of three important technology driven constraints: reliability and temperature driven upper limits on the maximum supply voltage; inductive noise driven constraints on the maximum rate of change of voltage frequency; and increasing manufacturing process variations. our experimental results show that, for the benchmarks considered, any dvfs control algorithm will lose up to performance, measured in terms of the number of steps required to reach a reference steady state, in the presence of maximum frequency and maximum frequency increment constraints. in addition, increasing process variations can lead to up to of fabricated chips being unable to meet the specified dvfs control specifications, irrespective of the dvfs algorithm used. with increased levels of integration in scaled technologies, novel on chip communication architectures that use a network on chip approach have emerged as a scalable alternative to traditional bus based or point to point communication solutions. furthermore, due to increased power density and energy consumption, nocs implemented using a multiple voltage frequency island design style have become an attractive alternative to single clock, single voltage designs. each island in a vfi system is locally clocked and has an independent voltage supply, while inter island communication is orchestrated via mixed clock, mixed voltage fi fos. the power savings result from the fact that the voltage of each island can be independently tuned to minimize the system power dissipation under performance constraints. to cope with run time variations in the workload or power characteristics of vfi systems, the voltage and frequency of each island can be dynamically scaled to exploit the slack in the application this research was funded in part by src grant year# hj year# to reduce the power dissipation under a performance budget. not surprisingly, designing appropriate dynamic voltage and frequency scaling control algorithms for run time control of vfi systems is a matter of great importance. while this problem has been addressed before by a number of authors, no attention has been given to analyzing the fundamental limits of the capabilities of dvfs controllers for multiple vfi systems. starting from these overarching ideas, in this paper, we speci cally focus on three technology driven constraints that we believe have the most impact on dvfs controller characteristics: reliability and temperature constrained upper limits on the maximum voltage and frequency at which any vfi can operate; inductive noise driven limits on the maximum rate of change of voltage and frequency; and the impact of manufacturing process variations. given the broad range of proposed dvfs control algorithms proposed in literature, we believe that it is insu cient to merely analyze the performance limits of a speci. the only assumption we make, which is common to many of the dvfs controllers proposed in literature, is that the goal of the control algorithm is to ensure that the occupancies of a pre de ned set of mixed clock, mixed voltage queues in the noc are controlled to remain at pre speci ed reference values. we then de ne the performance of a controller to be its ability to bring the queues, starting from an arbitrary initial state, back to their reference utilizations in a desired but xed number of control intervals given the technology constraints, our framework is then able to provide a theoretical guarantee on the existence of a controller that can meet this speci cation. we note that each of these factors is becoming increasingly important with technology scaling. catnap maximizes the number of consecutive idle cycles in a router, while avoiding performance loss due to overloading a subnet. multiple networks have been used in several processor implementations to scale bandwidth and ensure protocol level deadlock freedom for different message classes. in this paper, we observe that a multiple network design is also attractive from a power perspective and can be leveraged to achieve energy proportionality by effective power gating. unlike a single network design, a multiple network design is more amenable to power gating, as its subnetworks can be power gated without compromising the connectivity of the network. to exploit this opportunity, we propose the catnap architecture which consists of synergistic subnet selection and power gating policies. we evaluate a core processor with a concentrated mesh topology using synthetic traffic and applications. we show that the average network power of a power gating optimized multiple network design with four subnets could be lower than a bandwidth equivalent single network design for an average performance cost of about. energy proportional computing requires that computing systems consume proportionally lower power when the computation demand is lower. for a processor to be energy proportional, its key components, such as the on chip network must be energy proportional. as the number of cores increases, a high proportion of the processorpower will be consumed by its on chip network. borkar argues that network power for a many core die in the future could be as high as if we naively scale current network implementations. an on chip network is energy proportional if it consumes power that is proportional to the network demand and has insigni cant impact on network latency. in a many core system, even when all processor cores are actively computing, network demand may not always be near saturation. in fact, past studies have shown that real world applications exhibit bursty network traf. a few phases that consume peak network bandwidth, and other computationally intensive phases that inject few packets into the network. thus, to build an energy proportional many core processor, it is important to design energy proportional on chip networks. energy proportionality can be achieved through power gating unused network components, which reduces leakage power. at low network load, leakage power constitutes a dominant fraction of permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies bear this notice and the full citation on the rst page. to copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speci. dreslinski university of michigan university of michigan sudhirks umich edu rdreslin umich edu network power. even at network saturation, we nd that leakage power due to network components can be as high as in a core system. as the number of routers and their complexity increases to scale up the bandwidth for processors with hundreds of cores, the fraction of total power due to leakage is likely to increase. the problem is that, in a single network on chip design, even under low network load with only a few active ows, a majority of the routers in the network needs to be kept active to service those ows, signi cantly reducing the opportunities for power gating. this is unfortunate, because applications tend to contain different phases with signi cantly varying network demands. we observe that, unlike a single network on chip design, a multiple network on chip design is more amenable to power gating, and therefore is an attractive solution for scaling network bandwidth. a multi noc partitions wires and buffers into several subnetworks, and each node is connected to corresponding routers in all the subnets. to exploit this opportunity in multi noc, we must overcome several problems, which we discuss below. first, we must design a subnet selection policy that is able to expose long periods of idle time in a subnet to minimize the overheads of power gating and maximize its bene ts. a node in a multi noc is connected to several subnets, and therefore it can choose any one of the subnets to transmit a packet. conventional round robin or random subnet selection policies are inadequate, as their objective is to uniformly distribute the network load across subnets. consequently, every subnet has to service some traf, and as a result a majority of its routers needs to be kept active, squandering power gating opportunities. second, the subnet selection policy should be able to quickly adapt network bandwidth to an applicationbandwidth demands and operate ef ciently in the presence of bursty traf c. real applications are often characterized by phases of varying network utilization. when network load starts to increase, the subnet selection policy must be able to utilize higher number of subnets and avoid performance loss. when network load starts to decrease, the subnet selection policy must be able to utilize fewer subnets so that the remaining subnets can be gainfully power gated. this problem becomes particularly important for large processors with many cores. to address these problems, we propose the catnap noc architecture that employs a new subnet selection policy and a new power gating policy. catnapsubnet selection policy enforces a strict priority between subnets during injection. a packet is injected into a higher order subnet only if the current set of active subnets are getting close to congestion. this priority ordering ensures that at runtime only the required number of lower order subnets are active, while higher order subnets can be powered off. after a burst, as the network load reduces, congestion in all the subnets reduces. once the lower order subnetcongestion goes below the congestion detection threshold, they are prioritized so that new packets are not injected into the higher order networks. to determine when a router and its associated links should be turned on off, we discuss a power gating policy that works synergistically with the catnapsubnet selection policy. its objective is to maximize the sleep cycles while reducing frequent switches between power states and performance loss. in our design, a router in a subnet is turned off when its input buffers are empty for a prede ned number of consecutive cycles and the congestion status of currently active subnets is all set to false. a power gated router is woken up when either of these two conditions change. to achieve fast congestion detection, we discuss a regional congestion detection mechanism, which is the critical enabler of catnapsubnet selection policy and power gating policy. a node detects congestion in a subnet if any node in its region detects local congestion in that subnet. a node determines its local congestion status of a subnet by examining that subnetlocal router every cycle. we investigated several solutions for locally detecting congestion in a subnet. we found that some of the seemingly promising local congestion metrics, such as the local packet injection rate, did not perform well. the reason is that the injection rate threshold for determining congestion varies signi cantly by the type of network traf, which can change at runtime based on application characteristics. congestion metrics, such as occupancy of injection queue or average buffer occupancy of all ports of a router, did not perform well either. we found the maximum buffer occupancy of a local router to be the most effective local congestion metric, as it has the key advantage that its congestion threshold is independent of the network traf. also, it incurs lower design complexity than the other alternatives we considered. multi noc is attractive even from a dynamic power perspective. for low bandwidth networks with fewer nodes, the overhead of duplicating control logic across multiple routers in different subnets could be expensive in terms of area and power. however, for high bandwidth networks, a multi noc design with multiple narrower networks is more ef cient in terms of dynamic power than a bandwidth equivalent single noc design with a single wider network. the reason is that, beyond a datapath width, increasing the width of a router incurs a higher power cost than increasing the number of routers. we nd that, at a higher datapath width, the latency of a crossbar becomes the bottleneck in the router pipeline. therefore, a wider router needs to be operated at a higher voltage than a narrower router to achieve the same frequency. as power increases quadratically with respect to voltage, for high bandwidth networks, the power of a single wider router is higher than the aggregate power of multiple narrower routers. we evaluate concentrated mesh for a core system. our evaluations show that catnappower gating mechanism is effective in pro tably power gating multi nocnetwork components for as much as of execution cycles, while losing less than performance for workloads with low network demand. however, for single noc, we not only observe that there is only a negligible reduction in static power, but also that there is about a performance loss for workloads with low network demand. when averaged over different multiprogrammed workloads, we nd that the average network power of a catnap multi noc with four subnets is lower than a bandwidth equivalent single noc design, while the average performance overhead is about. this leakage problem will only compound as the technology scales down to advanced deep submicron nanometer regimes. runtime power gating has been successfully employed for various processor structures to reduce leakage power. however, solutions for power gating network components have been lacking. in fact, we nd that power gating single noc often results in signi cant performance penalty with little leakage power savings, because of frequent transitions between power states that often cause packets to wait for a power gated router to wake up. multi noc is more suitable for power gating because an entire subnet in a multi noc can be turned off without compromising the connectivity of the network. third, the power gating policy should also be to react quickly to congestion. the power gating policy determines when to wake up a router, and hence it must react quickly to congestion to avoid accruing wake up delays from powered off routers at each hop. it also ensures ef cient operation under bursty traf c. a processor with cores connected by a single concentrated mesh. buffers in on chip networks consume significant energy, occupy chip area, and increase design complexity. in this paper, we make a case for a new approach to designing on chip interconnection networks that eliminates the need for buffers for routing or flow control. we describe new algorithms for routing without using buffers in router input output ports. we analyze the advantages and disadvantages of bufferless routing and discuss how router latency can be reduced by taking advantage of the fact that input output buffers do not exist. our evaluations show that routing without buffers significantly reduces the energy consumption of the on chip cache processor to cache network, while providing similar performance to that of existing buffered routing algorithms at low network utilization. we conclude that bufferless routing can be an attractive and energy efficient design option for on chip cache processor to cache networks where network utilization is low. interconnection networks are commonly used to connect different computing components. with the arrival of chip multiprocessor systems, on chip interconnection networks have started to form the backbone of communication between cores and cores and memory within a microprocessor chip. several network onchip prototypes show that nocs consume a substantial portion of system power: in the intel core terascale chip, and in the mit raw chip. as power energy consumption has already become a limiting constraint in the design of high performance processors and future on chip networks in many core processors are estimated to consume hundreds of watts of power, simple energy and area ef cient interconnection network designs are especially desirable. previous on chip interconnection network designs commonly assumed that each router in the network needs to contain buffers to buffer the packets transmitted within the network. indeed, buffering within each router improves the bandwidth ef ciency in the network because buffering reduces the number of dropped or misrouted packets, ie, packets that are sent to a less desirable destination port. on the other hand, buffering has several disadvantages. first, buffers consume signi cant energy power: dynamic energy when read written and static energy even when they are not occupied. second, having buffers increases the complexity of the network design because logic needs to be implemented to place packets into and out of buffers. third, buffers can consume signi cant chip permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies bear this notice and the full citation on the rst page. to copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speci. area: even with a small number of total buffer entries per node where each entry can store bytes of data, a network with nodes requires kb of buffer storage. in fact, in the trips prototype chip, input buffers of the routers were shown to occupy of the total on chip network area. energy consumption and hardware storage cost of buffers will increase as future many core chips will contain more network nodes. in this paper, we propose to eliminate buffers in the design of onchip cache to cache and cache to memory networks to improve both energy and area ef ciency, as well as reduce network design complexity and router latency. the basic idea of bufferless routing is to always route a packet to an output port regardless of whether or not that output port results in the lowest distance to the destination of the packet. in other words, packets are de ected or misrouted by the router to a different output port if an output port that reduces the distance to the destination node is not available. bufferless routing has also been called hot potato routing in network theory, alluding to the scenario that the router immediately needs to pass the potato on to some other router as the potato is too hot to keep. we propose and evaluate a set of simple and practical bufferless routing algorithms, and compare them against baseline buffered algorithms in terms of on chip network energy consumption and latency. we nd that bless routing can yield substantial reductions in network energy consumption, while incurring little extra latency if the average injected traf. into the network is low, ie, below the network saturation point. we nd that in most application scenarios, due to low cache miss rates, the average injected traf. into the cache to cache and cache to memory networks is very low, making bless a potentially attractive mechanism for on chip networks. contributions: this work makes the following contributions: we propose a variety of simple and effective routing algorithms for bufferless routing. we show how bufferless routing can be effectively combined with wormhole routing. we comprehensively evaluate the network energy consumption, performance, latency, and area requirements of bufferless routing using real applications simulated on a self throttling chip multiprocessor on chip network, as well as using synthetic workloads. we show that bufferless routing can result in average network energy reduction of without signi cantly impacting application performance, while reducing network buffer area requirements by. we show how eliminating buffers can enable reductions in router latency. the reduced router latency can enable bufferless routing algorithms to outperform baseline buffered algorithms. applying error recovery monotonously can either compromise the real time constraint, or worsen the power energy envelope. neither of these violations can be realistically accepted in embedded system design, which expects ultra efficient realization of a given application. in this paper, we propose a hw sw methodology that exploits both application specific characteristics and spatial temporal redundancy. our methodology combines design time and runtime optimizations, to enable the resultant embedded processor to perform runtime adaptive error recovery operations, precisely targeting the reliability wise critical instruction executions. the proposed error recovery functionality can dynamically evaluate the reliability cost economy, determine the most profitable scheme, and adapt to the corresponding error recovery scheme, which is composed of spatial and temporal redundancy based error recovery operations. the experimental results have shown that our methodology at best can achieve fifty times greater reliability while maintaining the execution time and power deadlines, when compared to the state of the art. soft error has become one of the major reliability challenges for cmos based electronic systems. in order to resolve the adverse effect of soft error, error recovery functionality must be accommodated in the underlying system. error recovery functionality essentially has to induce a considerable amount of cost in either permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies bear this notice and the full citation on the rst page. to copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speci. basic block figure #: error vulnerability and time variation in adpcm logic gates or time. therefore, engaging error recovery mechanism for embedded computing systems, where very tight real time and power envelope constraints must be satis ed, can be a challenging design problem. traditional studies have largely achieved soft error resiliency by monotonously leveraging error recovery functionalities without the consideration of the application software and hardware. recent advances have shown promise by the use of runtime adaptive recovery techniques with one monotonous redundancy. these limitations are: unawareness of runtime workload dependent variations; invariant and in exible scheme at runtime; and, do not on combine both spatial and temporal redundancies. consequently, adopting stateof the art approaches can result in unrealistic and non optimal cost ef ciency. typically, this inef ciency can be seen in two example scenarios: wasting error recovery, which introduces the cost, for protecting the reliable executions that are inherently not vulnerable to soft errors; and, forcing error recovery, at the cost of the violating the stringent real time and power energy constraints. figure # illustrates the imbalance of relative soft error vulnerability amongst the basic blocks in an adpcm function. the green points represent the possible variation in execution time amongst those blocks. this observation suggests that, exploring an adaptive reliability solution, which takes advantage of the application speci. error vulnerability features while jointly considering both spatial and temporal redundancies, can use less resources or cost while achieving higher reliability. in order to overcome the hurdles that limit the applicability of error recovery techniques for embedded systems, we propose a novel approach that provides runtime adaptive error recovery for embedded processors. our approach focuses on addressing the above discussed problem in two ways: reliability aware static analysis: this analysis allows the error recovery functionality to precisely focus on reliability hot spot, where the soft errors have high probability to manifest at the system level. dynamic budgeting and adapting reliability: this aspect aims to let the system strategically engage one realistically optimal scheme. our novel contribution in a nutshell: in this paper, we propose raster approach that is motivated by our observation stated above. raster addresses the soft error recovery by a divide and conquer manner: error recovery functionality is decisively leveraged on those executions, in terms of instructions, which are more prone to soft errors. moreover, the error recovery functionality, which utilizes spatial or temporal redundancies, is specialized to adapt to diverse con gurations based on the available runtime resources in terms of power and execution time slack. therefore, raster approach enables more optimally ef cient and effective error recovery, particularly in embedded processors. the rest of the paper is structured as follows. section # provides a discussion of related work. section # elaborates our system model and problem formulation. section # and depict the concept and implementation of raster approach respectively. section # provides an experimental study that is followed by the conclusion in section #.