a large body of work in the data ow paradigm is in executing explicitly parallel programs, like ttda does with the id programming language. these works are orthogonal to ours, as they are attempting to target different programming models. integer linear equation explanation mvn these equations enforce that all computational vertices are mapped to exactly onevcvnv n. this constraint enforces that either a vertexinputs are either directly routed through. this enforces boundary transitivity: if there is no boundaries between and, and. pv and, then there can not be a boundary between and. this is only enforced, bv bv if all nodes can possibly map together, indicated by. this constraint makes sure that two nodes that could possibly map to each other are. the rst enforces simple timing, with an extra cycle if, tv bv lv tv a boundary exists between cfus. tv lvi tvi, pnvi, that the cfu instance cannot start until all inputs arrive. lat tv latency, which is the objective for minimization. table #: integer linear programming model for seed scheduling var param explanation gv graph of data dependencies. pv describes whether could possibly be grouped with. though its high level adaptive specialization paradigm is similar, along with some targeted code properties, the mi suite benchmarks mediabench cjpeg, djpeg, gsmdecode, gsmencode cjpeg, djpeg, enc, dec, jpg dec, jpg enc, mpeg dec, mpeg enc specint gzip, mcf, vpr, parser, bzip mcf, gcc, sjeng, astar, hmmer table #: benchmarks croarchitecture is vastly different, and will favor different codes. in terms of the microarchitecture, they are both essentially speculation free data ow execution of nested loops, and use queue like structures for data storage. for computation, mad uses a spatial grid of statically routed fus, while seed uses clustered instruction execution. mvmvbv,cv nncv npv only allowed to map to the same hardware node if they are on the same cfu instance. representing if and are mapped to different cfu instances. data ow architectures the notion of merging the bene ts of von neumann with data ow machines is far from new. in that context, iannucci proposes a hybrid architecture which adds a program counter to the ttda to execute explicitly parallel programs more ef ciently. along opposite lines, buehrer and ekanadham introduce another hybrid architecture which introduces mechanisms to support both sequential and explicitly parallel programming languages for ease of transitioning. that said, seed derives signi cant inspiration from the previous decades of data ow research. one example is the monsoon architecture, which improves the ef ciency of matching operands by using an explicit token store. this essentially eliminates complex matching hardware by allocating memory frames for instruction tokens and using offsets into the formulation here omits some details from our implementation for jointly optimizing communication and load balancing. a hardware input, or they are executed on separate instances of a cfu. tv variable for execution time of each operation. table #: scheduling notation summary the frame for token locations. our strategy of using explicit offsets into the operand buffers provides similar bene ts. core enhancements revolver in place loop execution somewhat resembles the in place nested loop acceleration of seed, but uses higher power structures. another related ooo enhancement is the forwardflow architecture, which is also a cam free execution substrate using explicit pointer based communication of values. though it is more energy ef cient than a typical ooo design, it still suffers overheads of fetch and decode, centralized register le access, and still must dynamically build the dependence graph. heterogeneity and specialization venkat et al demonstrated that due to the characteristics of existing isas, there is potential ef ciency gain through adaptive execution. our work exploits the same insight, but departs more radically from traditional von neumann isas. besides the accelerators described in the introduction, the most relevant architecture is xloops, which is a recent design targeting inner loops with speci. of seed is its ability to target coarser grain regions, enabling more effective power gating of the ooo core. another type of hybrid model is dyser, which accelerates the computation in an access execute paradigm with an explicit data ow substrate. a full system fpga based evaluation shows that dyser is best suited to data parallel workloads, where the cost of communication can be amortized with vectorization. finally, a concurrent work is the memory access data ow architecture, which augments the gpp with a data ow substrate for targeting memory access program phases. these phases occur either because the code is naturally memory intensive, or because an attached in core accelerator of oads most of the computation. conceptually, our work differs in that it explores the bene ts of hybrid data ow execution in both memory and computation intensive regions.