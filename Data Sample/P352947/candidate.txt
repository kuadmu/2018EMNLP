we show that incorporating user behavior data can significantly improve ordering of top results in real web search setting. we examine alternatives for incorporating feedback into the ranking process and explore the contributions of user feedback compared to other common web search features. we report results of a large scale evaluation over, queries and million user interactions with a popular web search engine. we show that incorporating implicit feedback can augment other features, improving the accuracy of a competitive web search ranking algorithms by as much as relative to the original performance. implicit relevance feedback for ranking and personalization has become an active area of research. recent work by joachims and others exploring implicit feedback in controlled environments have shown the value of incorporating implicit feedback into the ranking process. millions of users interact with search engines daily. they issue queries, follow some of the links in the results, click on ads, spend time on pages, reformulate their queries, and perform other actions. these interactions can serve as a valuable source of information for tuning and improving web search result ranking and can compliment more costly explicit judgments. our motivation for this work is to understand how implicit feedback can be used in a large scale operational environment to permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. how does it compare to and compliment evidence from page content, anchor text, or link based features such as inlinks or pagerank while it is intuitive that user interactions with the web search engine should reveal at least some information that could be used for ranking, estimating user preferences in real web search settings is a challenging problem, since real user interactions tend to be more noisy than commonly assumed in the controlled settings of previous studies. our paper explores whether implicit feedback can be helpful in realistic environments, where user feedback can be noisy and a web search engine already uses hundreds of features and is heavily tuned. to this end, we explore different approaches for ranking web search results using real user behavior obtained as part of normal interactions with the web search engine. the specific contributions of this paper include: analysis of alternatives for incorporating user behavior into web search ranking. an application of a robust implicit feedback model derived from mining millions of user interactions with a major web search engine. a large scale evaluation over real user queries and search results, showing significant improvements derived from incorporating user feedback. we summarize our findings and discuss extensions to the current work in section #, which concludes the paper. to copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and or a fee. this paper presents an experimental study of users assessing the quality of google web search results. in particular we look at how users satisfaction correlates with the effectiveness of google as quantified by ir measures such as precision and the suite of cumulative gain measures. results indicate strong correlation between users satisfaction, cg and precision, moderate correlation with dcg, with perhaps surprisingly negligible correlation with ndcg. the reasons for the low correlation with ndcg are examined. to our knowledge there is no previous work that directly addresses the relationship between precision, cumulative gain, discounted cumulative gain, normalized discounted cumulative gain and users satisfaction. search engines are among the most popular and useful services on the web. since the effectiveness of a retrieval system should be evaluated on the basis of how much it helps users achieve their task effectively and efficiently, the rating of search engine results by the user should be taken into account to evaluate search engines as a whole. therefore, this paper presents the relationship between these measures. current search engines do not, in general, perform well with longer, more verbose queries. one of the main issues in processing these queries is identifying the key concepts that will have the most impact on effectiveness. in this paper, we develop and evaluate a technique that uses query dependent, corpus dependent, and corpus independent features for automatic extraction of key concepts from verbose queries. we show that our method achieves higher accuracy in the identification of key concepts than standard weighting methods such as inverse document frequency. finally, we propose a probabilistic model for integrating the weighted key concepts identified by our method into a query, and demonstrate that this integration significantly improves retrieval effectiveness for a large set of natural language description queries derived from trec topics on several newswire and web collections. however, there is no explicit information in the description itself to indicate which of these concepts is more important. the concept weights are determined by how well they represent the query. automatic extraction of concepts of interest from a larger body of text have proved to be useful for summarization, keyword extraction, content targeted advertising, named entity recognition and document clustering. in this paper, we describe an extension of automatic permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies arenot made or distributed for pro. or commercial advantage and that copies bear this notice and the full citation on the rst page. to copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speci cpermission and or a fee. concept extraction methods for the task of extracting key concepts from verbose natural language queries. information retrieval research is generally more focused on keyword queries: terse queries that contain only a small selection of key words from a more verbose description of the actual information need underlying the query. trec topics illustrate the di erence between a keyword query and a description query. a trec topic consists of several parts, each of which corresponds to a certain aspect of the topic. in the example at figure #, we consider the title as a keyword query on the topic, and the description of the topic as a natural language description of the information request. number spanish civil war support provide information on all kinds of material international support provided to either side in the spanish civil war. figure #: an example of and parts of a trec topic. it might appear obvious to the reader that the key concept of the topic in figure # is spanish civil war, rather than, say, material international support, which only serves to complement the key concept. when running the query from figure # on three commercial web search engines, the rst page of the results for each of the search engines contains six, four and zero documents related to the spanish civil war, respectively. only one of the search engines returns documents mentioning international support during the war. in contrast, running the query from figure # results, for all three search engines, in all the documents returned on the rst page referring to some aspect of spanish civil war, including international support during the war. a verbose query could also potentially contain two or more equally essential key concepts. for example, consider a query what did steve jobs say about the ipod, which contains two key concepts, steve jobs and ipod, that must this example originally appeared on the powerset blog: http: blog powerset com robust gov the treatment of concept identi cation to section # that could potentially generate the actual query, and get that p. ectiveness comparison for and queries on several trec collections. be somehow related in a retrieved document in order for it to be relevant. when examining the top ten documents retrieved by three commercial web search engines in responsea common way to estimate a joint conditional probability is using a linear interpolation of the individual conditional probabilities. accordingly, we use a linear interpolation of and to estimate. applying some probability algebra, we can rank a documentin response to a queryusing an estimate to this query, we note that some of them contain only infor rank mation about a single key concept, what did the professor say check your ipod, while others contain both concepts, but with no explicit relation where is a free parameter in. in contrast, when examining the given no prior knowledge, the above is rank equivalent to top ten documents retrieved in response to a keyword query steve jobs ipod, we note that most of them discuss steve rank p, jobs in some relation to the ipod. our goal in this paper is to overcome the di culty of key concepts detection in verbose natural language queries. we hypothesize that the identi cation of the key query concepts will have a signi cant positive impact on the retrieval performance for verbose queries, which often mix several key and complementary concepts, as discussed in the above examples. treating all query concepts equally causes loss of focus on the main topics of the query in the retrieval results, eg, returning documents that discuss material international support, but not the spanish civil war. this loss of focus causes a paradoxical situation in that a keyword query that provides less information about the topic than its more verbose natural language counterpart attains better retrieval. ectiveness of the retrieval using either or query types, we note that queries consistently perform better on a variety of trec collections p we note that equation takes a general form, where each document is ranked according to the combination of its probability of generating the query itself, and a weighted sum of its probabilities of generating each implicit concept ci. as using all possible implicit concepts for ranking a document is infeasible, and moreover the probability will be close to zero for all but very few query related concepts, one may approximate the ranking above by using only. xed number of concepts with the highest weights. thus, equation may be interpreted as a query expansion technique such as local and global document analysis, latent concept expansion or query expansion using random walk models among others. alternatively, we may only consider the explicit concepts, ie, the concepts that appear in the actual query. this is the approach we take in this paper, as we are interested in discovering key concepts in verbose natural language queries. thus, equation at above reduces to table #. in this paper we: present a general probabilistic model rank p. for incorporating information about key concepts into the base query, develop a supervised machine learning technique for key concept identi cation and weighting, and empirically demonstrate that our technique can signi cantly improve retrieval. sponsored search systems are tasked with matching queries to relevant advertisements. the current state of the art matching algorithms expand the user query using a variety of external resources, such as web search results. the approach builds an expanded query representation by leveraging offline processing done for related popular queries. our experimental results show that our approach significantly improves the effectiveness of advertising on rare queries with only a negligible increase in computational cost. while these expansion based algorithms are highly effective, they are largely inefficient and cannot be applied in real time. in practice, such algorithms are applied offline to popular queries, with the results of the expensive operations cached for fast access at query time. in this paper, we describe an efficient and effective approach for matching ads against rare queries that were not processed offline. search engines provide a gateway to the web for most internet users. the second search is over the corpus of advertisements provided to the search engine through an interface or a feed from advertisers. since copyright is held by the international world wide web conference committee. distribution of these papers is limited to classroom use, and personal use by others. this typically includes matching the query against the ad text, target web site, or other information related to the user, ad, or advertiser. it is a well known fact that the volume distribution of web search queries follows the power law. the most frequent queries compose the head and torso of the curve, while the low volume, rarer queries make up the tail of the curve. for this reason, tail queries have signi cant potential for advertising revenue. the main reason for this is that tail queries are harder to interpret. we have shown in our previous work that such expanded queries can be. ectively be used to produce query rewrites for broad match. expanding them online with web results would require the sponsored search to wait for the web search to nish prior to performing ad selection, which in many cases would result in unacceptable latency. we then use the features of the topmost similar queries returned by this procedure to construct an enriched query, which is subsequently used to search over the ad space. indeed, the method can easily be applied to a variety of other search tasks that require expanding rare queries with external knowledge to improve textual matching by overcoming the vocabulary mismatch problem. other potential applications include web search, enterprise search, and social media search. second, we describe a novel approach for directly indexing query expansions for fast computation of query to query similarity. third, we propose a formalism for expanding queries with features derived from pre expanded related queries. finally, we describe a ranking and scoring method that adapts standard information retrieval techniques to the structure of the ads by modifying a unit of retrieval. next, section # explains the general architecture of our system and its various components. in section # we describe our online ad matching algorithm that leverages. they also support the web ecosystem by providing much needed tra. each query submitted to a commercial search engine results into two searches. the rst search is over the corpus of web pages crawled by the search engine. the web crawl performed by the search engine can be viewed as a pull mechanism used to obtain documents. we can view this as a search over pushed content. to commercial web sites that might otherwise not show up in the top web search results for the query. advertisers pay for the placement of their ads on the result page, the search of the ad space is commonly called sponsored search. the two main scenarios of sponsored search advertising are exact match, where advertisers specify the exact query for which the ad is to be shown, and broad match where queries are matched against ads using a broader criterion. while individually rare, tail queries make up a signi cant portion of the query volume. web search engines return results for most queries, including those in the tail of the curve. however, this is not the case for sponsored search. our evaluation of two major search engines has shown that only about of the query volume is covered by ad results. in most cases there are no ads that are explicitly associated with them by advertisers who speci cally bid on the query. furthermore, ad matching based on analyzing historical click data is also di cult, since due to the low volume it is harder to accumulate enough ad clicks to use statistical and explore exploit methods to identify good ads. search engines normally avoid displaying irrelevant ads in order not to degrade user experience, and so the current practice is not to advertise on most of the tail queries. in this paper we propose a method for online rewriting of tail queries for sponsored search. in our system, we preprocess a large number of head and torso queries. ine by expanding them with features extracted from web search results and store the results in a lookup table. at runtime, we look queries up in the table, and if the query is present, we use the expanded query to search the ad space. cient for head and torso queries, tail queries are too rare and cannot be expanded ahead of time. to solve this problem, we use the data of the pre processed queries in a di erent way. instead of an exact match lookup, we build an inverted index of the expanded query vectors, where each document represents a query and its features. at runtime, when the direct lookup into the query table fails, we use the inverted index to perform a similarity search between the userquery and the pre processed queries. although our primary focus is sponsored search, our proposed approach is rather general. the primary contributions of this paper are fourfold. cient online query expansion approach for tail queries. the remainder of this paper is laid out as follows. we begin with an introduction to sponsored search in section # and describe related work in section #. section # details our empirical evaluation over a large sponsored search data set. search engines can record which documents were clicked for which query, and use these query document pairs as soft relevance judgments. however, compared to the true judgments, click logs give noisy and sparse relevance information. we apply a markov random walk model to a large click log, producing a probabilistic ranking of documents for a given query. a key advantage of the model is its ability to retrieve relevant documents that have not yet been clicked for that query and rank those effectively. we conduct experiments on click logs from image search, comparing our random walk model to a different random walk, varying parameters such as walk length and self transition probability. the most effective combination is a long backward walk with high self transition probability. a search engine can track which of its search results were clicked for which query. for a popular system, these click records can amount to millions of query document pairs per day. each pair can be viewed as a weak indication of relevance: that the user decided to at least view the document, based on its description in the search results. although clicks are not real judgments, there is evidence that they are useful, for example as training data, as annotations, for query suggestion or directly as evidence for ranking. permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies bear this notice and the full citation on the rst page. to copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speci. we can use the clicks of past users to improve the current search results. however, the clicked set of documents is likely to di er from the current userrelevant set. other di erences are due to presentation issues; for example, the user must decide whether to click based on a short summary and is in uenced by the ordering of results. for any given search, a large number of documents are never seen by the user, therefore not clicked. from the perspective of a user conducting a search, documents that are clicked but not relevant constitute noise in the click data. documents that are relevant but not clicked constitute sparsity in the click data. one class of approaches attempts to reduce noise in click data, by building a click model that may use additional information about the userbehaviour. these approaches can signi cantly reduce noise, by identifying some clicked documents as irrelevant. this paper focuses on the sparsity problem, although our model also has noise reduction properties. the model gives a probabilistic ranking of documents, which includes relevant documents that have not yet been clicked for the current query. the sparsity problem is evidenced by power law distributions observed in click logs. most queries in the click log have a small number of clicked documents. in such cases, it is useful to identify additional relevant documents. we rst describe the click information as a graph, and survey a range of click graph applications. then we detail our markov random walk model for nding relevant documents. the subsequent sections describe a real click dataset, and empirical evaluation of the new methods. some differences arise because we are aggregating clicks across users, who may simply disagree about which documents are relevant. for example, taking into account the userbrowsing patterns after clicking a document. incorporating features extracted from clickthrough data has been demonstrated to significantly improve the performance of ranking models for web search applications. such benefits, however, are severely limited by the data sparseness problem, ie, many queries and documents have no or very few clicks. the ranker thus cannot rely strongly on clickthrough features for document ranking. this paper presents two smoothing methods to expand clickthrough data: query clustering via random walk on click graphs and a discounting method inspired by the good turing estimator. both methods are evaluated on real world data in three web search domains. experimental results show that the ranking models trained on smoothed clickthrough features consistently outperform those trained on unsmoothed features. this study demonstrates both the importance and the benefits of dealing with the sparseness problem in clickthrough data. we consider the task of ranking web search results, ie, a set of retrieved web documents are ordered by relevance to a query issued by a user. in this paper we assume that the task is performed using a ranking model that is learned on labeled training data, ie, human judged querydocument pairs. the ranking model is a function that maps the feature vector of a query document pair to a real valued relevance score. such a learned ranking model is shown to be superior to classical retrieval models largely due to its ability to integrate both traditional criteria such as tf idf and bm values, and non traditional features such as hyperlinks. in general web search, a document can be described by multiple text streams. to copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and or a fee. however, clickthrough data typically suffer from the sparseness problem. first, for a query, users only click on a very limited number of documents, thus the clicks are not complete. we refer to it as the incomplete click problem. second, for many queries and documents, no click at all is made by users. as a consequence, the clickthrough streams for most of documents are either short or empty. although one can use such raw text streams to extract some clickthrough features as in previous studies, their potential is severely limited because of the following reasons: first, with incomplete clicks, the clickrelated features that we can generate for a document query pair are also incomplete and unreliable. second, no clickthrough features can be generated for pairs without clicks. in the rankers used in most previous studies, this is equivalent to assigning zero values for clickthrough features. in ranker training, the zero valued features make a categorical difference between the documents with and without clicks, and severely penalize the documents without clicks. however, in reality, wkh wuxh gliihrence between these documents may be much smaller because a document could be unclicked for a variety of reasons even if the document is relevant. the missing click problem bears a strong resemblance to the problem of determining the frequency or probability of an unseen event, which has been well studied in the context of estimating ngram language models. various smoothing techniques have been proposed and successfully used to deal with this problem, including clustering and discounting. in the case of clickthrough data, we can consider a click for a document query pair as angram. then clickthrough data can also be smoothed in two directions: by clustering similar queries or by assigning non zero values to the clickthrough features of unclicked documents through discounting. in this paper, we propose to perform query clustering via random walk on click graphs, and a discounting method inspired by the good turing estimator. the random walk method is intended to address the incomplete click problem. in some particular settings, such as image retrieval and query classification, it has been shown that expanding clicks to similar documents and queries via random walk can lead to significant improvements. however, to our knowledge, no study has been carried out on general web search applications showing a similar improvement. our experiments show that the expanded clickthrough data is noisy, and it should be used with caution. effective improvement is possible only when we extract those features that are robust to noise for. message web design home www message uk com. msn web messenger webmessenger msn com year#: high school baseball web www hsbaseballweb come message boards htm. sprintpcs way sms messaging sprintpcs com sml guestcompose do. yahoo messenger chat, instant message messenger yahoo com year#: yahoo message boards home messages yahoo com figure #. kh txhu\ vhvvlrq iru wkh txhu\ zhe phvvdjh marked in bold are the links the user clicked on. notice that documents and queries with no click cannot be enriched through random walk. thus, inspired by the good turing method, we present a discounting method to estimate the values of the clickthrough features for the documents without clicks. our experiments will show that both smoothing techniques can significantly improve the retrieval effectiveness compared to the utilization of raw clickthrough data. in particular, the simple discounting method will prove to be effective on all the three test datasets. this series of experiments strongly indicate that sparseness is a crucial problem in clickthrough data, and an appropriate solution to this problem allows us to better take advantage of clickthrough data. in the rest of the paper, section # describes background information on clickthrough data and rankers. related work and conclusions are presented in sections and. send a wireless web message messaging sprintpcs com. users frequently modify a previous search query in hope of retrieving better results. these modifications are called query reformulations or query refinements. existing research has studied how web search engines can propose reformulations, but has given less attention to how people perform query reformulations. in this paper, we aim to better understand how web searchers refine queries and form a theoretical foundation for query reformulation. we study users reformulation strategies in the context of the aol query logs. we create a taxonomy of query refinement strategies and build a high precision rule based classifier to detect each type of reformulation. effectiveness of reformulations is measured using user click behavior. most reformulation strategies result in some benefit to the user. certain strategies like add remove words, word substitution, acronym expansion, and spelling correction are more likely to cause clicks, especially on higher ranked results. in contrast, users often click the same result as their previous query or select no results when forming acronyms and reordering words. perhaps the most surprising finding is that some reformulations are better suited to helping users when the current results are already fruitful, while other reformulations are more effective when the results are lacking. our findings inform the design of applications that can assist searchers; examples are described in this paper. of the roughly billion daily web searches made by internet users, approximately are modifications to the previous query, also known as query reformulations or query permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. to copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and or a fee. for example, a user may search for pizza seattle, but alter their query to sausage pizza seattle if they are unsatisfied with the results from the initial query. reformulations make up a large portion of web search activity. in a study of dogpile com logs, jansen et al reported that of search queries were reformulations when ignoring same queries. a study of altavista logs identified that of users reformulated their queries. search engines and humans both try hard to come up with appropriate query reformulations. many web search engines today offer query reformulation suggestions by, for example, mining query logs. users are manually reformulating their queries based on the search results from the initial query, and their knowledge and experience of how search engines work. the reformulation process is an iterative endeavor between users and search engines in getting a satisfactory set of results. while the search engine side of query reformulation has been studied extensively by the search companies and in prior information retrieval research, how users perform query reformulations has received less attention. among the benefits to understanding how people search is being able to automatically propose query reformulations. if many users searching for hummus reformulate their query to hummus recipe, the search engine can be proactive and suggest hummus recipe when the user searches for hummus. users can also benefit from an improved search experience when performing reformulations. currently, search engines present the same interface regardless of whether the user gives it a new query, same query, or query reformulation. being able to accurately detect when a user is making a query reformulation gives the search engine an opportunity to present an improved interface. the goal of this work is to look at the types of query reformulation users perform and evaluate them using effectiveness metrics such as click data. in order to study these metrics, we first construct a taxonomy of query reformulation strategies adopted by users. next, we build a classifier for these different types of reformulations. while there are some existing classifiers that determine whether a query is a reformulation, ours is the first to separate them into reformulation types. our work makes three specific contributions: a comprehensive taxonomy of query reformulation strategies defined by formal language, developed by combining the different types of reformulations reported in existing work and iterative experimentation over query logs. an unsupervised rule based classifier with high precision in detecting the different query reformulation strategies. analysis of correlations between query reformulation strategies and effectiveness metrics, giving us a better overall understanding of query reformulation strategy effectiveness. modern large retrieval environments tend to overwhelm their users by their large output. the third one computes the relative to the ideal performance of ir techniques, based on the cumulative gain they are able to yield. since all documents are not of equal relevance to their users, highly relevant documents should be identified and ranked first for presentation. in order to develop ir techniques in this direction, it is necessary to develop evaluation approaches and methods that credit ir methods for their ability to retrieve highly relevant documents. this can be done by extending traditional evaluation methods, that is, recall and precision based on binary relevance judgments, to graded relevance judgments. alternatively, novel measures based on graded relevance judgments may be developed. this article proposes several novel measures that compute the cumulative gain the user obtains by examining the retrieval result up to a given ranked position. the first one accumulates the relevance scores of retrieved documents along the ranked result list. the second one is similar but applies a discount factor to the relevance scores in order to devaluate late retrieved documents. these novel measures are defined and discussed and their use is demonstrated in a case study using trec data: sample system run results for queries in trec. as a relevance base we used novel graded relevance judgments on a four point scale. the test results indicate that the proposed measures credit ir methods for their ability to retrieve highly relevant documents and allow testing of statistical significance of effectiveness differences. the graphs based on the measures also provide insight into the performance ir techniques and allow interpretation, for example, from the user point of view. or commercial advantage, the copyright notice, the title of the publication, and its date appear, and notice is given that copying is by permission of the acm, inc. to bring such differences into daylight, both graded relevance judgments and a method for using them are required. in most laboratory tests in ir documents are judged relevant or irrelevant with regard to the request. more often relevance is con ated into two categories al at the analysis phase because of the calculation of precision and recall. the third one computes the relative to theideal performance of ir techniques, based on the cumulated gain they are able to yield. the graphs based on the measures also provide insight into the performance ir techniques and allow interpretation, for example, from the user point of view. modern large retrieval environments tend to overwhelm their users by their large output. since all documents are not of equal relevance to their users, highly relevant documents, or document components, should be identi ed and ranked rst for presentation. this is often desirable from the user point of view. in order to develop ir techniques in this direction, it is necessary to develop this research was supported by the academy of finland under the grant numbers and. authors address: department of information studies, fin university of tampere, finland; email: uta. permission to make digital hard copy of part or all of this work for personal or classroom use is granted without fee provided that the copies are not made or distributed for pro. to copy otherwise, to republish, to post on servers, or to redistribute to lists, requires prior speci. year# acm year# year# acm transactions on information systems, vol. evaluation approaches and methods that credit ir methods for their ability to retrieve highly relevant documents. the current practice of liberal binary judgment of topical relevance gives equal credit for a retrieval technique for retrieving highly and marginally relevant documents. for example, trec is based on binary relevance judgments with a very low threshold for accepting a document as relevant the document needs to have at least one sentence pertaining to the request to count as relevant. therefore differences between sloppy and excellent retrieval techniques, regarding highly relevant documents, may not become apparent in evaluation. in some studies relevance judgments are allowed to fall into more than two categories, but only a few tests actually take advantage of different relevance levels. however, graded relevance judgments may be collected in eld studies and also produced for laboratory test collections, so they are available. graded relevance judgments may be used for ir evaluation, rst, by extending traditional evaluation measures, such as recall and precision andr curves, to use them. al al arvelin, arvelin and kek ainen propose the use of each relevance level separately in recall and precision calculation. thus differentr curves are drawn for each level. they demonstrate that differing performance of ir techniques at different levels of relevancemaythusbeobservedandanalyzed kek ainenandj al arvelin generalize recall and precision calculation to directly utilize graded document relevance scores. they consider precision as a function of recall, but the approach extends to dcv based recall and precision as well. they demonstrate that the relative effectiveness of ir techniques, and the statistical signi cance of their performance differences, may vary according to the relevance scales used. in the present article we develop several new evaluation measures that seek to estimate the cumulative relevance gain the user receives by examining the retrieval result up to a given rank. the rst one accumulates the relevance scores of retrieved documents along the ranked result list. the second one is similar but applies a discount factor to the relevance scores in order to devaluate late retrieved documents. the rst two were originally presented inal arvelin and kek ainen and were also applied in the trec web track year# and in a text summarization experiment by sakai and sparck jones. these novel measures are akin to the average search length, sliding ratio, and normalized recall measures. they also have some resemblance to the ranked half life and relative relevance measures proposed by borlund and ingwersen for interactive ir. however, they offer several advantages by taking both the degree of relevance and the rank position of a document into account. the novel measures are rst de ned and discussed and then their use is demonstrated in a case study on the effectiveness of trec runs in retrieving documents of various degrees of relevance. the results indicate that the proposed measures credit ir methods for their ability to retrieve highly relevant documents and allow testing of statistical signi cance of effectiveness differences. section # explains our evaluation measures: the cumulated gain based evaluation measures. the test environment, relevance judgments, and the retrieval results are reported. section # contains discussion and section # conclusions. this paper examines the reliability of implicit feedback generated from clickthrough data in www search. analyzing the users decision process using eyetracking and comparing implicit feedback against manual relevance judgments, we conclude that clicks are informative but biased. while this makes the interpretation of clicks as absolute relevance judgments difficult, we show that relative preferences derived from clicks are reasonably accurate on average. the idea of adapting a retrieval system to particular groups of users and particular collections of documents promises further improvements in retrieval quality for at least two reasons. second, as evident from the trec evaluations, differences between document collections make it necessary to tune retrieval functions with respect to the collection for optimum retrieval performance. since manually adapting a retrieval function is time consuming or even impractical, research on automatic adaptation using machine learning is receiving much attention. ithaca, ny, usa cornell edu however, a great bottleneck in the application of machine learning techniques is the availability of training data. in this paper we explore and evaluate strategies for how to automatically generate training examples for learning retrieval functions from observed user behavior. however, implicit feedback is more di cult to interpret and potentially noisy. in this paper we analyze which types of implicit feedback can be reliably extracted from observed user behavior, in particular clickthrough data in www search. the study is designed to analyze how users interact with the list of ranked results from the google search engine and how their behavior can be interpreted as relevance judgments. first, we use eyetracking to understand how users behave on googleresults page. do users scan the results from top to bottom how many abstracts do they read before clicking how does their behavior change, if we arti cially manipulate googleranking answers to these questions give insight into the users decision process and suggest in how far clicks are the result of an informed decision. based on these results, we propose several strategies for generating feedback from clicks. to evaluate the degree to which feedback signals indicate relevance, we compare the implicit feedback against explicit feedback we collected manually. the study presented in this paper is di erent in at least two respects from previous work assessing the reliability of implicit feedback. first, our study provides detailed insight into the users decision making process through the use of eyetracking. second, we evaluate relative preference signals derived from user behavior. this is in contrast to previous studies that primarily evaluated absolute feedback. our results show that users make informed decisions among the abstracts they observe and that clicks re ect relevance judgments. however, we show that clicking decisions are biased in at least two ways. first, we show that there is a trust bias which leads to more clicks on links ranked highly by google, even if those abstracts are less relevant than other abstracts the user viewed. second, there is a quality bias: the users clicking decision is not only in uenced by the relevance of the clicked link, but also by the overall quality of the other abstracts in the ranking. we propose several strategies for extracting such relative relevance judgments from clicks and show that they accurately agree with explicit relevance judgments collected manually. first, a one size ts all retrieval function is necessarily a compromise in environments with heterogeneous users and is therefore likely to act suboptimally for many users. permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies bear this notice and the full citation on the rst page. to copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speci. in contrast to explicit feedback, such implicit feedback has the advantage that it can be collected at much lower cost, in much larger quantities, and without burden on the user of the retrieval system. to evaluate the reliability of implicit feedback signals, we conducted a user study. we performed two types of analysis in this study. this shows that clicks have to be interpreted relative to the order of presentation and relative to the other abstracts. this article examines the reliability of implicit feedback generated from clickthrough data and query reformulations in world wide web search. analyzing the users decision process using eyetracking and comparing implicit feedback against manual relevance judgments, we conclude that clicks are informative but biased. while this makes the interpretation of clicks as absolute relevance judgments difficult, we show that relative preferences derived from clicks are reasonably accurate on average. we find that such relative preferences are accurate not only between results from an individual query, but across multiple sets of results within chains of query reformulations. the idea of adapting a retrieval system to particular groups of users and particular collections of documents promises further improvements in retrieval quality for at least two reasons. second, as evident from the trec evaluations, differences between document collections make it necessary to tune retrieval functions with respect to the collection for optimum retrieval performance. since manually adapting a retrieval function is time consuming or even impractical, research on automatic adaptation using machine learning is receiving much attention. however, a great bottleneck in the application of machine learning techniques is the availability of training data. in contrast to explicit feedback, such implicit feedback has the advantage that it can be collected at much lower cost, in much larger quantities, and without burden on the user of the retrieval system. in this article we analyze which types of implicit feedback can be reliably extracted from observed user behavior, in particular clickthrough data in world wide web search. following and extending prior work reported in radlinski and joachims, joachims et al, and granka et al, we analyze implicit feedback from within individual queries as well as across multiple consecutive queries about the same information need. the feedback strategies across query chains exploit that users typically reformulate their query multiple times before their information need is satis ed. we elaborate on the query chain strategies proposed in radlinski and joachims, as well as propose and explore additional strategies. to evaluate the reliability of these implicit feedback signals, we conducted a user study. the study was designed to analyze how users interact with the list of ranked results from the google search engine and how their behavior can be interpreted as relevance judgments. first, we used eye tracking to understand how users behave on googleresults page. do users scan the results from top to bottom how many abstracts do they read before clicking how does their behavior change, if we arti cially manipulate googleranking answers acm transactions on information systems, vol. evaluating accuracy of implicit feedback in web search to these questions give insight into the users decision process and suggest in how far clicks are the result of an informed decision. based on these results, we propose several strategies for generating feedback from clicks and query reformulations. to evaluate the degree to which feedback signals indicate relevance, we compared the implicit feedback against explicit feedback we collected manually. the study presented in this article is different in at least two respects from previous work assessing the reliability of implicit feedback. second, we evaluate relative preference signals derived from user behavior. this is in contrast to previous studies that primarily evaluated absolute feedback. our results show that users make informed decisions among the abstracts they observe and that clicks re ect relevance judgments. however, we show that clicking decisions are biased in at least two ways. first, we show that there is a trust bias which leads to more clicks on links ranked highly by google, even if those abstracts are less relevant than other abstracts the user viewed. second, there is a quality of context bias: the users clicking decision is not only in uenced by the relevance of the clicked link, but also by the overall quality of the other abstracts in the ranking. this shows that clicks have to be interpreted relative to the order of presentation and relative to the other abstracts. we propose several strategies for extracting such relative relevance judgments from clicks and show that they accurately agree with explicit relevance judgments collected manually. first, our study provides detailed insight into the users decision making process through the use of eyetracking. first, a one size ts all retrieval function is necessarily a compromise in environments with heterogeneous users and is therefore likely to act suboptimally for many users. in this article we explore and evaluate strategies for how to automatically generate training examples for learning retrieval functions from observed user behavior. however, implicit feedback is more dif cult to interpret and potentially noisy. we performed two types of analysis in this study. spearman footrule and kendall tau are two well established distances between rankings. they, however, fail to take into account concepts crucial to evaluating a result set in information retrieval: element relevance and positional information. that is, changing the rank of a highly relevant document should result in a higher penalty than changing the rank of an irrelevant document; a similar logic holds for the top versus the bottom of the result ordering. we continue by extending the element weights into a distance metric between elements. we conclude by conducting simple experiments on web search data with the proposed measures. our experiments show that the weighted generalizations are more robust and consistent with each other than their unweighted counter parts. for example, in search evaluation, swapping the order of two nearly duplicate results should result in little penalty, even if these two are highly relevant and appear at the top of the list. in this work, we extend both of these metrics to those with position and element weights, and show that a variant of the diaconis graham inequality still holds the generalized two measures remain within a constant factor of each other for all permutations. we extend the distance measures to this more general case and show that they remain within a constant factor of each other. there are dozens of di erent metrics used in the literature, from classical ones like kendalltau and spearmanfootrule, neoclassical ones like map and ndcg, and much newer propositions, for example, rank distance, err, and others. the preponderance of measures leads to a natural second order question: how does one measure the measures copyright is held by the international world wide web conference committee. distribution of these papers is limited to classroom use, and personal use by others. www year#, april, year#, raleigh, north carolina, usa. evaluating metrics is indeed a di cult problem. there have been two approaches generally taken by the community. here the approach is to establish basic properties that the metric should obey, and then derive a measure that satis es these properties. kendalltau and spearmanfootrule serve as leading examples of this approach; a general version of dcg can also be seen in this light, if the axioms talk about a decreasing importance with rank and relevance. a di erent approach is to exhibit a problem with one of the standard and accepted metrics, and propose a variation that xes the problem. the new metric is then shown to generally correlate well with the old metric, except for the problematic examples, where it performs signi cantly better. overtime, variations on these variations are introduced, and we are left with dozens of metrics to chose from and report in experimental evaluations. in this paper we take an axiomatic approach. we argue that there are several criteria that any modern evaluation metric should satisfy. by now it has become evident that there are three important factors to keep in mind when computing the distance between two orderings. the metric should support element weights, which represent the relevance of a particular document or result to the query. cacy of the metric: errors at the top of the list are costlier than errors at the tail of the list, and any new metric should be re ective of this fact. finally, diversity, and, more generally, interaction between results has been recognized as an important part of result evaluation. for example, returning ve identical results may not lead to high user satisfaction even if individually each one of those results is extremely relevant. one of the reasons metrics like kendalltau remain prominent, even when their shortfalls have been widely recognized, is their inherent simplicity. it is natural to count the total number of inversions, or look at the total distance, as in the case of spearmanfootrule. however, as the metrics get richer, this simplicity is often lost. even the authors themselves lament that their new measure is not intuitive. notwithstanding the richness criteria, any proposed metric should collapse to a natural metric in cases where the richer criteria do not play a role. for example if all of the element weights are set to, or all pairwise interactions are the same, the metric should simplify to one of the classic and well known metrics. the proposed evaluation measure should satisfy some basic properties that make it easier to reason about. it should be invariant under relabeling of the elements, and, ideally, should follow the triangle inequality: for two permutationsand, the metricshould satisfy. finally, a suite of metrics all capturing the same. ect in di erent ways is much more powerful than a single new metric. typically, all of these measures have good intuition underlying them, however the formal statement for the intuition takes on di erent forms. therefore if two metrics are trying to capture the same. one of the best examples of this kind of correlation is the fact that while kendalltau and spearmanfootrule take very di erent ways of measuring distances between permutations, diaconis and graham showed that the two measures are equivalent up to a factor of. the correlation also gives freedom when trying to build on top of these metrics. as we illustrate in section # sometimes solving the problem with respect to one optimization metric is np hard, while using an equivalent metric leads to a polynomial time solution. we give new formulations of these metrics that capture element weights, position weights, and pairwise distances between permutations, while at the same time retaining their classical form. the generalized footrule distance can be seen as an distance on the right metric space, and the generalized kendalltau has a term for every inverted pair. we show that even though they take on very di erent forms, the generalized versions of these two metrics remain within a factor of three of each other, and collapse to their classical variants when all of the weights and pairwise distances are set to. intuitively, an error on a high weight element should be more signi cant than an error on a low weight element. in a similar vein, the position of the element in the list plays a large role with respect to the. in this sense, the new metric must generalize already existing metrics. the study of metrics for information retrieval is as old as the eld itself, after all, it is impossible to evaluate a result without some sort of a measure. for example, it should be scale free: that is scaling all of the weights by a the same constant factor should not change the solution. ect, but disagree greatly on some of the examples, it typically implies that neither is fully capturing the. our contributions in this work we enrich the space measured by spearmanfootrule and kendalltau to satisfy the rst condition above. traditional interactive information retrieval systems function by creating inverted lists, or term indexes. for every term in the vocabulary, a list is created that contains the documents in which that term occurs and its relative frequency within each document. retrieval algorithms then use these term frequencies alongside other collection statistics to identify the matching documents for a query. in this paper, we turn the process around: instead of indexing documents, we index query result sets. first, queries are run through a chosen retrieval system. for each query, the resulting document ids are treated as terms and the score or rank of the document is used as the frequency statistic. an index of documents retrieved by basis queries is created. with reverted indexes, standard retrieval algorithms can retrieve the matching queries for a set of documents. these recovered queries can then be used to identify additional documents, or to aid the user in query formulation, selection, and feedback. in ad hoc information retrieval, users describe their information needs by queries to search a document collection. query terms are often used with an inverted index to rank documents by estimated relevance. in query expansion based on relevance feedback, users explicitly identify relevant documents to help re ne a search iteratively. in this paper, we present and evaluate a general approach to indexing a collection for exploration using document based permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies bear this notice and the full citation on the rst page. to copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speci. reverted indexing is a variant of inverted indexing founded on the retrievability of documents by queries. while traditional inverted indexing associates terms with documents in which they occur, reverted indexing relates documents with the queries that retrieve them. to build the reverted index, we rst assemble a large set of queries, and refer to its elements as basis queries to distinguish them from the user queries that represent users information needs. basis queries can be compiled from keywords extracted from query logs or from the documents comprising the collection, or by using other conjunctive mechanisms to form more complex queries. once a set of basis queries is determined, we use a standard ranking function to order documents by their relevance to each basis query. for each document we construct the vector with elements corresponding to the basis queries and values determined by that documentestimated relevance to that basis query. this reverted index thus associates each document with the basis queries that retrieve it, as in figure #. line and does not re quire substantial computation for simple ranking functions. the process is analogous to standard term based inverted indexing. a conventional inverted indexes is a set of lists, one for each term. a given termlist contains elements for each document in which that term occurs, as in figure #. each element is weighted according to the termimportance within the corresponding document. in sum, the basic conceptual foundation for conventional inverted indexes is term occurrence, while reverted indexes are founded on document retrievability. in the next section, we review related representations for document collections. we then describe our indexing scheme in detail and present query expansion experiments that demonstrate improved performance over well regarded methods. we also show that our method reduces online computational costs, and conclude the paper with a discussion of our results and potential future extensions. this paper presents a novel approach for using clickthrough data to learn ranked retrieval functions for web search results. we observe that users searching the web often perform a sequence, or chain, of queries with a similar information need. using query chains, we generate new types of preference judgments from search engine logs, thus taking advantage of user intelligence in reformulating queries. to validate our method we perform a controlled user study comparing generated preference judgments to explicit relevance judgments. we also implemented a real world search engine to test our approach, using a modified ranking svm to learn an improved ranking function from preference data. our results demonstrate significant improvements in the ranking given by the search engine. the learned rankings outperform both a static ranking function, as well as one trained without considering query chains. many different evaluation metrics have been proposed in the ir literature, with average precision being the dominant one due a number of desirable properties it possesses. in this work, we propose a new measure of retrieval effectiveness, the graded average precision. gap generalizes average precision to the case of multi graded relevance and inherits all the desirable characteristics of ap: it has a nice probabilistic interpretation, it approximates the area under a graded precision recall curve and it can be justified in terms of a simple but moderately plausible user model. evaluation metrics play a critical role both in the context of comparative evaluation of the performance of retrieval systems and in the context of learning to rank as objective functions to be optimized. however, most of these measures, including average precision, do not incorporate graded relevance. we then evaluate gap in terms of its informativeness and discriminative power. finally, we show that gap can reliably be used as an objective metric in learning to rank by illustrating that optimizing for gap using softrank and lambdarank leads to better performing ranking functions than the ones constructed by algorithms tuned to optimize for ap or ndcg even when using ap or ndcg as the test metrics. even though di erent metrics evaluate di erent aspects of retrieval. it has an underlying theoretical basis as it corresponds to the area under the precision recall curve. it can be justi ed in terms of a simple but moderately plausible user model. given the in nite number of possible discount and gain functions, the vast di erences in users search behavior, the many di erent possible retrieval tasks and the di culty in measuring user satisfaction, a complete and rigorous analysis of the relationship between di erent gain and discount functions and user satisfaction under di erent retrieval scenarios is prohibitively expensive, if at all possible. for instance, burges et al, introduced an exponential gain function, where rel is the relevance score of the document at rankto express the fact that a highly relevant document is very much more valuable than one of a slightly lower grade. it has an underlying theoretical basis as it corresponds to the area under the graded precision recall curve. it can be justi ed in terms of a simple but moderately plausible user model similarly to ap it appears to be highly informative. this user model corresponds to one of the approaches brie. ers an alternative way of thinking about graded relevance compared to the notion of utility employed by ndcg and other multi graded metrics. we then describe some desirable properties gap possesses. in particular, we describe a probabilistic interpretation of gap, generalize precision recall curves for the multigraded relevance case and show that gap is an approximation to the area under the graded precision recall curves. evaluation metrics play a critical role both in the context of comparative evaluation of the performance of retrieval systems and in the context of learning to rank as objective functions to be optimized. many di erent evaluation metrics have been proposed and studied in the literature. ectiveness, only a few of them are widely used, with average precision being perhaps the most commonly used such metric. ap has been the dominant systemoriented evaluation metric in ir for a number of reasons: it has a natural top heavy bias. it appears to be highly informative; it predicts other metrics well. it results in good performance ranking functions when used as objective in learning to rank. the main criticism to average precision is that it is based on the assumption that retrieved documents can be considered as either relevant or non relevant to a userinformation need. thus, documents of di erent relevance grades are treated as equally important with relevance con ated into two categories. this assumption is clearly not true: by nature, some documents tend to be more relevant than others and intuitively the more relevant a document is the more important it is for a user. further, when ap is used as an objective metric to be optimized in learning to rank, the training algorithm is also missing this valuable information. for these reasons, a number of evaluation metrics that utilize multi graded relevance judgments has appeared in the literature, with ndcg being the most popular among them, especially in the context of learning to rank as most learning to rank algorithms are designed to optimize for ndcg. in the framework used to de ne ndcg, a relevance score is mapped to each relevance grade, eg, for highly relevant documents, for fairly relevant documents and so on. the relevance score of each document is viewed as the gain returned to a user when examining the document. to account for the late arrival of relevant documents gains are then discounted by a function of the rank. the discount function is viewed as a measure of the patience of a user to step down the ranked list of documents. the discounted gain values are then summed progressively from rank to. this discounted cumulative gain at rankis nally normalized in a to range to enable averaging the values of the metric over a number of queries, resulting in the normalized discounted cumulative gain, ndcg. the ndcg metric is thus a functional of a gain and a discount function and thus it can accommodate di erent user search behavior patterns on di erent retrieval task scenarios. as it has been illustrated by a number of correlation studies di erent gain and discount functions lead to radically di erent rankings of retrieval systems. ers, de ning gain and discount functions in a meaningful way is a di cult task. for this reason, in the past, the selection of the gain and discount functions has been done rather arbitrarily, based on speculations of the search behavior of an average user and speculations of the correlation of the metric to user satisfaction. further, the logarithmic discount function dominated the literature compared to the linear one based on the speculation that the gain a user obtains by moving down the ranked list of documents does not drop as sharply as indicated by the linear discount. despite the reasonable assumptions behind the choice of the gain and discount function that dominates nowadays the literature, recent work demonstrated that cumulative gain without discounting is more correlated to user satisfaction than discounted cumulative gain and ndcg. this result not only strongly questions the validity of the aforementioned assumptions but mostly underlines the di culty in specifying gain and discount functions in a meaningful manner. due to the above di culties associated with the current multigraded evaluation metrics, even when multigraded relevance judgments are available, average precision is still reported by converting the relevance judgments to binary. thus, despite the invalid assumption of binary relevance, average precision remains one of the most popular metrics used by ir researchers. furthermore, even though ap is wasting valuable information in the context of learningto rank, since it ignores the swaps between documents of di erent positive relevance grades, it has been successfully used as an objective metric. therefore, we believe that a direct extension of the metric to the multigraded case in a systematic manner is needed and it will become a valuable tool for the community both in the context of evaluation and in the context of ltr. in this paper, we generalize average precision to the multigraded relevance case in a systematic manner, proposing a new metric, the graded average precision. the gap metric is a direct extension of ap and thus it inherits all the desirable properties that average precision has: it has the same natural top heavy bias average precision has. when used as an objective function in learning to rank it results in good performance retrieval systems. the incorporation of multi graded relevance in average precision becomes possible via a simple probabilistic user model which naturally dictates to what extend documents of di erent relevance grades account for the. sakai for instance has previously introduced a multigraded measure which has been shown to behave similarly to ap for ranks above. nevertheless, the incorporation of graded relevance by themeasure follows the same model with ndcg. gap on the other hand is based on the well trusted notions of precision and recall as is ap. in what follows, we rst describe the user model on which gap is based and de ne the new metric. further, we evaluate gap in terms of informativeness and discriminative power. finally, we extend two popular ltr algorithms, softrank and lambdarank, to optimize for gap and test the performance of the resulting ranking functions over di erent collections. we propose a simple yet effective approach to context sensitive synonym discovery for web search queries based on co click analysis; ie, analyzing queries leading to clicking same documents. in addition to deriving word based synonyms, we also derive concept based synonyms with the help of query segmentation. evaluation results show that this approach dramatically outperforms the thesaurus based synonym replacement method in keeping search intent, from accuracy of to above. synonyms are words or expressions of the same language that have the same or nearly the same meaning in some or all senses. automatically discovering synonyms from text has been active topics in a variety of language processing tasks. most existing work is to create a general purpose synonym thesaurus without targeted applications. however, it is unclear how general synonyms can help a particular application. in the context of web search, we want to nd synonyms that can express the same search intent of users. discovering synonyms for web search have at least the following challenges: synonym discovery is context sensitive. although there are quite a few manually built thesauri available to provide high quality synonyms, most of these synonyms have the same or nearly the same meaning only in some senses. if we simply replace them in search queries, it is very easy to trigger search intent drift, a very bad search experience for users. for example, according to the de nition by www merriam webster com permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies bear this notice and the full citation on the rst page. to copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speci. baby and infant are treated as synonyms in many thesauri, but santa baby has nothing to do with infant not only it is a song title, which is an entity that needs special handling, but also the meaning of baby in this entity is di erent than the usual meaning of infant. the performance of web search engines may often deteriorate due to the diversity and noisy information contained within web pages. user click through data can be used to introduce more accurate description for web pages, and to improve the search performance. however, noise and incompleteness, sparseness, and the volatility of web pages and queries are three major challenges for research work on user click through log mining. in this paper, we propose a novel iterative reinforced algorithm to utilize the user click through data to improve search performance. the algorithm fully explores the interrelations between queries and web pages, and effectively finds virtual queries for web pages and overcomes the challenges discussed above. experiment results on a large set of msn click through log data show a significant improvement on search performance over the naive query log mining algorithm as well as the baseline search engine. this method works well when users queries are clear and specific. these will very likely lead to the deteriorating of the performance of web search engines, due to the gap between query space and document permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. to copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and or a fee. this problem can be partially solved by using external evidence to enrich the content of existing web pages the so called surrogate document approach. one of such examples is to use anchor texts as additional description of target web pages. previous research show that this method yields better search result than searching on web page content alone. this is because anchor texts represent the view of a web page by other web editors rather its own author. another solution is to introduce additional description by using click through data, which has not been extensively studied. user click through data can be extracted from a large amount of search logs accumulated by web search engines. these logs typically contain user submitted search queries, followed by the url of web pages which are clicked by users in the corresponding search result page. although these clicks donreflect the exact relevancy, they provide valuable indications to the users intention by associating a set of query terms with a set of web pages. if a user clicks on a web page, it is likely that the web page is relevant to the query, or at least related to some extent. many valuable applications have been proposed along this direction, such as term suggestion, query expansion, and query clustering. in this paper we try to use user click through data as the additional metadata to bridge the gap between users information need and the content of the web pages. the query log based web page metadata generation method has three important properties. first, click through data can be regarded as web searchers view of web pages, and they are more valuable than anchor texts because the performance of web search engines are evaluated by web users not editors of web pages. second, since such metadata can be combined with the content and other representations of web pages, we reduce the risk of losing relevant web pages in a pure reranking algorithm. third, the correlations between web pages and queries may evolve with the accumulation of clickthrough data. this process can reflect and update users view of web pages as time goes by. a naive method of applying user click through data is to associate the queries with the clicked web page as the metadata of the web pages. furthermore, associated queries can be found by analyzing co visited relationship of web pages, which we denoted as covisited based method. the basic assumption of the co visited method is that two web pages are similar if they are co visited by users with similar queries, and the associated queries of the two web pages can be taken as the metadata for each other. this work was conducted while the author was doing internship at microsoft research asia. however, several issues are not solved in these methods. they are: the clicks through data may be very noisy and incomplete, and introduce inaccurate metadata to associated web pages. the co visited method only considers the similarity of queries by content; it does not take into account that two queries are similar if they lead to the visit of similar web pages. such kind of similarity can be propagated between the web pages and the queries, and the effect of noisy information in clickthrough data can be constrained. existing web search engines often calculate the relevancy of web pages for a given query by counting the search keywords contained in the web pages. however, in real world, web search queries are often short and ambiguous, and web pages contain a lot diverse and noisy information.