bloom lters have been used for ip packet forwarding, and particularly the longest pre. the authors use bloom lters to determine the length of the longest matching pre. for an address and then perform a direct lookup in a large hash table in slow memory. the authors in design aleft scheme usinghash functions for ip lookups. to perform an ip lookup, they still need to access the slow memory at leasttimes. the paper stores bloom lter in the fast memory, and stores the values in a linked structure in the slow memory such that the value can be accessed via one access on the slow memory most of the times. di erent from these works, we focus on at addresses and perform the entire lookup in fast memory at the expense of a few false positives. we also propose a simple scheme that handles false positives within fast memory, and proves its reachability and stretch bound. our one bloom lter per next hop scheme is similar to their general idea of using one bloom lter to store the list of resources that can be accessed through each neighboring node. to keep up with link speed in packet forwarding with a strict fast memory size constraint, we dynamically tune the optimal size and the number of hash functions of bloom lters by keeping large xed size counting bloom lters in slow memory. buffalo is also similar to bloomier lters in that we both use a group of bloom lters, one for each value of a function that maps the key to the value. however, bloomier lters only work for a static element set. bloom lters are also been used for multicast forwarding. lipsin uses bloom lters to encode the multicast forwarding information in packets. false positives in bloom lters may cause loops in its design. lipsin caches packets that may experience loops and send the packets to a different link when a loop is detected. in contrast, our loop prevention mechanism is simple and. to handle routing changes, both and store counting bloom lters in fast memory, which uses more memory space than the bloom lters. we leverage the fact that routing changes happen on a much longer time scale than address lookup, and thus store only the bf in fast memory, and use the cbf in slow memory to handle routing changes. our idea of maintaining both the cbf and bf is similar to the work in, which uses bfs for sharing caches among web proxies. since cache contents change frequently, the authors suggest that caches use a cbf to track their own cache contents, and broadcast the corresponding bf to the other proxies. the cbf is used to avoid the cost of reconstructing the bf from scratch when an update is sent; the bf rather than the cbf is sent to the other proxies to reduce the size of broadcast messages. our idea of using one bloom lter per port is similar to spswitch which forward packets on at identi ers in content centric networks. our workshop paper applies bloom lters for enterprise edge routers by leveraging the fact that edge routers typically have a small number of next hops. the paper uses one bloom lter for each pair and discusses its. we consider at address lookup in spaf networks in this paper, and thus eliminate the. we also propose a mechanism to handle false positives in the network without extra memory. however, it does not deal with loops caused by false positives.