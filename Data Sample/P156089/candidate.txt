ethernet is vastly simpler to manage, but does not scale beyond small local area networks. this paper describes an alternative network architecture called seattle that achieves the best of both worlds: the scalability of ip combined with the simplicity of ethernet. seattle provides plug and play functionality via flat addressing, while ensuring scalability and efficiency through shortest path routing and hash based resolution of host information. ip networks today require massive effort to configure and manage. in contrast to previous work on identity based routing, seattle ensures path predictability and stability, and simplifies network management. we performed a simulation study driven by real world traffic traces and network topologies, and used emulab to evaluate a prototype of our design based on the click and xorp open source routing platforms. our experiments show that seattle efficiently handles network failures and host mobility, while reducing control overhead and state requirements by roughly two orders of magnitude compared with ethernet bridging. ethernet stands as one of the most widely used networking technologies today. due to its simplicity and ease of con guration, many enterprise and access provider networks utilize ethernet as an elementary building block. each host in an ethernet is assigned a persistent mac address, and ethernet bridges automatically learn host addresses and locations. todaylayer networks are being built on an unprecedented scale and with highly demanding requirements in terms of ef ciency and availability. large data centers are being built, comprising hundreds of thousands of computers within a single facility, and maintained by hundreds of network operators. additionally, large metro ethernet deployments contain over a million hosts and tens of thousands of bridges. ethernet is also being increasingly deployed in highly dynamic environments, such as backhaul for wireless campus networks, and transport for developing regions. first, ethernet bridging relies on network wide ooding to locate end hosts. this results in large state requirements and control message overhead that grows with the size of the network. second, ethernet forces paths to comprise a spanning tree. this not only consumes excessive resources, but also introduces security vulnerabilities and privacy concerns. network administrators sidestep ethernetinef ciencies today by interconnecting small ethernet lans using routers running the internet protocol. it also has control overhead and forwarding table sizes that are proportional to the number of subnets, rather than the number of hosts. subnetting leads to wasted address space, and laborious con guration tasks. although dhcp automates host address con guration, maintaining consistency between dhcp servers and routers still remains challenging. while the overhead of address con guration and ip routing may be reduced by provisioning vlans over a large number of, if not all, bridges, doing so reduces bene ts of broadcast scoping, and worsens data plane ef ciency due to larger spanning trees. speci cally, seattle offers the following features: a one hop, network layer dht: seattle forwards packets based on end host mac addresses. however, seattle does not require each switch to maintain state for every host, nor does it require network wide oods to disseminate host locations. exible directory service which also performs address resolution, and more exible service discovery. this allows data packets to directly traverse the shortest path, making the networkforwarding behavior predictable and stable. in contrast to conventional dhts, this update process is directly triggered by network layer changes, providing fast reaction times. for example, by observing link state advertisements, switches determine when a hostlocation is no longer reachable, and evict those invalid entries. through these approaches, seattle seamlessly supports host mobility and other dynamics. seattle switches can also handle general broadcast traf. to offer broadcast scoping and access control, seattle also provides a more scalable and exible mechanism that allows administrators to create vlans without trunk con guration. this eliminates the need to maintain a spanning tree and improves forwarding paths. cmu ethernet also leverages link state and replaces end host broadcasting by propagating host information in link state updates. however, its control plane overheads and storage requirements are similar to ethernet, as every end hostinformation is disseminated to every switch. first, these previous approaches determine paths based on a hash of the destinationidenti er, incurring a stretch penalty. in contrast, seattle does not perform identity based routing. driven caching of host information, as opposed to the traf. by only caching information that is needed to forward packets, seattle significantly reduces the amount of state required to deliver packets. in section #, we enhance existing ethernet mechanisms to make our design backwards compatible with conventional ethernet. as compared with rofl, seattle reduces state requirements required to achieve reasonably low stretch by a factor of ten, and improves path stability by more than three orders of magnitude under typical workloads. seattle also handles network topology changes and host mobility without signi cantly increasing control overhead. these plug and play permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies bear this notice and the full citation on the rst page. to copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speci. semantics simplify many aspects of network con guration. flat addressing simpli es the handling of topology changes and host mobility, without requiring administrators to reassign addresses. while an ethernet based solution becomes all the more important in these environments because it ensures service continuity and simpli es con guration, conventional ethernet has some critical limitations. spanning trees perform well for small networks which often do not have many redundant paths anyway, but introduce substantial inef ciencies on larger networks that have more demanding requirements for low latency, high availability, and traf. ip routing ensures ef cient and exible use of networking resources via shortest path routing. however, introducing ip routing breaks many of the desirable properties of ethernet. for example, network administrators must now subdivide their address space to assign ip pre xes across the topology, and update these con gurations when the network design changes. moreover, since ip addresses are not persistent identi ers, ensuring service continuity across location changes becomes more challenging. additionally, access control policies must be speci ed based on the hostcurrent position, and updated when the host moves. alternatively, operators may use virtual lans to build ip subnets independently of host location. ef ciently assigning vlans over bridges and links must also consider hosts communication and mobility patterns, and hence is hard to automate. moreover, since hosts in different vlans still require ip to communicate with one another, this architecture still inherits many of the challenges of ip mentioned above. in this paper, we address the following question: is it possible to build a protocol that maintains the same con guration free properties as ethernet bridging, yet scales to large networks to answer, we present a scalable ethernet architecture for large enterprises. instead, seattle uses the global switch level view provided by a linkstate routing protocol to form a one hop dht, which stores the location of each host. we use this network layer dht to build. driven location resolution and caching: to forward packets along shortest paths and to avoid excessive load on the directory service, switches cache responses to queries. furthermore, seattle also provides a way to piggyback location information on arp replies, which eliminates the need for location resolution when forwarding data packets. a scalable, prompt cache update protocol: unlike ethernet which relies on timeouts or broadcasts to keep forwarding tables up todate, seattle proposes an explicit and reliable cache update protocol based on unicast. this ensures that all packets are delivered based on up to date state while keeping control overhead low. despite these features, our design remains compatible with existing applications and protocols running at end hosts. for example, seattle allows hosts to generate broadcast arp and dhcp messages, and internally converts them into unicast queries to a directory service. related work our quest is to design, implement, and evaluate a practical replacement for ethernet that scales to large and dynamic networks. although there are many approaches to enhance ethernet bridging, none of these are suitable for our purposes. rbridges leverage a link state protocol to disseminate information about both bridge connectivity and host state. viking uses multiple spanning trees for faster fault recovery, which can be dynamically adjusted to conform to changing load. smartbridges allows shortest path forwarding by obtaining the network topology, and monitoring which end host is attached to each switch. this results in substantially improved control plane scalability and data plane ef ciency. while there has been work on using hashing to support at addressing conducted in parallel with our work, these works do not promptly handle host dynamics, require some packets to be detoured away from the shortest path or be forwarded along a spanning tree, and do not support hierarchical con gurations to ensure fault path isolation and the delegation of administrative control necessary for large networks. the design we propose is also substantially different from recent work on identity based routing. our solution is suitable for building a practical and easy to manage network for several reasons. instead, seattle uses resolution to map a mac address to a hostlocation, and then uses the location to deliver packets along the shortest path to the host. this reduces latency and makes it easier to control and predict network behavior. predictability and controllability are extremely important in real networks, because they make essential management tasks possible. second, the path between two hosts in a seattle network does not change as other hosts join and leave the network. this substantially reduces packet reordering and improves constancy of path performance. however, our design also consists of several generic components, such as the multi level one hop dht and service discovery mechanism, that could be adapted to the work in. roadmap: we summarize how conventional enterprise networks are built and motivate our work in section #. then we describe our main contributions in sections and where we introduce a very simple yet highly scalable mechanism that enables shortestpath forwarding while maintaining the same semantics as ethernet. we then evaluate our protocol using simulations in section # and an implementation in section #. our results show that seattle scales to networks containing two orders of magnitude more hosts than a traditional ethernet network. to reduce energy costs, these data centers employ virtual machine migration and adapt to varying workloads, placing additional requirements on agility. finally, critical bootstrapping protocols used frequently by end hosts, such as address resolution protocol and dynamic host con guration protocol, rely on broadcasting. in addition, to provide stronger fault isolation and to support delegation of administrative control, we present a hierarchical, multi level one hop dht. in enterprise networks, hosts typically communicate with a small number of other hosts, making caching highly effective. though seattle was inspired by the problems addressed in these works, it takes a radically different approach that eliminates network wide dissemination of per host information. it is accepted wisdom that the current internet architecture conflates network locations and host identities, but there is no agreement on how a future architecture should distinguish the two. one could sidestep this quandary by routing directly on host identities themselves, and eliminating the need for network layer protocols to include any mention of network location. the key to achieving this is the ability to route on flat labels. in this paper we take an initial stab at this challenge, proposing and analyzing our rofl routing algorithm. while its scaling and efficiency properties are far from ideal, our results suggest that the idea of routing on flat labels cannot be immediately dismissed. these discussions address a wide range of issues, and would take the architecture in many different directions. properly incorporate mobility, multihoming, and a more comprehensive notion of identity into the internet architecture. as long ago as saltzercommentary and the gse proposal, and probably even before that, there have been calls for separating the two, either through new addressing schemes, or through more radical architectural changes. most designs involve resolution; that is, at some point in the process, the name gets turned into a location, and the network uses this location information to deliver the packet to the destination. this location information is considered ephemeral, and only the name serves as a long term identi er. simpler allocation: unlike ip addresses, which need to be carefully allocated to ensure both uniqueness and adherence to the network topology, the allocation of identities need only ensure uniqueness. more appropriate access controls: network level access controls, which are now largely based on ip addresses, can now be applied at a more meaningful level, the identi er. the design in does not use resolution, but cannot scale if many objects donfollow the dns hierarchy. so we now ask: how can you route just on names, and how well can it be done first we need to settle what these names look like. if they are to be the cornerstone of the architecture, one would like names to serve as persistent identi ers. as argued in, though, persistence can only be achieved if the names are free of any mutable semantics. the easiest way to ensure a name has no mutable semantics is to give the name no semantics at all. at namespace, where names have no semantic content. for a variety of reasons, including the newarch project, various commentaries, nsfgeni and find programs, and pent up frustration at the current state of affairs, it has become fashionable to consider clean slate redesigns of the internet architecture. however, the one point of consensus is that any new architecture should cleanly separate location from identity the current use of ip addresses to signify both the location and the identity of an endpoint is seen as the source of many ills, including the inability to by location we mean a label that enables one to nd the object in the network, and by identity we mean a label that uniquely and persistently speci es that object. we will use the terms name and identity interchangeably throughout this paper. permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies bear this notice and the full citation on the rst page. to copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speci. all of these proposals de ne or assume the existence of a endpoint namespace, but they differ greatly in the nature of the namespace, from using fqdns, to at names, to allowing any namespace at all. despite the differences in namespaces and many other factors, there is an underlying similarity in how these proposals use endpoint names. the resolution could be done through dns, or by the network, or through some other unspeci ed process. rather than split identity from location, we get rid of location altogether. that is, we propose that the network layer not contain location information in the packet header; instead, we propose to route directly on the identities themselves this approach inherits all the advantages of the location identity split, such as mobility, multihoming, and stable identities, but also has several practical advantages of its own: no new infrastructure: there is no need for a separate name resolution system. fate sharing: packet delivery does not depend on anything off the data path, because there is no need to contact a resolution infrastructure before sending a packet. however, this design isnmotivated solely by these advantages. the real driving force is our wanting to question the implicit assumption, which has been around for as long as the internet, that we will return to these papers later when we review related work, but for now we note that triad and ipnl both routed on fqdns; however, they used resolution to reach objects that are outside of their home realm. thus, none of these three designs can scalably route on fully general identities. scalable routing requires structured location information in the packet header. one can argue for or against the desirability of at namespaces, and we certainly donhave the space to make a persuasive case here, but not only do we believe they have signi cant advantages, we also believe that if you route on any form of structured names then you are indeed back in the realm of using structure to scale routing. the technical challenge, then, is to scalably route on at labels. to our knowledge, every practical and scalable routing system depends on the structure of addresses to achieve scalability, so this is a daunting challenge indeed. our goal isnto prove that rofl can match the performance of the current internet, it is merely to see how far we can get in this direction of the design space. our quest is related to the work on compact routing, which for the internet context has been most usefully explored in. the focus there was on the asymptotic static properties of various compact routing schemes on internet like topologies, but there was no attempt to develop or analyze a dynamic routing protocol that implemented these algorithms. it is precisely that problem, the de nition and performance of a practical routing protocol on at labels, that is our focus here. while rofl falls far short of the static compact routing performance described in and elsewhere, it seems far better suited for a distributed dynamic implementation. roadmap: we start by giving a high level overview of our design in section #. we then provide a more detailed description in two parts: intradomain routing, and interdomain routing. we touch on extensions to the basic rofl design to address related concerns in routing and then discuss simulation results. current distributed routing paradigms involve a convergence process consisting of an iterative exploration of intermediate routes triggered by certain events such as link failures. the convergence process increases router load, introduces outages and transient loops, and slows reaction to failures. we propose a new routing paradigm where the goal is not to reduce the convergence times but rather to eliminate the convergence process completely. to this end, we propose a technique called failure carrying packets that allows data packets to autonomously discover a working path without requiring completely up to date state in routers. our simulations, performed using real world failure traces and rocketfuel topologies, show that: the overhead of fcp is very low, unlike traditional link state routing, fcp can provide both low loss rate as well as low control overhead, compared to prior work in backup path pre computations, fcp provides better routing guarantees under failures despite maintaining lesser state at the routers. recent large scale deployments of delay and loss sensitive applications have led to stringent demands on routing. lost or delayed packets in applications such as voice over ip, streaming media, gaming, and telecommuting video conferencing applications can result in signi cant performance degradation. isps hence have strong incentives to reduce delay and loss on their networks, permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies bear this notice and the full citation on the rst page. to copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speci. as these are often key metrics used when negotiating service level agreements associated with such applications. routing convergence is one of the key impediments to meeting strict slas. traditional routing paradigms distance vector, path vector, and link state differ substantially in the nature of the state maintained by and exchanged between routers. however, all these paradigms rely on protocol messages to alert routers about changes in the network topology. it is only after the news of a topology change has reached all routers, directly in the case of link state and indirectly in the case distance vector and path vector, that the protocol can ensure that the forwarding tables de ne consistent routes between all pairs of nodes. thus, all such routing protocols experience a convergence period after the change has been detected and before all routers learn about the change during which the routing state might be inconsistent. while the convergence process is invoked whenever link costs change, link and router failures are the events that cause the most serious problems. they can cause losses and, in some cases, trigger lsa storms, resulting in high cpu and memory utilization in routers and increased network instability. though the convergence period fundamentally depends on network properties such as the diameter of the network, it is exacerbated in practice due to system level issues such as protocol timers. the attempts to solve this problem in the literature can be roughly classi ed into three categories: designing loop free convergence protocols, reducing the convergence period of protocols, and using precomputed backup paths to route around failures. the rst category of proposals involves protocol changes to ensure that the convergence process does not cause transient loops. the second category involves reducing convergence period by tweaking protocol parameters. these mechanisms often achieve lower convergence times but at the expense of additional overhead, and lower stability. the third category deals speci cally with link failures by precomputing backup paths for links, which can be used when the link in question fails. recently, bgp proposes using precomputation based backups for fast failover during bgp convergence; bgp also provides provable guarantees such as loop prevention. these backup mechanisms typically deal with the failure of single links gracefully; however, in order to provide guarantees for simultaneous failures of multiple arbitrary links, the number of precomputed paths needed is extremely high. using the state of the art techniques, the convergence period can be eliminated for single failures, and more generally the duration and impact of convergence can be reduced. while these changes are quantitatively bene cial, they do not change the qualitative fact that these protocols could endure a convergence period during when it is hard to provide routing guarantees. in this paper, we propose a different routing paradigm, called failure carrying packets that eliminates the convergence period altogether. once a failure is detected locally, packets are guaranteed to be routed to their destination as long as a path to the destination exists in the network. fcp takes advantage of the fact that network topology in the internet does not undergo arbitrary changes. in intradomain isp networks and in the as level internet graph there is a well de ned set of potential links that does not change very often. the set of these potential links that are actually functioning at any particular time can uctuate, but the set of potential links is governed by much slower processes. thus, one can use fairly standard techniques to give all routers a consistent view of the potential set of links, which we will call the network map. fcp hence adopts a link state approach, in that every router has a consistent network map. since all routers have the same network map, all that needs to be carried by the packets is information about which of these links have failed at the current instant. this failure carrying packets approach ensures that when a packet arrives at a router, that router knows about any relevant failures on the packetprevious path. this eliminates the need for the routing protocol to immediately propagate failure information to all routers, yet allows packets to be routed around failed links in a consistent loop free manner. we also present a variant called source routing fcp that provides similar properties even if the network maps are inconsistent, at the expense of additional overhead in packet headers. though we present fcp to introduce a new routing paradigm that is qualitatively different from previous approaches, we show through simulation that it has the potential to provide quantitative bene ts as well. using real world isp topologies and failure data, we show that the overhead of using fcp in terms of computation, overhead in packet headers, and stretch incurred is very small. we also compare fcp with ospf and show that, unlike ospf, fcp can simultaneously achieve both low loss and low overhead. finally, we show that compared to prior work in backup path precomputations, fcp provides much lower loss rates while maintaining less state at the routers. though we present fcp as a link state protocol, an approach which applies directly to intradomain and enterprise routing, we believe that the same idea can be used for interdomain routing as well. to this end, we outline a strawman proposal for applying fcp to interdomain routing in section #. we leave a complete study of applying fcp to interdomain routing for future work. the sharing of caches among web proxies is an important technique to reduce web traffic and alleviate network bottlenecks. nevertheless it is not widely deployed due to the overhead of existing protocols. in this paper we propose a new protocol called summary cache; each proxy keeps a summary of the urls of cached documents of each participating proxy and checks these summaries for potential hits before sending any queries. two factors contribute to the low overhead: the summaries are updated only periodically, and the summary representations are economical as low as bits per entry. using trace driven simulations and a prototype implementation, we show that compared to the existing internet cache protocol, summary cache reduces the number of inter cache messages by a factor of to, reduces the bandwidth consumption by over, and eliminates between to of the cpu overhead, while at the same time maintaining almost the same hit ratio as icp. hence summary cache enables cache sharing among a large number of proxies. in enterprise and data center networks, the scalability of the data plane becomes increasingly challenging as forwarding tables and link speeds grow. simply building switches with larger amounts of faster memory is not appealing, since high speed memory is both expensive and power hungry. implementing hash tables in sram is not appealing either because it requires significant overprovisioning to ensure that all forwarding table entries fit. instead, we propose the buffalo architecture, which uses a small sram to store one bloom filter of the addresses associated with each outgoing link. we provide a practical switch design leveraging flat addresses and shortest path routing. buffalo gracefully handles false positives without reducing the packet forwarding rate, while guaranteeing that packets reach their destinations with bounded stretch with high probability. we tune the sizes of bloom filters to minimize false positives for a given memory size. we also handle routing changes and dynamically adjust bloom filter sizes using counting bloom filters in slow memory. our extensive analysis, simulation, and prototype implementation in kernel level click show that buffalo significantly reduces memory cost, increases the scalability of the data plane, and improves packet forwarding performance. the ethernet switches used in todayenterprise and datacenter networks do not scale well with increasing forwardingtable size and link speed. rather than continuing to build switches with ever larger and faster memory in the data plane, we believe future switches should leverage bloom lters for a more scalable and cost. memory problems in the data plane enterprises and data centers would be much easier to design and manage if the network. ered the simple abstraction of a virtual layer two switch. end hosts could be identi ed directly by their hard coded mac addresses, and retain these addresses as they change locations. the hosts could be assigned ip addresses out of a large pool, without the arti cial constraints imposed by dividing a network into many small ip subnets. however, traditional ethernet can only support this abstraction in small network topologies, due to a heavy reliance on network wide ooding and spanning tree. recent advances have made it possible to build much larger layer networks, while still identifying hosts by their mac addresses. these new architectures focus primarily on improving the control plane, enabling the use of shortest path routing protocols and. as these new technologies enable the construction of ever larger at networks, the scalability of the data plane becomes an increasingly serious problem. in todayethernet and in proposed solutions like trill, each switch maintains a forwarding table entry for each active mac address. other solutions cache a smaller number of end host mac addresses, but still require a relatively large amount of data plane state to reach every switch in the network. large networks can easily have tens or hundreds of thousands of end host mac addresses, due to the proliferation of pdas and virtual machines. in addition, link speeds are increasing rapidly, forcing the use of ever faster and, hence, more expensive and power hungry memory for the forwarding tables. this motivates us to explore new ways to represent the forwarding table that require less memory and do not require memory upgrades when the number of end hosts inevitably grows. to store the forwarding table, one simple solution is to use a hash table in sram to map mac addresses to outgoing interfaces. however, this approach requires signi cant overprovisioning the fast memory for three reasons: first, when switches are out of memory, the network will either drop packets in some architectures or crash in others. second, it is di cult and expensive to upgrade the memory for all the switches in the networks. third, collisions in hash tables require extra memory overhead to handle them, and. given these memory problems in the data plane, our goal is to make. cient use of a small, fast memory to perform packet forwarding. such small fast memory can be the or cache on commodity pcs serving as software switches, or dedicated sram on the line cards. when the memory becomes limited with the growth of forwarding table, we ensure that all packet forwarding decisions are still handled within the sram, and thus allow the switches last longer with the increase of forwarding table size. the buffalo forwarding architecture most enterprise and data center networks are spaf networks, which uses shortest path routing on addresses that are flat. leveraging the unique properties in spaf networks, we propose buffalo, a bloom filter forwarding architecture for large organizations. buf falo performs the entire address lookup for all the packets in a small, fast memory while occasionally sending the packets through a slightly longer path. to make all packet forwarding decisions with a small fast memory, we use a bloom lter, a hash based compact data structure for storing a set of elements, to perform the at address lookup. similar to previous work on resource routing, we construct one bloom lter for each next hop, and store all the addresses that are forwarded to that next hop. by checking which bloom lter theaddressesmatch, weperform the entire address lookup within the fast memory for all the packets. in contrast, previous work uses bloom lters to assist packet lookup and every address lookup still has to access the slow memory at least once. to apply our bloom lter based solution in practice, we provide techniques to resolve three issues: handling false positives: false positives are one key problem for bloom lters. we propose a simple mechanism to forward packets experiencing false positives without any memory overhead. this scheme works by randomly selecting the next hop from all the matching next hops, excluding the interface where the packet arrived. we prove that in spaf networks the packet experiencing one false positive is guaranteed to reach the destination with constant bounded stretch. we also prove that in general the packets are guaranteed to reach the destination with probability. buffalo gracefully degrades under higher memory loads by gradually increasing stretch rather than crashing or resorting to excessive ooding. in fact, in enterprise and data center networks with limited propagation delay and high speed links, a small increase in stretch would not run the risk of introducing network congestion. our evaluation with real enterprise and these studies design the algorithms of locating resources by using one bloom lter to store a list of resources that can be accessed through each neighboring node. shows that the expected stretch of buffalo is only of the length of the shortest path when each bloom lter has a false positive rate of. optimizing memory and cpu usage: to make ef cient use of limited fast memory, we optimize the sizes and number of hash functions of the bloom lters to minimize the overall false positive rate. to reduce the packet lookup time, we let the bloom lters share the same group of hash functions and reduce the memory access times for these bloom lters. through extensive analysis and simulation, we show that buffalo reduces the memory usage by compared to hash tables. handling routing dynamics: since routing changes happen on a much longer time scale than packet forwarding, we separate the handling of routing changes from the packet forwarding and use counting bloom lters in the large, slow memory to assist the update of the bloom lters. to reduce the false positive rate under routing changes, we dynamically adjust the sizes and number of hash functions of bloom lters in fast memory based on the large xed size counting bloom lters in slow memory. we implement a prototype in the click modular router running in the linux kernel. by evaluating the prototype under real enterprise and data center network topologies and tra, we show that in addition to reducing memory size, buffalo forwards packets faster than traditional hash table based implementation. buffalo also reacts quickly to routing changes with the support of counting bloom lters. the rest of the paper is organized as follows: section # describes the underlying spaf networks we focus on in this paper. section # presents an overview of the buffalo architecture. section # describes how to handle false positives and proves the packet reachability. in section #, we adjust the sizes of bloom lters to make the most. in section #, we show how to dynamically adjust the sizes of bloom lters using counting bloom lters. section # presents our prototype implementation and the evaluation. section # and discuss related work and conclude the paper. enterprise networks are important, with size and complexity even surpassing carrier networks. yet, the design of enterprise networks is ad hoc and poorly understood. in this paper, we show how a systematic design approach can handle two key areas of enterprise design: virtual local area networks and reachability control. we focus on these tasks given their complexity, prevalence, and time consuming nature. first, we show how these design tasks may be formulated in terms of network wide performance, security, and resilience requirements. our formulations capture the correctness and feasibility constraints on the design, and they model each task as one of optimizing desired criteria subject to the constraints. the optimization criteria may further be customized to meet operator preferred design strategies. second, we develop a set of algorithms to solve the problems that we formulate. third, we demonstrate the feasibility and value of our systematic design approach through validation on a large scale campus network with hundreds of routers and vlans. to date, realistic isp topologies have not been accessible to the research community, leaving work that depends on topology on an uncertain footing. in this paper, we present new internet mapping techniques that have enabled us to directly measure router level isp topologies. our techniques reduce the number of required traces compared to a brute force, all to all approach by three orders of magnitude without a significant loss in accuracy. they include the use of bgp routing tables to focus the measurements, exploiting properties of ip routing to eliminate redundant measurements, better alias resolution, and the use of dns to divide each map into pops and backbone. we collect maps from ten diverse isps using our techniques, and find that our maps are substantially more complete than those of earlier internet mapping efforts. we also report on properties of these maps, including the size of pops, distribution of router outdegree, and the inter domain peering structure. as part of this work, we release our maps to the community. realistic internet topologies are of considerable importance to network researchers. topology in uences the dynamics of routing protocols, the scalability of multicast, the ef cacy of proposals for denial of service tracing and response, and other aspects of protocol performance. some isps publish simpli ed topologies on the web, but these lack routerlevel connectivity and pop structure and may be optimistic or out of date. or commercial advantage and that copies bear this notice and the full citation on the rst page. topologies generated by tools such as gt itm or brite are representative. the main contribution of this paper is to present new measurement techniques to infer high quality isp maps while using as few measurements as possible. our insight is that routing information can be exploited to select the measurements that are most valuable. one technique, directed probing, uses bgp routing information to choose only those traceroutes that are likely to transit the isp being mapped. a second technique, path reductions, suppresses traceroutes that are likely to follow redundant paths through the isp network. these two techniques reduce the number of traces required to map an isp by three orders of magnitude compared to a bruteforce, all to all approach, and we show that the savings do not come at a high cost in terms of accuracy. we also describe a new solution to the alias resolution problem of clustering the interface ip addresses listed in a traceroute into their corresponding routers. we used our techniques to map ten diverse isps abovenet, at, ebone, exodus, level, sprint, telstra, tiscali, verio, and vsnl by using over publicly available traceroute sources as measurement vantage points. we also estimate the completeness of our maps by scanning isp ip address ranges for routers that we might have missed, and by comparing the peering links we nd with those present in bgp routing tables. as a second contribution, we examine several properties of the maps that are both of interest to researchers and likely to be useful for generating synthetic internet maps. we also characterize the distribution of router outdegree, repeating some of the analysis in with richer data. we are also making the entire raw measurement data available to researchers; all our maps are constructed with end to end measurements and without the bene. the implementation of our mapping engine, rocket copyright year# acm. sadly, real topologies are not publicly available because isps generally regard their router level topologies as con dential. there is enough uncertainty in the properties of real isp topologies that it is unclear whether synthetic permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. to copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speci. our new, pair wise alias resolution procedure nds three times as many aliases as prior techniques. additionally, we use dns information to break the isp maps into backbone and pop components, complete with their geographical location. three isps, out of the ten we measured, helped to validate our maps. our maps reveal more complete isp topologies compared to earlier efforts; we nd roughly seven times more routers and links in our area of focus than skitter. we report new results for the distribution of of pop sizes and the number of times that an isp connects with other networks. finally, as one goal of our work and part of our ongoing validation effort, we are publicly releasing the isp network maps inferred from our measurements. the rest of this paper is organized as follows. in sections and, we describe our approach and the mapping techniques re sigcomm, august, year#, pittsburgh, pennsylvania, usa. neighbors traceroute server figure #: isp networks are composed of pops and backbones. a pop consists of backbone and access routers. each traceroute across the isp discovers the path from the source to the destination. we present sample isp maps in section #. in section #, we evaluate our maps for completeness, and our techniques for their measurement ef ciency and accuracy. we analyze properties of the inferred maps in section #, present related work in section #, and conclude in section #. a large fraction of today internet applications are internally publish subscribe in nature; the current architecture makes it cumbersome and inept to support them. in essence, supporting efficient publish subscribe requires data oriented naming, efficient multicast, and in network caching. deployment of native ip based multicast has failed, and overlay based multicast systems are inherently inefficient. in this paper, we propose a novel multicast forwarding fabric, suitable for large scale topic based publish subscribe. due to very simple forwarding decisions and small forwarding tables, the fabric may be more energy efficient than the currently used ones. we surmise that scalable and efficient publish subscribe will require substantial architectural changes, such as moving from endpoint oriented systems to information centric architectures. to understand the limitations and potential, we provide efficiency and scalability analysis via simulations and early measurements from our two implementations. we show that the system scales up to metropolitan wan sizes, and we discuss how to interconnect separate networks. to copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speci. for example, rss feeds, instant messaging, presence services, many typical web site designs, and most middleware systems are either based on a publish subscribe like information paradigm or internally implement a publish subscribe system. ip multicast and application level multicast have scalability and. in this paper, we propose a novel multicast forwarding fabric. the mechanism is based on identifying links instead of nodes and using bloom lters to encode sourceroute style forwarding information into the packet header, enabling forwarding without dependency on end to end addressing. this provides native support for data oriented naming and in network caching. the forwarding decisions are simple and the forwarding tables are small, potentially allowing faster, smaller, and more energy. the proposed model aims towards balancing the state between the packet headers and the network nodes, allowing both stateless and stateful operations. the presented method takes advantage of inverting the bloom lter thinking. describe the two implementations we have built and evaluate the scalability and copyright year# acm. further, we give an indication of the potentially achievable speed from our early measurements on our netfpga based implementation. the rest of this paper is organized as follows. first, in section #, we discuss the overall problem and outline the proposed solution. section # discusses how to inter connect multiple networks, scaling towards internet wide systems, and section # brie. section # contrasts our work with related work, and section # concludes the paper. many networking applications are internally publish subscribe in nature; the actual acts of information creation permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies bear this notice and the full citation on the rst page. and consumption are decoupled in time and or space, and often there are multiple simultaneous receivers. in general, publish subscribe is a data dissemination method which provides asynchrony between data producers and consumers. rst class citizen at the naming level,cient caching to loosen the coupling between producers and consumers in the time dimension, and multicast to. ciently disseminate new data, including both user published data and systeminternal metadata. in addition to pure pub sub applications, peer to peer storage systems and some data center applications may also bene. in topic based pub sub networks, the number of topics is large while each topic may have only a few receivers. similarly, while multicast is a natural choice for data centers, it has the drawback of requiring routers to maintain additional state and performing costly address translations. cient pub sub network design is how to build a multicast infrastructure that can scale to the general internet and tolerate its failure modes while achieving both low latency and. instead of maintaining bloom lters at the network nodes and checking if incoming packets are included in the sets de ned by the lters, we put the bloom lters themselves in the packets and allow the nodes on the path to determine which outgoing links the packet should be forwarded to. in section #, we go into details of the design. next, in section #, we provide scalability evaluation of our forwarding fabric in networks up to metropolitan scales. hash tables are fundamental components of several network processing algorithms and applications, including route lookup, packet classification, per flow state management and network monitoring. these applications, which typically occur in the data path of high speed routers, must process and forward packets with little or no buffer, making it important to maintain wire speed throughout. a poorly designed hash table can critically affect the worst case throughput of an application, since the number of memory accesses required for each lookup can vary. hence, high throughput applications require hash tables with more predictable worst case lookup performance. while published papers often assume that hash table lookups take constant time, there is significant variation in the number of items that must be accessed in a typical hash table search, leading to search times that vary by a factor of four or more we present a novel hash table data structure and lookup algorithm which improves the performance over a naive hash table by reducing the number of memory accesses needed for the most time consuming lookups. this allows designers to achieve higher lookup performance for a given memory bandwidth, without requiring large amounts of buffering in front of the lookup engine. our algorithm extends the multiple hashing bloom filter data structure to support exact matches and exploits recent advances in embedded memory technology. through a combination of analysis and simulations we show that our algorithm is significantly faster than a naive hash table using the same amount of memory, hence it can support better throughput for router applications that use hash tables. a hash table is a versatile date structure for performing fast as strusociative lookups, which requires average memory accesses per lookup. these applications typically appear in the data path of high speed routers. hence, they must be able to process packets at line speed, which makes it imperative for the underlying hash tables to deliver a good lookup performance. hash tables for packet processing following is a short discussion of how various network processing applications use hash tables and why their lookup performance is important. maintaining per ow context: one of the most important applications of hash tables in network processing is in the context of maintaining connection records or per ow state. for instance, intrusion detection systems like bro and snort maintain a hash table of connection records for tcp connections. a record is created and accessed by computing a hash over the tuple of the tcp ip header. this record contains the certain information describing the connection state and is updated upon the arrival of each packet of that connection. efforts are under way to implement intrusion detection systems in hardware for line speed packet processing. in these implementations, connection records are maintained in dram. ip route lookup: ef cient hash tables are important for some ip routing lookup algorithms. lengths algorithm, which has the best theoretical performance of any sequential algorithm for the best pre. the algorithm described in, uses parallel search of on chip bloom lters to identify which of a number of off chip hash tables must be searched to nd the bestmatching pre. in, pre xes are grouped according to their lengths and stored in a set of hash tables. a binary search on these tables is performed to nd the matching pre xes of the destination ip address. each search step probes a corresponding hash table to nd a match. by storing extra information along with the member pre xes in hash tables, a match in a given table implies that the longest matching pre. is at least as long as the size of pre xes in the table, whereas a failure to match implies the longest matching pre. in the worst case, if there are wdifferent possible pre. lengths, the search requires at most lowprobes of the hash table. for ipv lookup, this means we need to perform lookups in ve hash tables. expansion we need multiple hash table lookups depending on the resulting number of unique pre. this algorithm critically demands better hash tables to preserve the performance gained by binary search. in, the authors present a hardware based lpm algorithm for ip lookup. the technique improves the performance of a regular hash table using bloom lters. in this algorithm pre xes are also grouped by length. each group is programmed in a bloom lter and all the pre xes are kept in a hash table. bloom lters are maintained in a high bandwidth and small on chip memory while the hash table resides in the slow and high volume off chip memory. before a search is initiated in the off chip table, the on chip bloom lter is probed to check if the item exists in the table. this typically allows one to perform just a single probe of the off chip table. however, if the probe of the off chip table requires multiple memory accesses, the performance of the algorithm can suffer. the bart scheme also uses hash tables for routing table lookup. it constructs simple hash functions by picking a few bits in the ip address. to bound the collisions in a hash bucket, it selects the bits for use in the hash function, based on an exhaustive search of the space of possible bit sets. this makes con guration of the lookup engine for a particular set of address pre xes cumbersome and time consuming. fundamentally, many packet classi cation algorithms rst perform a lookup on a single header eld and leverage the results to narrow down the search to a smaller subset of packet classi ers. since a lookup on the individual elds can also be performed using one of the hash table based algorithms mentioned above, improving the hash table performance also bene ts packet classi cation algorithms. the tuple space search algorithm groups the rules into a set of tuples according to their pre. each group is then stored in a hash table. the packet classi cation queries perform exact match operations on each of the hash tables corresponding to all possible tuples, given the rule set. while the algorithm analysis in was centers on the number of distinct tuples, the hash table lookup performance also directly affects the classi cation throughput. in, exact lters are used for reserved bandwidth ows and multicast in high performance routers as an auxiliary component to general packet classi cation. the search technique described in employs a hash lookup with chaining to resolve collisions. a hash key based on low order bits of the source and destination address is used to probe an on chip hash table containing valid bits. if the appropriate bit for the packet being processed is set, the hash key is used to index a table in off chip static random access memory. off chip table items are chained together if multiple lters hash to the same bucket. the hash table performance directly impacts the system throughput. the above mentioned applications illustrate the role of hashing in a variety of network processing applications and make it clear that the performance of the hash table lookup has a direct impact on their performance. related work a hash table lookup involves hash computation followed by memory accesses. while memory accesses due to collisions can be moderately reduced by using sophisticated cryptographic hash functions such as md or sha, these are dif cult to compute quickly. in the context of high speed packet processing devices, even with specialized hardware, such hash functions can take several clock cycles to produce the output. for instance, some of the existing hardware implementations of the hash cores consume more than clock cycles, which exceeds the budget of minimum packet time. moreover, the performance of such hash functions is no better than the theoretical performance with the assumption of uniform random hashing. another avenue to improve the hash table performance would be to devise a perfect hash function based on the items to be hashed. while this would deliver the best performance, searching for a suitable hash function can be a slow process and needs to be repeated whenever the set of items undergoes changes. moreover, when a new hash function is computed, all the existing entries in the table need to be re hashed for correct search. this can impede the normal operations on the hash table making it impractical in high speed processors. some applications instead settle on using a semi perfect hash function which can tolerate a predetermined collision bound. however, even searching for such a hash function can require time in the order of minutes. multiple hash functions are known to perform better than single hash functions. when we have multiple hash tables each with different hash function, the items colliding in one table are hashed into other tables. each table has smaller size and all hash functions can be computed in parallel. another multi hashing algorithm, drandom scheme, uses only one hash table but dhash functions. each item is hashed by dindependent hash functions, and the item is stored into the least loaded bucket. a search needs to examine dbuckets but the bucketaverage load is greatly reduced. a simple variation ofrandom, which is called theleft scheme is proposed to improve ip lookups; this approach generalizes the left scheme in. in this scheme, the buckets are partitioned into dsections, each time a new item needs to be inserted, it is inserted into the least loaded bucket. simulation and analysis show the performance is better thanrandom. while these ideas are similar to our fast hash table algorithm, our approach uses on chip bloom lters to eliminate the need to search multiple buckets in an off chip memory. a bloom lter can be considered a form of multi hashing. counting bloom filter extend the simple binary bloom lter by replacing each bit in the lter with a counter. this makes it possible to implement a deletion operation on the set represented by the bloom lter. some lookup mechanisms schemes use a bloom lter to avoid unnecessary searches of an off chip hash table table. while this is useful, it does nothing to reduce the time needed to perform the search of the off chip table when a search is called for. in contrast, our fast hash table algorithm fully utilizes the information gained from an extended bloom lter to optimize the exact match lookup. scope for improvement from a theoretical perspective, although hash tables are among the most extensively studied data structures with almost saturated improvements, from an engineering perspective designing a good hash table can still be a challenging task with potential for several improvements. the main engineering aspect that differentiates our hash table design from the rest is the innovative use of the advanced embedded memory technology in hardware. today it is possible to integrate a few mega bits of static random access memory with multiple access ports into a very small silicon. moreover, multiple such embedded memory cores can be incorporated in the same vlsi chip. some of the high end fpgas such as xilinx virtex ii pro contain memory blocks each with bits. we exploit the high lookup capacity offered by such memory blocks to design an ef cient hash table. at the same time it is important to note that embedded memory on its own is not suf cient to build a fast hash table when we need to maintain a large number of items having signi cant size. for instance, we can not squeeze, tcp connection records each of bytes into a hash table built with only mbits of on chip memory. since, dram is inherently slow, use of commodity memory makes it imperative to reduce the off chip memory access resulting either from collision or due to unsuccessful searches for ef cient processing. this leads us to the question: can we make use of the small but high bandwidth on chip memory to improve the lookup performance of an off chip hash table the answer to this question forms the basis of our algorithm. we use the well known data structure bloom lter, and extends it to support exact match and reduce the time required to perform this exact match. we use a small amount of on chip multiport memories to realize a counting bloom lter like data structure such that it not only answers the membership query on the search items but also helps us reduce the search time in the off chip table. the rest of the paper is organized as follows. section # illustrates our algorithms and architecture of fast hash table. in section #, we provide a detailed mathematical analysis of the proposed hash table algorithm. we also provide comparisons on the average search time and the expected collision list length of the naive hash table and our fast hash table, theoretically and experimentally, in section # and. indeed, due to its wide applicability in network packet processing, some of modern network processors provide built in hashing units. a survey of recent research literature on network packet processing reveals that hash tables are common to many applications including per ow state management, ip lookup and packet classi cation. per ow state is useful in providing qos for ows, recording measurements, and monitoring and payload analysis in intrusion detection systems. similarly, hardwarebased network monitoring systems such as netflow or adaptive netflow maintain a hash table of connection records in dram. for instance, most of the modern field programmable gate array devices contain multiple on chip embedded sram with two read write ports. thus, we must resort to using the commodity memory such sdram to store the items in the hash table. packet classi cation: hash tables are also used for some packet classi cation algorithms. exact ow matching is an important subproblem of the general packet classi cation problem, where the lookup performs an exact match on the packet tuple header elds. we introduce the bloomier filter, a data structure for compactly encoding a function with static support in order to support approximate evaluation queries. our construction generalizes the classical bloom filter, an ingenious hashing scheme heavily used in networks and databases, whose main attribute space efficiency is achieved at the expense of a tiny false positive rate. whereas bloom filters can handle only set membership queries, our bloomier filters can deal with arbitrary functions. we give several designs varying in simplicity and optimality, and we provide lower bounds to prove the optimality of our constructions. we contribute to the healthy debate on future internet design and discuss ongoing information oriented efforts. in response to the limitations of the internet architecture when used for applications for which it was not originally designed, a series of clean slate efforts have emerged to shape the so called future internet. recently, visionary voices have advised a shift in the networking problem under research, moving from seamless host reachability to internetworking of information. inspired by recent works in bloom filterlike data structures, we propose the spswitch as a novel switching engine to make wire speed forwarding decisions on flat information labels. we address part of the scalability issues in a data oriented forwarding layer by trading overdeliveries for state reduction and line speed operations. clean slate design has been a buzz term for networking project proposals. last decadeefforts towards rearchitecturing the internet have mainly focused on end host reachability with novel concepts addressing the classic end toend security, mobility and routing issues. for a few years, funding agencies around the world have been promoting the research towards the so called future internet. however, the lack of palpable results and clear business models raises doubts whether network revolution makes sense at all. todayuse of the internet reveals well known limitations in terms of mobility, security, address space exhaustion, routing and content delivery ef ciency. permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies bear this notice and the full citation on the rst page. to copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speci. rearch, december, year#, madrid, spain copyright year# acm. the internet has shifted from being a simple host connectivity infrastructure to a platform enabling massive content production and content delivery, transforming the way information is generated and consumed. from its original design, the internet carries datagrams inserted by sending hosts in a best effort manner, agnostic to the semantics and purpose of the data transport. there is a sense that the network could do more and better given that todayuse of the network is about retrieval of named pieces of data rather than speci. hence, the enhancements at the internetworking layer should not be limited to qos or routing ef ciency: data persistence, availability and authentication of the data itself leveraged with timeliness are bene cial innetwork data centric capabilities to be embraced from design. all of these proposals are more or less host centric. however, this trend is changing, and senior researchers that have participated in the internet development since its beginning, have advised tackling the future internet problem from an information interconnection perspective. van jacobsen provides a vision to understand the motivation for a networking revolution; while the rst networking generation was about wiring and the second generation was about interconnecting wires, the next generation should be about interconnecting information at large. this architectural shift implies rethinking many fundamentals by handling information as. recent concerning events may potentially promote and accelerate the adoption of new internetworking paradigms. pakistan telecom routing mis con guration for youtubeaddress block propagated internationally, breaking the reachability of the popular video service in february year#. this paper is certainly not the rst to turn into data oriented networking or to leverage the publish subscribe communication paradigm. first, we discuss on the signi cance of future internetworking research and gather a set of newly emerged concepts from ongoing information oriented internetworking activities that set the context and motivation of our work. for the long term, continuously patching the internet with adhoc protocol extensions and overlay solutions seems to be a complex and costly solution. todayeconomy is internet sensitive, service outages due to ddos attacks or due to limitations of bgp insecure routing carry important worries and ex internet reports claim potential costs of per minute for amazontwo hour outage in june year#. additionally, new forms of spam and evolving phishing methods are threatening todayso successful ipbased communicationexperience. we move a step towards the feasibility of new data oriented architectures by proposing the spswitch, a novel switching application based on recent bloom lterinspired data structures, validated through preliminary experimental results. the goals of our future work are hardware friendly forwarding schemes for a global scale information oriented architecture. as forwarding tables and link speeds continue to grow, fast packet forwarding becomes increasingly challenging for enterprise edge routers. simply building routers with ever larger amounts of ever faster memory is not appealing, since high speed memory is both expensive and power hungry. instead, we believe future enterprise routers should leverage a hierarchical memory architecture consisting of a small, fast memory and a large, slow memory. however, the conventional approach of caching popular forwarding table entries in the fast memory does not perform well in practice, especially under worst case workloads with a wide range of destination ip addresses. instead, the small memory could be used to store one bloom filter of the address blocks associated with each outgoing link. in this paper, we present techniques to make the use of bloom filters practical for enterprise edge routers, including optimizing the sizes of bloom filters with limited fast memory, handling routing changes and dynamically tuning bloom filter sizes using counting bloom filters in slow memory, and handling the small number of false positives. our evaluation shows that our scheme works well with less than mb of fast memory. fast packet forwarding is a challenge today due to the signi cant growth of the forwarding table and the increasing permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies bear this notice and the full citation on the rst page. to copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speci. jennifer rexford princeton university jrex cs princeton edu link speeds. to keep up with link speed, the large forwarding table must be stored in larger and faster memory. enterprises are more cost conscious than internet service providers, making them reluctant to use expensive, power hungry fast memory such as tcam. therefore, our design goal is to reduce memory cost and power consumption of packet forwarding by leveraging a small fast memory. enterprise edge routers introduce unique opportunities to optimize packet forwarding compared with core routers. first, enterprise edge routers usually have only a few outgoing links. we leverage this fact and propose a solution that maintains a small data structure for each next hop. second, multi homed enterprises can reach most destination pre xes through multiple upstream providers, allowing them to occasionally direct packets to a less preferred outgoing link. to provide fast packet forwarding using low cost memory, we assume a hierarchical memory structure consisting of a small, fast memory and a large, slow memory. the fast memory could be embedded sram in the line card of hardware routers, or the processor cache in a software router. for multi core platforms, the fast memory could be a group of caches associated with di erent cores, or the shared cache among cores. fast memory is expensive, so we keep its size small, usually less than mb. slow memory is cheap and can be large enough to store a conventional forwarding table data structure in its entirety. this can be a dram placed in line card or near the control plane processor in hardware routers, or the main memory in a software router. using the small, fast memory as a cache is a seemingly natural way to leverage the hierarchical memory architecture. the basic idea is to store the most frequently used entries of the forwarding table in the fast memory. in fact, route caching was once commonly used in routers. however, during cache misses, the router experiences low throughput and high packet loss. in addition, when routing changes or link failures happen, many of the cached routes are simultaneously invalidated. with a wide range of destination addresses may signi cantly increase the cache miss rate, making route caching highly ine cient. due to its bad performance under worst case workloads, route caching cannot keep up with the increasing link speeds and thus is not used in most routers today. instead, a bloom lter, a hash based compact data structure to store a set of elements, is a more suitable way to capitalize on the small, fast memory. in fact, several previous studies have proposed ways to leverage bloom lters in packet forwarding. their basic idea is to use small fast memory to assist packet address lookup by reducing the number of accesses to the slow memory. for example, in, the authors use bloom lters to determine the length of the longest matching pre. for an address, and then they refer to the entire forwarding table stored in the slow large memory to determine the outgoing link. in these works, every address lookup still must access the slow memory at least once. instead, we advocate performing the entire lookup in the fast memory. similar to the work in resource routing, one bloom lter is constructed for each next hop, and is used to store all the addresses that are forwarded to that next hop. bloom lters are constructed in the router whereis the number of next hops. this scheme works well under a wide range of workloads at the expense of a few false positives. in this paper, we provide practical techniques to apply the basic bloom lter idea to fast packet forwarding in enterprise edge routers: to make. cient use of limited fast memory, we optimize the sizes and number of hash functions of the bloom lters. surprisingly, we show that to reach the optimal overall false positive rate, bloom lters with fewer elements must have fewer false positives than those with more elements. we also prove that a smallin the enterprise edge router will lead to a small overall false positive rate. to obtain a false positive rate of, we need only kb of fast memory to store the fib of entries obtained from an edge router with next hops. to adapt bloom lters for routing changes, which happen on a much longer time scale than packet forwarding, we store counting bloom lters in the large, slow memory. to reduce the false positive rate under routing changes, we dynamically adjust the size and number of hash functions of bloom lters in fast memory by keeping large xed size counting bloom lters in slow memory. since enterprise edge routers usually have multiple upstream providers, a few false positives are allowable. we also propose multiple methods to handle false positives for enterprise edge routers. the rest of the paper is organized as follows: section # gives a brief introduction to bloom lters. section # describes our solution to perform the entire packet address lookup in small fast memory, and our enhancements for reducing computational overhead and false positives. section # evaluates the false positive rate of our solution under various settings. section # shows how we leverage counting bloom lters in slow memory to handle routing changes. section # discusses our solutions to handle false positives. sections and discuss related work and conclude the paper.