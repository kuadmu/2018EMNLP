understanding how people interact when searching is central to the study of interactive information retrieval. most of the prior work has either been conceptual, observational or empirical. while this has led to numerous insights and findings regarding the interaction between users and systems, the theory has lagged behind. in this paper, we extend the recently proposed search economic theory to make the model more realistic. we then derive eight interaction based hypotheses regarding search behaviour. to validate the model, we explore whether the search behaviour of thirty six participants from a lab based study is consistent with the theory. our analysis shows that observed search behaviours are in line with predicted search behaviours and that it is possible to provide credible explanations for such behaviours. this work describes a concise and compact representation of search behaviour providing a strong theoretical basis for future iir research. how information seekers behave and interact with information retrieval systems is a fundamental question in the area of interactive information retrieval. considerable empirical and observational research has been undertaken which has led to various ndings about users, their permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies bear this notice and the full citation on the rst page. copyrights for components of this work owned by others than the author must be honored. to copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speci. behaviours, their perceptions of systems and system performance. for example with respect to querying behaviour, it has been observed that users worked harder on systems that were less. ective by posing more queries and that they could achieve their goal by posing a series of short queries. however, users issued fewer queries when the cost of querying increased, while more experienced users posed fewer queries than inexperienced users. such observations are valuable, helping to piece together how users behave and act under various circumstances. however, it is di cult to link such ndings together as much of the empirical and observational studies have been performed independently, and have not be guided by any underlying theory. consequently, developing formal models and theories that describe, predict and explain search behaviour has been hailed as one of the grand challenges of iir. while numerous models of the information retrieval and seeking process have been developed, they have been largely conceptual in nature showing where researchers should focus their attention. however, such models do not make predictions or explain observed search behaviours, ie, they are descriptive. for example, a popular descriptive model is bates berry picking metaphor which described users as foragers, who go from patch to patch, choosing the best berries from the bushes in each patch. while this metaphor might be an apt description of how people interact with search results, it does not provide any insight into why people behave like this, nor does it help predict how people will behave under di erent circumstances. in, such models are referred as pretheoretical, in the sense that they point out the relationships between factors which can be used to develop more formal and predictive models of interaction from which hypotheses can be generated. while these lines of research have been useful, the focus has mainly been on answering the question: how people behave when searching however, a fundamental question persists: why do people behave in such ways a promising development in the late year#s was the introduction of information foraging theory, which sought to predict and explain various information interactions. under ift, for example, the berry pickeractions are quanti ed mathematically in order to make predictions about how they will behave, where it is assumed that the berry picker will seek to maximise the rate at which they acquire relevant information. the theory implies that the berry picker will stay longer in a patch when it takes them longer to get there. while ift received a lot of initial interest, most research was focused on browsing rather than applied speci cally to ad hoc topic retrieval. there has recently however been a renewed interest in developing formal models of interaction which are mathematical and computational in nature, that speci cally focus on topic retrieval. in these works the relationship between the userinteractions, the associated costs, and the bene. as a consequence, the use of such models can lead to directly testable hypotheses about search behaviour; either directly from the theory or via simulations. however, such models have been criticised because they often make numerous assumptions about users. in this paper, we will be focusing on the model of search based on economic theory. while the initial theory provided some interesting insights and explanations about how users behave, it makes a number of critical modelling assumptions which detracts from its realism and applicability. furthermore, empirical research has shown that the current theory failed to convincingly explain the observed search behaviours when tested. in this work, we propose a new model of search, addressing some of the limitations of the previous attempt. this leads to a number of deeper insights regarding search behaviours and a number of novel contributions: we provide a better explanation of observed search behaviours, we show how the model leads to a number of speci. hypotheses about search behaviour, we explain how the search behaviour of users will change as cost and performance change, and we provide a comprehensive empirical analysis contrasting actual search behaviour of thirty six participants against the theory developed. finally, we show that the predicted relationships between cost, performance and interaction hold and the observed search behaviour is consistent with the theory. we investigate whether user preference for source presentation changes during a multi session search task. the dynamic nature of multi session search tasks makes the design of a controlled experiment a non trivial challenge. we adopt a methodology based on triangulation and conduct two types of observational study: a longitudinal study and a laboratory study. we find that a stable information need over multiple sub tasks negatively influences perceived usability of the blended displays, while we do not find an influence when the information need changes. aggregated search interfaces provide users with an overview of results from various sources. two general types of display exist: tabbed, with access to each source in a separate tab, and blended, which combines multiple sources into a single result page. multi session search tasks, eg, a research project, consist of multiple stages, each with its own sub tasks. several factors involved in multi session search tasks have been found to influence user search behavior. in the longitudinal study we follow the use of tabbed and blended displays by students during a project. we find that while a tabbed display is used more than a blended display, subjects repeatedly switch between displays during the project. use of the tabbed display is motivated by a need to zoom in on a specific source, while the blended display is used to explore available material across sources whenever the information need changes. in a laboratory study students completed a multi session search task composed of three sub tasks, the first with a tabbed display, the second and third with blended displays. the tasks were manipulated by either providing three task about the same topic or about three different topics. such factors include: stages in the overall task, user search experience, user knowledge of the search topic, and complexity of individual sub tasks. the dynamic nature of multi session search tasks make the design of a controlled experiment a non trivial challenge. through questionnaires and focus group discussions we elicitate the motivation for using a particular display. in todayinformation society, organizations such as census bureaus, news companies, and archives, are making their collections of high quality information accessible through individual search interfaces. as these sources are rarely indexed by major web search engines, seeking for information across these sources requires users to sequentially go through each of them individually. aggregated search interfaces are a solution to this problem; they provide users with an overview of the results from various sources by collecting and presenting information from multiple collections. two general types of aggregated search interfaces exist: tabbed and blended. tabbed interfaces provide access to each source in separate tabs, while blended interfaces combine multiple sources into a single result page. the focus of previous work on aggregated search interfaces has been on selecting which vertical to present given a query and where to present it in the result list based on click logs, judgements or on simulations. others have investigated how users interact with aggregated search interfaces, ie, how verticals in uence user search behavior or the in uence of tabbed and blended interfaces on user behavior and preferences in single session tasks of varying complexity. a multi session search task, such as writing a report, consists of multiple information seeking tasks, each of which might be composed of its own sub tasks. several factors involved in multi session search tasks have been found to in uence user search behavior. research also shows that users apply the display which they feel will be most effective and ef cient in solving their task. for multi session research tasks this means that the preference for a tabbed or blended interface might alter between sub tasks, depending on the useridiosyncratic needs. this potential alteration is problematic for interface designers, because the prediction of which vertical to show, where, and how, requires an understanding of the relationship between the presentation options of each interface type, the user needs, and the performed sub tasks. importantly, while there is a general focus on text based media, the domain increasingly makes use of other media types too. an example here is the eld of media studies, where nding answers to hypotheses as part of the paper writing process relies on the inspection of audio visual media, related metadata and secondary literature. for the research presented in this paper we adopt a methodology based on triangulation and conduct two types of studies: a longitudinal study and a laboratory study. in our longitudinal study we follow students during a four week research project. we provide students with an interface that allows switching between a tabbed display, blended display, and blended display with. this allows for the study of display use and switching in a naturalistic setting. in a laboratory study we present students with a multi session search task consisting of three complex sub tasks. each sub task is carried out with a different display: the rst task with the tabbed display; the second task with the blended display; and the third task with the blended display with. we zoom in on the in uence of changes in information need associated with recurring search sessions by manipulating whether a subject is assigned three sub tasks about the same topic or three sub tasks about different topics. this allows us to investigate the factors associated with changes in information need and whether these in uence preference for a tabbed or blended display in different stages of a multi session search task. in section # we describe the three variants of the aggregated in terface; section # and describe the experimental setup and results of the longitudinal and laboratory study, respectively; in section # we discuss the results of both studies in light of our research questions; section # describes related work; we conclude in section #. as with any application of machine learning, web search ranking requires labeled data. the labels usually come in the form of relevance assessments made by editors. click logs can also provide an important source of implicit feedback and can be used as a cheap proxy for editorial labels. the main difficulty however comes from the so called position bias urls appearing in lower positions are less likely to be clicked even if they are relevant. in this paper, we propose a dynamic bayesian network which aims at providing us with unbiased estimation of the relevance from the click logs. experiments show that the proposed click model outperforms other existing click models in predicting both click through rate and relevance. web page ranking has been traditionally based on hand designed ranking functions such as bm. with the inclusion of thousands of features for ranking, hand tuning of ranking function becomes intractable. several machine learning algorithms have been applied to automatically optimize ranking functions. machine learned ranking requires a large number of training examples, with relevance labels indicating the degree of relevance for each querydocument pair. the cost of the editorial labeling is usually quite expensive. moreover, the relevance labels of the training examples could change over time. for example, if the query is time sensitive or recurrent, a search engine is expected to return the copyright is held by the international world wide web conference committee. distribution of these papers is limited to classroom use, and personal use by others. most up to date documents sites to the users. however, it would be prohibitive to keep all the relevance labels up to date. click logs embed important information about user satisfaction with a search engine and can provide a highly valuable source of relevance information. compare to editorial labels, clicks are much cheaper to obtain and always re ect current relevance. clicks have been used in multiple ways by a search engine: to tune search parameters, to evaluate di erent ranking functions, or as signals to directly in uence ranking. however, clicks are known to be biased, by the presentation order, the appearance of the documents, and the reputation of individual sites. many studies have attempted to account the position bias of click. carterette and jones proposed to model the relationship between clicks and relevance so that clicks can be used to unbiasedly evaluate search engine when lack of editorial relevance judgment. other research attempted to model user click behavior during search so that future clicks may be accurately predicted based on observations of past clicks. two di erent types of the click models are position models and the cascade model. a position model assumes that a click depends on both relevance and examination. each rank has a certain probability of being examined, which decays by rank and depends only on rank. a click on a url indicates that the url is examined and considered relevant by the user. however this model treats the individual urls in a search result page independently and fails to capture the interaction among urls in the examination probability. take for example two equally relevant urls for a query: a user may only click on the top one, feel satis ed, and then leave the search result page. in this case, the positional bias cannot fully explain the lack of clicks for the second url. the cascade model assumes that users examine the results sequentially and stop as soon as a relevant document is clicked. here, the probability of examination is indirectly determined by two factors: the rank of the url and the relevance of all previous urls. the cascade model makes a strong assumption that there is only one click per search and hence it could not explain the abandoned search or search with more than one clicks. even though the cascade model is quite restrictive, the authors of that paper showed that we refer to url as a shorthand for the entire display block consisting of the title, abstract and url of the corresponding result. it can predict click through rates more accurately than the position models described above. none of the above models distinguish perceived relevance and actual relevance. because users cannot examine the content of a document until they click on the url, the decision to click is made based on perceived relevance. while there is a strong correlation between perceived relevance and actual relevance, there are also many cases where they di er. in this paper, a dynamic bayesian network model is proposed to model the users browsing behavior. as in the position model, we assume that a click occurs if and only if the user has examined the url and deemed it relevant. similar to the cascade model, our model assumes that users make a linear transversal through the results and decide whether to click based on the perceived relevance of the document. the user chooses to examine the next url if he she is unsatis ed with the clicked url. our model di ers from the cascade model in two aspects: because a click does not necessarily mean that the user is satis ed with the clicked document, we attempt to distinguish the perceived relevance and actual relevance. while numerous metrics for information retrieval are available in the case of binary relevance, there is only one commonly used metric for graded relevance, namely the discounted cumulative gain. a drawback of dcg is its additive nature and the underlying independence assumption: a document in a given position has always the same gain and discount independently of the documents shown above it. inspired by the cascade user model, we present a new editorial metric for graded relevance which overcomes this difficulty and implicitly discounts documents which are shown below very relevant documents. more precisely, this new metric is defined as the expected reciprocal length of time that the user will take to find a relevant document. this can be seen as an extension of the classical reciprocal rank to the graded relevance case and we call this metric expected reciprocal rank. we conduct an extensive evaluation on the query logs of a commercial search engine and show that err correlates better with clicks metrics than other editorial metrics. in recent years many models have been proposed that are aimed at predicting clicks of web search users. in addition, some information retrieval evaluation metrics have been built on top of a user model. in this paper we bring these two directions together and propose a common approach to converting any click model into an evaluation metric. we then put the resulting model based metrics as well as traditional metrics into a common evaluation framework and compare them along a number of dimensions. one of the dimensions we are particularly interested in is the agreement between offline and online experimental outcomes. it is widely believed, especially in an industrial setting, that online atesting and interleaving experiments are generally better at capturing system quality than offline measurements. we show that offline metrics that are based on click models are more strongly correlated with online experimental outcomes than traditional offline metrics, especially in situations when we have incomplete relevance judgements. there are currently two orthogonal approaches to evaluating the quality of ranking systems. the rst approach is usually called the cran eld approach and is done. xed set of queries and documents judged by permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies bear this notice and the full citation on the rst page. copyrights for components of this work owned by others than acm or the author must be honored. to copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speci. ranking systems are then evaluated by comparing how good their ranked lists are among other things, a system is expected to place relevant documents higher than irrelevant ones. another approach described by kohavi et al makes use of real online users by assigning some portion of the users to test groups. the simplest variant, called atesting, randomly assigns some users to the control group and the treatment group. ranking systems are then compared by analysing the clicks of the users in the control against those in the treatment group. in the interleaving method by joachims users are presented with a combined list made out of two rankings. then the system that receives more clicks is assumed to be better. one of the main advantages of online evaluation schemes is that they are user based and, as a result, often assumed to give us more realistic insights into the real system quality. interleaving experiments are now widely being used by large commercial search engines like bing and yahoo as well as studied in academia. ine measurements, whereas in the traditional cran eld approach one can re use the same set of judged documents to evaluate any ranking. ine editor based evaluation methods unavoidable during the early development phase of ranking algorithms. one should take care, however, that the resulting editor based measurements agree with the outcomes of online experiments online comparison is often used as the nal validation step before releasing a new version of a ranking algorithm. in order to bring the two evaluation approaches closer to each other, we propose a method for building an. ine information retrieval metric from a user click model. click models, probabilistic models of the behavior of web search users, have been studied extensively by the ir community during the last ve years. the main purpose of predicting clicks, as seen in previous works, is: modeling user behavior when real users are not available; improving ranking using relevance inferred from clicks. we hypothesize that click models can also be turned into. ine metrics and the resulting click modelbased metrics should be closely tied to the user and hence should better correlate with online measurements than traditional. in addition, there is a growing trend to ground. ine metrics in a user model and that is exactly copyright year# acm year#. what click modeling does trying to propose a better user model. so, the question is why not use better user models, based on click behavior, as the basis for. ine metrics we put our proposal for transforming click models into metrics to the test through a set of thorough comparisons with online measurements. our comparison includes an analysis of correlations with the outcomes of interleaving experiments, an analysis of correlations with absolute online metrics, an analysis of correlations between traditional. ine metrics and our new click model based metrics, as well as an analysis of the discriminative power of the various metrics. one dimension to which we devote special attention in our comparison framework concerns unjudged documents. as was shown by buckley and voorhees, having partially judged result pages in the evaluation pool may result in biased measurements. we also show that in situations when we cannot. ord to use only fully judged data, we can still make good use of the available data by making adjustments, by either a technique called condensation or a new threshold method that we propose. the main research questions that we address in this work are: how do click model based ir metrics compare to the traditional. ine ir metrics agree with online experiments do click model based metrics show higher agreement how well do di erent. ine metrics perform in the pres ence of unjudged documents how can we modify. ine metrics to enhance agreement with online experiments our main contributions in this paper are a method for converting click models into click model based. click model based metrics with online measurements and traditional. the rest of the paper is organized as follows. section # shows how to transform a click model into a model based. in section # we examine click model based and traditional. we nish with a conclusion and discussion in section #. secondly, we present a thorough analysis and comparison of speci. a key source of bias is presentation order: the probability of click is influenced by a document position in the results page. this paper focuses on explaining that bias, modelling how probability of click depends on position. we carry out a large data gathering effort, where we perturb the ranking of a major search engine, to see how clicks are affected. we then explore which of the four hypotheses best explains the real world position effects, and compare these to a simple logistic regression model. a cascade model, where users view results from top to bottom and leave as soon as they see a worthwhile document, is our best explanation for position bias in early ranks. search engine click logs provide an invaluable source of relevance information, but this information is biased. we propose four simple hypotheses about how position bias might arise. the data are not well explained by simple position models, where some users click indiscriminately on rank or there is a simple decay of attention over ranks. as people search the web, certain of their actions can be logged by a search engine. they can also be indicative of success or failure of the engine. or commercial advantage and that copies bear this notice and the full citation on the rst page. these record which results page elements were selected for which query. click log information can be fed back into the engine, to tune search parameters or even used as direct evidence to in uence ranking. a fundamental problem in click data is position bias. the probability of a document being clicked depends not only on its relevance, but on its position in the results page. in top results lists, the probability of observing a click decays with rank. eye tracking experiments show that the user is less likely to examine results near the bottom of the list, although click probability decays faster than examination probability so there are probably additional sources of bias. our approach is to consider several such hypotheses for how position bias arises, formalising each as a simple probabilistic model. we then collect click data from a major web search engine, while deliberately ipping positions of documents in the ranked list. we nally evaluate the position bias models using the ip data, to see which is the best explanation of real world position. although our experiment involves ips, our goal is to model position bias so we can correct for it, without relying on ips. with such a model it should be possible to process a click log and extract estimates of a search resultabsolute click relevance. patterns of behaviour in logs can give an idea of the scope of user activity. when deciding which search results to permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. to copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speci. bill ramsey microsoft research, redmond usa brams microsoft com present, click logs are of particular interest. such estimates could be used in applications where an estimate of probability of click is useful such as ad ranking or evaluation. search engine click logs provide an invaluable source of relevance information but this information is biased because we ignore which documents from the result list the users have actually seen before and after they clicked. otherwise, we could estimate document relevance by simple counting. in this paper, we propose a set of assumptions on user browsing behavior that allows the estimation of the probability that a document is seen, thereby providing an unbiased estimate of document relevance. our solution outperforms very significantly all previous models. they also explain why documents situated just after a very relevant document are clicked more often. to train, test and compare our model to the best alternatives described in the literature, we gather a large set of real data and proceed to an extensive cross validation experiment. as a side effect, we gain insight into the browsing behavior of users and we can compare it to the conclusions of an eye tracking experiments by joachims et al. in particular, our findings confirm that a user almost always see the document directly after a clicked document. users permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies bearthisnoticeand thefull citationonthe rstpage tocopy otherwise, to republish, topost on servers or to redistribute tolists, requiresprior speci. benjamin piwowarski yahoo research latin america bpiwowar yahoo inc com areincreasingly understood tobethedrivingforceof theinternet and many initiatives are aimed at empowering them. social search, as its name implies, supposes participation from users who tag, bookmark, andcomment their search results. in addition to this information explicitly provided by users, there is a much larger source of implicit data which is collectedby search engines. itis apoll of millions of users over an enormous variety of topics. examples of applicationsincludewebpersonalization, web spam detection, query term recommendation. unlike human tags and bookmarks, implicit feedback is also not biased towards socially active web users. that is, the data is collected from all users, notjust usersthat choosetoedit a wikipage, orjoin a social network such asmyspace orfriendster. click data seems the perfect source of information when deciding whichdocuments to showin answerto a query. this information can be fed back into the engine, to tune search parameters or even used asdirect evidencetoin uence ranking. nevertheless, they cannot be used without further processing: a fundamental problem is the position bias. the probability of a document being clicked depends not only on its relevance, but on other factors as its position in the result page. contributions user activity models within web search can be broadly divided in three categories: analysis models where the aim istogaininsightintotypical userbehavior, modelsthat try topredictthenext useraction, and eventually models that estimate the attractiveness or perceived relevance of a document independently of the layout in uence. this work focusses on thelatter, usingas the only source ofinformation the web search logs produced by the search engines. yet users do not browse the whole list and documents situated earlier in the rankinghave ahigherprobability ofbeing examined. as a consequence, they also have a higher probability of being clicked independently of how relevant they are. if we could estimatetheprobability that adocumentis examined by the user, we could estimate its relevance as the ratio of the number of times a user clicked on the document to the expected number of times the document is examined. the main contribution of this work is a model of user browsing behavior when consulting a page of search results. this model estimates the probability of examination of a documentgiven the rankofthedocument andthedistance to the last clicked document. our model sheds light on user behavior, is in agreement with the user experiments ofgranka et al and extends andquanti esthe user model ofjoachims et al. in section # we review the literature for click models and we present our contributions. in section # we compare the predicting abilities on unseen data of the di erent models. westudy in moredetailstheimplications of theuserbrowsing model and we relate the ndings with the eye tracking experiments of insection. social search is quickly gaining acceptance as a promising way of harnessing the common knowledge of millions of users to help each other and search more. arguably, this is a long term trend that started with kleinberg idea of hubs and authorities, which proposed that a hyperlink from one document to another was a vote in favor of the document linked to, an idea in practice exploited in the pagerank algorithm. thisfeedbackprovidesdetailed and valuable information about users interactions with the system as theissuedquery, thepresentedurls, the selected documents and their ranking. it has been used in many ways to mine user interests and preferences. it can be thought as the result of users voting in favor of the documents they nd interesting. in top results lists, the probability of observing a click decays with rank. eye tracking experiments show that a user is less likely to examine results near the bottom of the list, although click probability decays faster than examination probability so there are probably additional sources of bias. experiments also show that a document is not clicked with the same frequency if situated after a highly relevant or a mediocre document. if the users looked with attention all the documents in the ranking list, the relevance of one of them could be estimated simply by counting thenumberof timesitisselected. search systems use context to effectively satisfy a user information need as expressed by a query. tasks are important factors in determining user context during search and many studies have been conducted that identify tasks and task stages through users interaction behavior with search systems. queries are the most pervasive input from users to express their information need regardless of the input method, eg, typing keywords or clicking facets. instead of characterizing interaction behavior in terms of interface specific components, we propose to characterize users search behavior in terms of two types of query modification: direct modification, which refers to reformulations of queries; and indirect modification, which refers to user operations on additional input components provided by various search interfaces. we investigate the utility of characterizing task stages through direct and indirect query reformulations in a case study and find that it is possible to effectively differentiate subsequent stages of the search task. we found that describing user interaction behavior in such a generic form allowed us to relate user actions to search task stages independent from the specific search interface deployed. the next step will then be to validate this idea in a setting with a wider palette of search tasks and tools. the type of interaction available to users, however, depends on the type of search interface features available. in order to effectively satisfy users information needs as expressed by a query, search systems use context. many forms of context exist, including previous queries issued and users interac permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies bear this notice and the full citation on the rst page. copyrights for components of this work owned by others than the author must be honored. to copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speci. arjen de vries centrum wiskunde en informatica science park, year#xg amsterdam, the netherlands arjen de vries cwi nl tions with search systems. to correctly interpret contextual signals it is important to determine the underlying factors causing these signals. one salient factor that determines the context of a user is the task type and task stage in which the user is engaged. tasks can range from simple factual search to complex multi session search tasks and can consist of single or multiple stages. the interac tion of the user with the search system may change depending on task type and task stage. for example, vakkari et al found that students term addition and removal behavior changes during various stages of a research project. for dif cult tasks, studies found that users tend to formulate more diverse queries and use more advanced query operators. in exploratory search tasks, users prefer more advanced interface features such as facets and comparisons. work on aggregated search interfaces found that users have a tendency to click on results from more and more diverse facets in complex tasks. independently each of these stud ies contributes to our understanding of user interaction with various types of systems across different tasks and stages. the interaction patterns discovered, however, depend on the type of system used in the study, eg, a web search engine provides less interface features for interaction than an exploratory search system. queries are the most pervasive input from users to express their information need regardless of the input method, eg, submitting a query by typing keywords in a search box or modifying a query by clicking a facet. therefore, users queries and the associated query formulation behavior provide a consistent feature to determine task type and stage. we propose to characterize users search behavior in terms of two types of query modi cation: direct modi cation, which refers to reformulations of queries, such as adding, removing or substituting terms in consecutive queries; and indirect modi cation, which refers to user operations on additional input components provided by various search interfaces such as using lters, and switching between collections. we report on a case study that investigates how users search behavior changes throughout different stages of their search task. we focus on two types of search behavior, exploration and focused search, and how these behaviors are re ected in users interaction with a system in terms of direct as well as indirect query modi cations. we follow students during a four week project. the research project represents a complex search task spanning multiple sessions and stages. we con rm empirically that subjects exhibit different query modi cation patterns during the various stages of the task. our contribution is a demonstration of the effectiveness of using direct and indirect query modi cations as a way of characterizing different stages of a complex multi session search task. the ben figure #: a screen shot of the aggregated search interface. interactions to more general interaction types, ie, exploration vs. we provide students with an interface that provides various interface options, eg, facets, verticals, and aggregated display. focused search, is that interactions observed with different interfaces become comparable. typical crowdsourcing tasks ask workers to label images or make relevance judgements, as a low cost alternative to lab based user studies. more recently, gamification has been employed as a way to make these tasks more appealing and so users play, rather than work. one observation is that differences in task design and incentives elicits different player behavior. care should be taken in the design of a gamified version of such a task to allow players to complete tasks with a limited amount of effort and time, without changing the behavior to be studied. we discuss the motivation of the abstractions and design choices we have made in achieving this goal. we then analyze whether and how these abstractions and design choices influence our observations of player behaviors. in this paper we discuss a new type of task, where we aim at eliciting player behavior that resembles user behavior when performing a search task. crowdsourcing as a collective problem solving approach has many applications. to increase user engagement, and to subsequently improve the quantity and quality of the crowd sourced tasks, often game elements such as a high score boards, badges, and progress bars are introduced. researchers have successfully applied gami cation for different types of task. the main type of tasks involves asking workers to provide objective answers for labelling or classi cation tasks, eg, to recognize whether there is a certain object in a video, or more specialized, eg, to label sh species. a more subjective tasks involves ascertaining opinions from the crowd, eg, relevance judgements, which relies on consensus over subjective answers. the task we discuss in this paper, however, is yet another type, which involves workers emulating users engaged in permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies bear this notice and the full citation on the rst page. to copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speci. such a task allows researchers to collect behavioral data to set the parameters of user interaction models with a particular search system. these interaction models have recently become a popular way to evaluate search systems. compared to a lab user study, a crowd sourcing based study is likely to collect larger amounts of observations within a smaller amount of time and with lower cost. however, a dif cult or lengthy task, such as a search task, may not attract any workers or they may quickly turn away for other easier, more interesting, or more lucrative tasks. to crowd source this type of task, it is necessary to simplify the task so that they can be accomplished within a reasonable amount of time and effort. in this paper, we present a case study where we study user browsing behavior with a faceted interface in a gami ed setting. we describe the task design and abstractions made. we discuss our motivation for these design choices, and the impact of the task design and abstractions as observed from the data collected and the feedback from the players. leif azzopardiarjen de vriesuniversity of glasgow cwi lilybank gardens glasgow science park leifos acm org year#xg amsterdam arjen acm org a search task with a particular search system. a key challenge is therefore to design the task in such a way that it allows the study of the behavior of interest while abstracting away from other possible behaviors. our findings help us better understand how searchers use cursors on serps and can help design more effective search systems. understanding how people interact with search engines is important in improving search quality. web search engines typically analyze queries and clicked results, but these actions provide limited signals regarding search interaction. laboratory studies often use richer methods such as gaze tracking, but this is impractical at web scale. in this paper, we examine mouse cursor behavior on search engine results pages, including not only clicks but also cursor movements and hovers over different page regions. we: report an eye tracking study showing that cursor position is closely related to eye gaze, especially on serps; present a scalable approach to capture cursor movements, and an analysis of search result examination behavior evident in these large scale cursor data; and describe two applications that demonstrate the value of capturing cursor data. our scalable cursor tracking method may also be useful in non search settings. modern large retrieval environments tend to overwhelm their users by their large output. the third one computes the relative to the ideal performance of ir techniques, based on the cumulative gain they are able to yield. since all documents are not of equal relevance to their users, highly relevant documents should be identified and ranked first for presentation. in order to develop ir techniques in this direction, it is necessary to develop evaluation approaches and methods that credit ir methods for their ability to retrieve highly relevant documents. this can be done by extending traditional evaluation methods, that is, recall and precision based on binary relevance judgments, to graded relevance judgments. alternatively, novel measures based on graded relevance judgments may be developed. this article proposes several novel measures that compute the cumulative gain the user obtains by examining the retrieval result up to a given ranked position. the first one accumulates the relevance scores of retrieved documents along the ranked result list. the second one is similar but applies a discount factor to the relevance scores in order to devaluate late retrieved documents. these novel measures are defined and discussed and their use is demonstrated in a case study using trec data: sample system run results for queries in trec. as a relevance base we used novel graded relevance judgments on a four point scale. the test results indicate that the proposed measures credit ir methods for their ability to retrieve highly relevant documents and allow testing of statistical significance of effectiveness differences. the graphs based on the measures also provide insight into the performance ir techniques and allow interpretation, for example, from the user point of view. or commercial advantage, the copyright notice, the title of the publication, and its date appear, and notice is given that copying is by permission of the acm, inc. to bring such differences into daylight, both graded relevance judgments and a method for using them are required. in most laboratory tests in ir documents are judged relevant or irrelevant with regard to the request. more often relevance is con ated into two categories al at the analysis phase because of the calculation of precision and recall. the third one computes the relative to theideal performance of ir techniques, based on the cumulated gain they are able to yield. the graphs based on the measures also provide insight into the performance ir techniques and allow interpretation, for example, from the user point of view. modern large retrieval environments tend to overwhelm their users by their large output. since all documents are not of equal relevance to their users, highly relevant documents, or document components, should be identi ed and ranked rst for presentation. this is often desirable from the user point of view. in order to develop ir techniques in this direction, it is necessary to develop this research was supported by the academy of finland under the grant numbers and. authors address: department of information studies, fin university of tampere, finland; email: uta. permission to make digital hard copy of part or all of this work for personal or classroom use is granted without fee provided that the copies are not made or distributed for pro. to copy otherwise, to republish, to post on servers, or to redistribute to lists, requires prior speci. year# acm year# year# acm transactions on information systems, vol. evaluation approaches and methods that credit ir methods for their ability to retrieve highly relevant documents. the current practice of liberal binary judgment of topical relevance gives equal credit for a retrieval technique for retrieving highly and marginally relevant documents. for example, trec is based on binary relevance judgments with a very low threshold for accepting a document as relevant the document needs to have at least one sentence pertaining to the request to count as relevant. therefore differences between sloppy and excellent retrieval techniques, regarding highly relevant documents, may not become apparent in evaluation. in some studies relevance judgments are allowed to fall into more than two categories, but only a few tests actually take advantage of different relevance levels. however, graded relevance judgments may be collected in eld studies and also produced for laboratory test collections, so they are available. graded relevance judgments may be used for ir evaluation, rst, by extending traditional evaluation measures, such as recall and precision andr curves, to use them. al al arvelin, arvelin and kek ainen propose the use of each relevance level separately in recall and precision calculation. thus differentr curves are drawn for each level. they demonstrate that differing performance of ir techniques at different levels of relevancemaythusbeobservedandanalyzed kek ainenandj al arvelin generalize recall and precision calculation to directly utilize graded document relevance scores. they consider precision as a function of recall, but the approach extends to dcv based recall and precision as well. they demonstrate that the relative effectiveness of ir techniques, and the statistical signi cance of their performance differences, may vary according to the relevance scales used. in the present article we develop several new evaluation measures that seek to estimate the cumulative relevance gain the user receives by examining the retrieval result up to a given rank. the rst one accumulates the relevance scores of retrieved documents along the ranked result list. the second one is similar but applies a discount factor to the relevance scores in order to devaluate late retrieved documents. the rst two were originally presented inal arvelin and kek ainen and were also applied in the trec web track year# and in a text summarization experiment by sakai and sparck jones. these novel measures are akin to the average search length, sliding ratio, and normalized recall measures. they also have some resemblance to the ranked half life and relative relevance measures proposed by borlund and ingwersen for interactive ir. however, they offer several advantages by taking both the degree of relevance and the rank position of a document into account. the novel measures are rst de ned and discussed and then their use is demonstrated in a case study on the effectiveness of trec runs in retrieving documents of various degrees of relevance. the results indicate that the proposed measures credit ir methods for their ability to retrieve highly relevant documents and allow testing of statistical signi cance of effectiveness differences. section # explains our evaluation measures: the cumulated gain based evaluation measures. the test environment, relevance judgments, and the retrieval results are reported. section # contains discussion and section # conclusions. this paper examines the reliability of implicit feedback generated from clickthrough data in www search. analyzing the users decision process using eyetracking and comparing implicit feedback against manual relevance judgments, we conclude that clicks are informative but biased. while this makes the interpretation of clicks as absolute relevance judgments difficult, we show that relative preferences derived from clicks are reasonably accurate on average. the idea of adapting a retrieval system to particular groups of users and particular collections of documents promises further improvements in retrieval quality for at least two reasons. second, as evident from the trec evaluations, differences between document collections make it necessary to tune retrieval functions with respect to the collection for optimum retrieval performance. since manually adapting a retrieval function is time consuming or even impractical, research on automatic adaptation using machine learning is receiving much attention. ithaca, ny, usa cornell edu however, a great bottleneck in the application of machine learning techniques is the availability of training data. in this paper we explore and evaluate strategies for how to automatically generate training examples for learning retrieval functions from observed user behavior. however, implicit feedback is more di cult to interpret and potentially noisy. in this paper we analyze which types of implicit feedback can be reliably extracted from observed user behavior, in particular clickthrough data in www search. the study is designed to analyze how users interact with the list of ranked results from the google search engine and how their behavior can be interpreted as relevance judgments. first, we use eyetracking to understand how users behave on googleresults page. do users scan the results from top to bottom how many abstracts do they read before clicking how does their behavior change, if we arti cially manipulate googleranking answers to these questions give insight into the users decision process and suggest in how far clicks are the result of an informed decision. based on these results, we propose several strategies for generating feedback from clicks. to evaluate the degree to which feedback signals indicate relevance, we compare the implicit feedback against explicit feedback we collected manually. the study presented in this paper is di erent in at least two respects from previous work assessing the reliability of implicit feedback. first, our study provides detailed insight into the users decision making process through the use of eyetracking. second, we evaluate relative preference signals derived from user behavior. this is in contrast to previous studies that primarily evaluated absolute feedback. our results show that users make informed decisions among the abstracts they observe and that clicks re ect relevance judgments. however, we show that clicking decisions are biased in at least two ways. first, we show that there is a trust bias which leads to more clicks on links ranked highly by google, even if those abstracts are less relevant than other abstracts the user viewed. second, there is a quality bias: the users clicking decision is not only in uenced by the relevance of the clicked link, but also by the overall quality of the other abstracts in the ranking. we propose several strategies for extracting such relative relevance judgments from clicks and show that they accurately agree with explicit relevance judgments collected manually. first, a one size ts all retrieval function is necessarily a compromise in environments with heterogeneous users and is therefore likely to act suboptimally for many users. permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies bear this notice and the full citation on the rst page. to copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speci. in contrast to explicit feedback, such implicit feedback has the advantage that it can be collected at much lower cost, in much larger quantities, and without burden on the user of the retrieval system. to evaluate the reliability of implicit feedback signals, we conducted a user study. we performed two types of analysis in this study. this shows that clicks have to be interpreted relative to the order of presentation and relative to the other abstracts. the standard system based evaluation paradigm has focused on assessing the performance of retrieval systems in serving the best results for a single query. real users, however, often begin an interaction with a search engine with a sufficiently under specified query that they will need to reformulate before they find what they are looking for. in this work we consider the problem of evaluating retrieval systems over test collections of multi query sessions. we propose two families of measures: a model free family that makes no assumption about the user behavior over a session, and a model based family with a simple model of user interactions over the session. in both cases we generalize traditional evaluation metrics such as average precision to multi query session evaluation. we demonstrate the behavior of the proposed metrics by using the new trec year# session track collection and simulations over the trec query track collection. faceted navigation is being increasingly employed as an effective technique for exploring large query results on structured databases. this technique of mitigating information overload leverages metadata of the query results to provide users with facet conditions that can be used to progressively refine the user query and filter the query results. however, the number of facet conditions can be quite large, thereby increasing the burden on the user. we present the facetor system that proposes a cost based approach to faceted navigation. at each step of the navigation, the user is presented with a subset of all possible facet conditions that are selected such that the overall expected navigation cost is minimized and every result is guaranteed to be reachable by a facet condition. we prove that the problem of selecting the optimal facet conditions at each navigation step is np hard, and subsequently present two intuitive heuristics employed by facetor. our user study at amazon mechanical turk shows that facetor reduces the user navigation time compared to the cutting edge commercial and academic faceted search algorithms. the user study also confirms the validity of our cost model. we also present the results of an extensive experimental evaluation on the performance of the proposed approach using two real datasets. facetor is available at http: db cse buffalo edu facetor. in recent years, there has been a tremendous increase in the number and size of databases published online, commonly referred to as the deep web, exposing a wide range of content including product catalogs, bibliographies, local businesses and many more. these databases are commonly queried using forms or keyword based interfaces. when users are not familiar with the content and structure of the database, or are unable to use sophisticated search interfaces, they issue queries that are exploratory in nature and may return a large number of results. in other cases, users often issue broad queries in fear of missing potentially useful results. as a consequence, users end up spending considerable effort browsing long results lists. this phenomenon, known as information overload, is a major hurdle in querying large databases. information overload has been tackled from two directions ranking and categorization. there are many recent works on ranking database results for both keyword and structured queries. ranking is effective when the assumptions used by the ranking function are aligned with user preferences. ranking may not perform well for exploratory queries, since it is hard to judge which result is better than the other when the query is broad. moreover, no summary of the query result is provided for the user to refine her query. in categorization, query results are grouped based on hierarchies, keywords, tags, or attribute values. for instance, consider the medline database of biomedical citations, whose articles are tagged with terms from the mesh concept hierarchy. categorization systems propose a method for users to effectively explore the large results by navigating the mesh sub hierarchy relevant to the particular query result. wider adoption of such hierarchical categorization systems is limited, as building these concept hierarchies requires an intense manual effort, and automatically assigning terms to tuples afterwards is not always successful. a popular variant of categorization, which is the focus of this paper, is faceted navigation. here, the tuples in a query result are classified into multiple independent categories, or facets, instead of a single concept hierarchy. for an example car dataset, the result for keyword query. shown in figure #a is categorized based on, and. each facet is associated with a set of facet conditions, each of which appears in the number of tuples shown in parenthesis. facet in figure #a is associated with the set of facet conditions. the user can narrow down or refine this result set by selecting a facet condition and clicking on it. user studies have shown that faceted navigation improves the ability of users to explore large query results and identify tuples of interest when compared to single concept hierarchies. faceted navigation has been studied extensively by the information retrieval community, where the challenge is to dynamically determine the facets for a given set of documents. the drawback of these systems is the unpredictability and counter intuitiveness of the resulting facets. in contrast, faceted navigation is much more intuitive and predictable for structured databases, where each attribute is a facet describing a permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. to copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and or a fee. particular characteristic of the tuples in the dataset. the following are key concerns that need to be addressed to achieve effective faceted navigation when the number of facets and facet conditions are large: which facets and facet conditions should be suggested to the user for example, the query result in figure #a consists of tuples that can be categorized using facets and facet conditions. suggesting familiar facets and facet conditions would help the user make a refinement decision without requesting additional facet conditions. for example, if users are more familiar with the. facet in figure #a, it is intuitive to suggest conditions from the year facet. most current solutions, try to address the facet conditions selection problem in an ad hoc manner by ranking the facet conditions using results cardinality or other ad hoc factors. faceted search helps users by offering drill down options as a complement to the keyword input box, and it has been used successfully for many vertical applications, includingcommerce and digital libraries. however, this idea is not well explored for general web search, even though it holds great potential for assisting multi faceted queries and exploratory search. in this paper, we explore this potential by extending faceted search into the open domain web setting, which we call faceted web search. to incorporate user feedback on these query facets into document ranking, we investigate both boolean filtering and soft ranking models. we evaluate faceted web search systems by their utility in assisting users to clarify search intent and find subtopic information. our experiments testify to the potential of faceted web search, and show boolean filtering feedback models, which are widely used in conventional faceted search, are less effective than soft ranking models. to tackle the heterogeneous nature of the web, we propose to use query dependent automatic facet generation, which generates facets for a query instead of the entire corpus. we describe how to build reusable test collections for such tasks, and propose an evaluation method that considers both gain and cost for users. faceted search enables users to navigate a multi faceted information space by combining text search with drill down options in each facet. this technique has been used successfully for many vertical applications, includingcommerce and digital libraries. however, faceted search has not been explored much for general web search, even though it holds great potential for assisting multi faceted queries and exploratory search. the challenges stem from the large and heterogeneous nature of the web, which makes it di cult to generate and recommend facets. some recent work extracts facets for a query from the top ranked search results, providing what appears to be a promising direction for solving the problem. changing from a global model that generates facets in advance for an entire corpus to a query based approach that generates facets from the topranked documents, these methods not only make the generation problem easier, but also address the facet recommendation problem at the same time. however, their evaluation is based on the similarity between system generated and human created facets, which may not exactly re ect the utility in assisting users search tasks. however, that study is based on corpora with human created facet metadata, which is di cult to obtain for the general web. in this paper, we extend faceted search into the opendomain web setting, which we call faceted web search. for example, suppose a user is preparing for an international ight and wants to nd baggage allowance information. when the user searches baggage allowance in an fws system, the system may provide a facet for di erent airlines, a facet for di erent ight types, and a facet for di erent classes, when the user selects terms such as delta, international and economy in these facets, the system can ideally help to bring web documents that provide baggage allowance information for the economy class of delta international ights to the top of the search results. we describe a way to build an fws system. to tackle the heterogeneous nature of the web, we propose using querydependent automatic facet generation which generates facets for a query instead of in advance for the entire corpus. to incorporate user feedback on these query facets into document ranking, we investigate both boolean ltering and soft ranking models. we also propose an evaluation method for fws that directly measures the utility in assisting users to clarify search intent and nd subtopic information. the evaluation method considers both gain and cost for users. our experiments show fws is able to assist the search task and signi cantly improve ranking performance. comparing our evaluation with previous evaluations on di erent facet generation models, we nd previous evaluations do not always re ect system utility in real application. the rest of the paper is organized as follows. after that, section # describes how an fws system can be built and introduces the two major components in fws query facet generation and facet feedback, which are then described in detail in sections and respectively. section # describes evaluation for fws, including previous evaluation approaches and our proposed evaluation. we describe how to build reusable test collections for such tasks, and make our collected data set publicly available. for example, when searching computer monitor in ancommerce site, users can select brands and monitor types from the the provided facets: and. previous work also studied how to use user selected terms inside the facets for document ltering or re ranking. similar to faceted search, fws system will provide facets when a user issues a web search query. the user can then select some terms from the facets, which will be used by the fws system to adjust the search results to better address the userinformation need. comparing di erent feedback models, we nd boolean ltering models, which are widely used in conventional faceted search, are too strict in fws, and less. faceted search is becoming a popular method to allow users to interactively search and navigate complex information spaces. a faceted search system presents users with key value metadata that is used for query refinement. while popular incommerce and digital libraries, not much research has been conducted on which metadata to present to a user in order to improve the search experience. nor are there repeatable benchmarks for evaluating a faceted search engine. in order to demonstrate these ideas and better understand personalized faceted search, several faceted search algorithms are proposed and evaluated using the novel evaluation methodology. this paper proposes the use of collaborative filtering and personalization to customize the search interface to each user behavior. this paper also proposes a utility based framework to evaluate the faceted interface. given the set of wikipedia articles resulting from a keyword query, facetedpedia generates a faceted interface for navigating the result articles. compared with other faceted retrieval systems, facetedpedia is fully automatic and dynamic in both facet generation and hierarchy construction, and the facets are based on the rich semantic information from wikipedia. the essence of our approach is to build upon the collaborative vocabulary in wikipedia, more specifically the intensive internal structures and folksonomy. we propose metrics for ranking individual facet hierarchies by user navigational cost, and metrics for ranking interfaces by both their average pairwise similarities and average navigational costs. we thus develop faceted interface discovery algorithms that optimize the ranking metrics. this paper proposes facetedpedia, a faceted retrieval system for information discovery and exploration in wikipedia. given the sheer size and complexity of this corpus, the space of possible choices of faceted interfaces is prohibitively large. our experimental evaluation and user study verify the effectiveness of the system. a range of methods for measuring the effectiveness of information retrieval systems has been proposed. these are typically intended to provide a quantitative single value summary of a document ranking relative to a query. for example, recall is not well founded as a measure of satisfaction, since the user of an actual system cannot judge recall. average precision is derived from recall, and suffers from the same problem. in addition, average precision lacks key stability properties that are needed for robust experiments. in this article, we introduce a new effectiveness metric, rank biased precision, that avoids these problems. rank biased pre cision is derived from a simple model of user behavior, is robust if answer rankings are extended to greater depths, and allows accurate quantification of experimental uncertainty, even when only partial relevance judgments are available. information retrieval systems compute, for each document in a collection, a score that estimates the similarity between that document and a query. in typical systems, each score represents an estimated probability that the document is relevant to the information need expressed by the query. once the process of scoring is complete, documents are presented to the user in decreasing score order, in the expectation that the user considers them in sequence until their information need has been satis ed. a range of methods for measuring the effectiveness of information retrieval systems has been proposed. a key element of many of these measures and certainly of those in the widest use is the assumption of binary relevance, with human assessors asked to determine, for a set of documents, which members are relevant to the query and which are not. given a ranking, each document is marked as relevant or irrelevant, and the sequence of decisions is then used as input to a quantitative measure of effectiveness. these can be combined to give a single value via mechanisms such as a point or point recall precision average. one of the most commonly used measures in recent ir research is average precision, which does not directly use recall, but does require knowledge of, the total number of relevant documents for the query in question. other widely used measures are precision atdocuments retrieved, where typicallyis; precision, orp; and reciprocal rank. for example, it is not clear what user behavior is modeled by ap, and it has properties that render it volatile in typical experimental settings. in particular, using ap with incomplete relevance judgments typically leads to in ated effectiveness estimates, and the discovery of further relevant documents in a ranking usually reduces measured effectiveness. these issues are not addressed by recent ap based metrics such as those of buckley and voorhees or sakai. underlying these issues are two problems with recall. one, which is widely known, is that in current systems complete relevance judgments are impractical and thus recall tends to be overestimated. figure # shows this problem using the standard venn diagram approach. the trec methodology is discussed in more detail below. another problem with recall, which has not received such wide attention, is that it does not correspond to a likely model of user behavior. in this article, we introduce a new metric, rank biased precision, that avoids many of the failings of average precision. the basis of rbp is that it measures the rate at which utility is gained by a user working at a given degree of persistence; by adjusting persistence, a parameter that represents an aspect of user behavior, rbp has the advantage of capturing the critical facets of ap, rr, and. of rbp compared to ap is that it allows accurate quanti cation of experimental errors when only partial relevance judgments are available, which is useful when large scale experiments are being carried out. rank biased precision also has some similarities with the the cranfield arrangement the trec arrangement figure #. recall and precision: the cran eld arrangement, with all documents in the collection categorized for relevance, and in which precision is a, and recall is a; and the trec arrangement, in which only a subset of the documents are categorized for relevance, and the size of the sets. is not known, but for calculation purposes it is assumed that. discounted cumulative gain metric ofal arvelin and kek ainen, and is compared to that measure below. to understand some of the issues in existing measures, we rst consider recall and precision and the way in which relevance judgments are collected. we next review the measures in common use in experimental work, as well as other measures that have been proposed in the literature. we then describe rank biased precision, and experimentally examine its behavior. time biased gain provides a unifying framework for information retrieval evaluation, generalizing many traditional effectiveness measures while accommodating aspects of user behavior not captured by these measures. by using time as a basis for calibration against actual user data, time biased gain can reflect aspects of the search process that directly impact user experience, including document length, near duplicate documents, and summaries. unlike traditional measures, which must be arbitrarily normalized for averaging purposes, time biased gain is reported in meaningful units, such as the total number of relevant documents seen by the user. in prior work, we proposed and validated a closed form equation for estimating time biased gain, explored its properties, and compared it to standard approaches. in this paper, we use stochastic simulation to numerically approximate time biased gain. stochastic simulation provides greater flexibility that will allow us, in future work, to easily accommodate different types of user behavior and increase the realism of the effectiveness measure. in order to achieve the advantages of both user oriented studies and system oriented tests, while ameliorating some of their disadvantages, we propose a time biased gain. we published an initial exposition and validation of tbg in prior work. in its most general permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies bear this notice and the full citation on the rst page. to copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speci. form, tbg can be written as the riemann stieltjes integral dg. in this formula, represents a cumulative gain function, monotonically increasing with time. imagine a user working down through a result list returned by a commercial search engine, which typically consists of a ranked list of query biased summaries, ten or so to a page. the user starts by reading the title and description associated with the rst summary. deciding it might be interesting, she clicks on the url and reads the document for a while. eventually, she returns back to the result list. she quickly skips the second result, which looks unpromising, but clicks on the third, reads it, returns, and so on down the list. in a scenario such as this one, represents the cumulative gain experienced by the user as time passes, where in this scenario gain might be measured by the total number of relevant documents viewed. other scenarios would produce other cumulative gain functions, perhaps measured in other units. eventually, the user will decide to stop working. tbg assumes that this decision depends on time alone, independent of other factors, including cumulative gain. in equation the decay function indicates the probability that the user continues until time, with, and withdecreasing monotonically to as. in our prior work, we adopted an exponential decay function, a choice which we supported through an analysis of queries and clicks taken from the logs of a commercial search engine. the valuerepresents a normalization factor, which may be desirable for averaging scores across multiple queries. since total gain may be expressed in meaningful units, eg, total number of relevant documents viewed, normalization may not be required, allowing us to set. however, in some circumstances, it may be reasonable to normalize by the maximum gain possible over a given test collection, or over any test collection. in our prior work, we did not normalize tbg, setting. g, because gain is realized after the user nishes viewing a document then equation reduces to gkd, k where the gain gk represents the bene. to the user of viewing the document at rank, and isthe time it takes the user to nish viewing the document at rank. in our prior work, we adopted gain values representing probabilities of relevance, ie, the value of gk represents the probability that the user judges the document at rankto be relevant, a choice supported by some current interpretations of graded relevance. in the remainder of this paper, we work with the form of tbg shown in equation, with an exponential decay function, no normalization, and gain values representing probabilities of relevance. this equation implicitly assumes the scenario of a user with a topical information need, working their way down a result list, searching for as much relevant information as possible. this scenario roughly corresponds to the assumptions underlying many trec retrieval experiments, including test collections from the trec year# robust track experiments, which we use to calibrate and validate our work. in our prior work, we estimated byway of asimple model of an idealized user working down the result list. this user model incorporates the time to read a summary, the probability of clicking on a summary, and the time to read a document of lengthwords. we calibrated this model from a user study in which we presented subjects with an interface styled after a modern web search engine, including a result page with ten query biased summaries, and instructed them to nd and save as many relevant documents as possible in the time allocated, while making as few mistakes as possible. results from this user study were applied to set calibration parameters within the model. the outcome of this prior work is a closed form equation for estimating tbg. the closed form nature of the equation provides us with the comfortingly familiarity of a traditional. ectiveness measure, while enabling a closer association with actual user behavior and a meaningful interpretation in terms of the number of relevant documents seen. by relating the depth in the result list to the time invested by the user, tbg appropriately handles aspects of user behavior not normally handled by traditional. ectiveness measures, such as the impact of summaries, near duplicate documents, and document length. in the current paper we take the development of tbg one step further. abandoning the restriction of a closed form equation, we view as a random process and approximate tbg using stochastic simulation while maintaining the model of a single idealized user. as we will discuss in section #, moving to a simulation will allow us in future work the ability to easily move to modeling a population of users where we can both estimate the expected total gain, ed dg, and the distribution of gain for the population. in addition, the simulation will allow us to more easily conduct what if experiments that could be di cult to perform with actual humans. we implement our approach in a web application called faccy net. the evaluation is based on simulations employing year# queries, products, facets, and three drill down strategies. multifaceted search is a commonly used interaction paradigm incommerce applications, such as web shops. because of the large amount of possible product attributes, web shops usually make use of static information to determine which facets should be displayed. unfortunately, this approach does not take into account the user query, leading to a non optimal facet drill down process. in this paper, we focus on automatic facet selection, with the goal of minimizing the number of steps needed to find the desired product. we propose several algorithms for facet selection, which we evaluate against the state of the art algorithms from the literature. as evaluation metrics we use the average number of clicks, the average utility, and the top promotion percentage. the results show that the probabilistic entropy algorithm significantly outperforms the other considered algorithms. online product search has nowadays become more important than ever, as consumers purchase more often on the web. one explanation for this is that the web facilitates the user in nding products that better match their permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies bear this notice and the full citation on the rst page. copyrights for components of this work owned by others than acm must be honored. to copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speci. not only do the users have access to more information, they also nd it easier to shop from their homes. on the other hand, because of the many options, users are often overwhelmed and nd it di cult to browse through the available products. multifaceted search, also sometimes referred to as guided navigation, is a popular interaction paradigm that allows users to navigate through multidimensional data. one of the main uses of multifaceted search is in the domain of ecommerce, ie, web shops. it is being employed to solve the parametric product search problem for web shops that have collected local. for example, in a web shop the user might enter a query like samsung, gps in order to search for a samsung phone that has built in gps capabilities. after showing the initial result set, most web shopping interfaces display the facets of the products in the result set, which can be used to further drill down into the results set. the facets in this case are product attribute value combinations. some examples of such product facets are connectivity: hspda and screensize: inch. an important problem of multifaceted search is the selection of facets that should be displayed for each query. because products have so many attributes that could be displayed as facets, web shops usually have some static business logic to display certain facets for each result set. although this works for local web shops that do not have many product categories, the creation of this business logic is a time consuming process and is not appropriate for webwide product search. one solution to this problem is to employ an optimized facet selection process. the goal of such an optimization process is to show facets that. ectively partition the product search space so that the user can easily drill down and nd its desired product. in literature, this is referred to as the facet selection problem, which can be expressed as the optimization of a hyperactive media link generation process. in this paper, we propose new algorithms for the facet selection problem in product search. we evaluate several approaches and compare our proposed algorithms against several state of the art facet selection algorithms from the literature. our proposed algorithms aim to partition the space in the most. ective manner and thus allow the user to drill down in the least amount of time. we perform the evaluation on a large data set and analyze the results, di erently from previous works, across three di erent measures.