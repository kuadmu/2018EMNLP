although interactive query reformulation has been actively studied in the laboratory, little is known about the actual behavior of web searchers who are offered terminological feedback along with their search results. we analyze log sessions for two groups of users interacting with variants of the altavista search engine a baseline group given no terminological feedback and a feedback group to whom twelve refinement terms are offered along with the search results. we examine uptake, refinement effectiveness, conditions of use, and refinement type preferences. although our measure of overall session success shows no difference between outcomes for the two groups, we find evidence that a subset of those users presented with terminological feedback do make effective use of it on a continuing basis. one of the most widely studied is the use of interactive relevance feedback, in which term suggestions are permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. one workaround for this problem has been to generate search suggestions from the top ranked documents regardless of their actual relevance, using linguistic and other heuristics to select and order the terms displayed back to the user. space is already at a premium on the typical textually cluttered search results page. for example, a word cluster based refinement tool offered on the altavista web site several years ago received scant user attention and was eventually scrapped. the incorporation of such refinement tools into full scale web search engines provides ir researchers an opportunity to study user behavior both in the large and in its natural state, free of the potential confounding influences of a laboratory setting or artificial tasks. in order to assist the user in bridging the gap between an internal information need and an expression of that need in the language of the target documents, many ir researchers have proposed the use of terminological feedback mechanisms to offer search term suggestions. to copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and or a fee. generated based on user relevance judgements of previously retrieved documents while this approach has been shown to be effective in improving the recall and precision of subsequent searches, it has been difficult to implement in practice because of the reluctance of users to make the prerequisite document relevance judgements. although a number of such systems have shown promise in the laboratory setting, their incorporation into large scale web search engines has been slow, and for good reason. furthermore, while the majority of end users are familiar with the way search engines currently work, they donreally understand how or why they work and may find additional interface features clumsy or confusing. recently, several web search engines have begun offering short lists of search refinement suggestions in order to encourage the interactive narrowing of query result sets. among these is the altavista prisma tool, which allows a user to augment or replace the current query expression by clicking on feedback terms derived dynamically from an analysis of the top ranked search results. in this paper, we will report on the results of several log based studies of user interaction with altavistaprisma assisted search tool. we were interested in the degree and nature of user uptake of the feature, as well as the conditions and effectiveness of its use within information seeking sessions. an experiment controlling the display of the interface allowed us to compare how behavior differed between users provided with the feature and those operating without it. we begin with a brief overview of the functionality provided within the prisma refinement interface. we then enumerate a range of issues which our study was intended to address, relating our investigation to previous work on each topic. next we lay out the methodology we used to conduct experiments and to extract session information from activity logs. finally, we offer our conclusions and suggestions for future research. experienced web users have strategies for information search and re access that are not directly supported by web browsers or search engines. we studied how prevalent these strategies are and whether even experienced users have problems with searching and re accessing information. with this aim, we conducted a survey with experienced web users. the results showed that this group has frequently used key strategies that they find important, whereas some of the strategies that have been suggested in previous studies are clearly less important for them. in some aspects, such as query formulation, this group resembles less experienced web users. for instance, we found that most of the respondents had misconceptions about how their search engine handles queries, as well as other problems with information search and re access. in addition to presenting the prevalence of the strategies and rationales for their use, we present concrete designs solutions and ideas for making the key strategies also available to less experienced users. the world wide web contains enormous amounts of information and search engines are a widely used tool for accessing this information. alone, search engines are used by about million adults on a typical day. in addition to finding information for their current needs, people require methods for re accessing information they have found earlier. our focus is on the information search and re access strategies utilized by people with considerable web and web search experience. along with experience, users develop efficient copyright is held by the international world wide web conference committee. distribution of these papers is limited to classroom use, and personal use by others. strategies and make imaginative use of available tools for web information search and management. for example, we have seen them using as many as a dozen browser windows in parallel to manage the search process and to reduce the waiting caused by downloading times. in addition, theymail urls to themselves and add links to their personal web page so that they can access them later from a different computer. previous studies on experienced users search and re access strategies have mostly used observational methods with a small number of users, though observational studies can provide an understanding of the strategies in context and the rationales behind them, they may over emphasize incidental findings. other studies, which are based on log data, make it easy to study a large number of people but the approach is perhaps weakened by an ignorance of the context of the use. log studies are also often limited in scope as they typically gather data in relation to the use of a specific tool or service. in contrast, we applied a questionnaire with both openended and closed questions in order to gain data from a large number of users in relation to a pre defined context of use. using a questionnaire, we expected to gain a broad understanding of the search and re access strategies regardless of the tools that people are using. by reaching tens or even hundreds of people, we can firmly determine the relative importance of the strategies in question along with the rationales for their use. using this questionnaire, we addressed the following three questions: what are the tools that experienced users use for information search and re access. how prevalent are the different strategies for searching and re accessing information. are there problems in the process of information search and re access that even experienced users face in addition to examining the strategies, we will present concrete interface solutions and design ideas that aim to place the key strategies at the disposal of all web users. there has been increased interest in the use of simulated queries for evaluation and estimation purposes in information retrieval. however, there are still many unaddressed issues regarding their usage and impact on evaluation because their quality, in terms of retrieval performance, is unlike real queries. in this paper, wefocus on methods for building simulated known item topics and explore their quality against real known item topics. using existing generation models as our starting point, we explore factors which may influence the generation of the known item topic. informed by this detailed analysis we propose a model with improved document and term selection properties, showing that simulated known item topics can be generated that are comparable to real known item topics. this is a significant step towards validating the potential usefulness of simulated queries: for evaluation purposes, and becausebuilding models of querying behavior provides a deeper insight into the querying process so that better retrieval mechanisms can be developed to support the user. evaluation plays a central role in information retrieval because it enables the benchmarking and comparison of different retrieval techniques. however, manually building permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies bear this notice and the full citation on the rst page. to copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speci. test collections for evaluation is a time consuming and expensive process. with more and more collections becoming available and only nite resources available, the range of tasks that can be evaluated is restricted. ective alternative to manually building test collections is to construct simulated test collections instead. while this involves a number of compromises regarding the realism of the generated test collection, the solution has many bene ts. simulation provides an inexpensive avenue for testing, training, and evaluating retrieval algorithms along with the ability to precisely control the experimental conditions. for instance, the length, style, quality and number of queries that can be produced for a given topic can be greatly varied to de ne a speci. this enables selective evaluation of particular query types. by considering di erent query types the relationship between query characteristics and algorithm performance can be better understood and help guide the development of retrieval algorithms and query performance prediction. recently, there has been number of studies which have constructed a simulated test collection for evaluation and training purposes. however, little research has been performed on investigating their validity, utility and limitations for evaluation. consequently, there are many open questions and issues concerning their use. what is the information need how should topics be generated can the models of query generation produce reasonable or interpretable queries are these queries really like user queries do they give the same indication of performance, or the same ranking of systems and what about relevance judgments so while using simulated test collections is coste ective and potentially useful in the context of evaluation, they are not well understood. the focus of this study is on one particular type of simulated test collections built from the automatic generation of known item topics. the approach generates knownitem topics by selecting a document, the known item, and producing a query for that known item. since the task of known item nding has a clear and precise semantics, this removes issues relating to acquiring user judgements or de ning an information need. the main concern for these test collections, is the production of the known item topics and whether they are representative or re ective of actual known items. the challenge is to develop models that produce copyright year# acm. known item topics that are comparable to manually created known item topics. previous studies using simulated topics have resulted in varying levels of performance. a very early study found that simulated queries for ad hoc retrieval performed very poorly compared to real queries. however, more recent studies have shown mixed performances from simulated queries. azzopardi and de rijke report that performance for known item nding queries is reasonably similiar to real queries, but either somewhat lower or somewhat higher. during webclef year# simulated queries were also used to generate queries for the known item task in over languages. simulated topics resulted in substantially poorer performance than manual topics for many of the languages. as a result, only a weak correlation between the ranking of systems using simulated and real queries was found. in sum, current models for generating simulated topics do not appear to be providing comparable performance to manual topics. the cause of this problem, we believe, is that the models used to generate the queries and topics are not a good representation of the actual querying processes. in this paper, we examine the problems of developing useful simulated queries for known item nding, and attempt to identify generation methods that produce topics that are comparable to real topics. on six di erent european language collections, we test current models of known item generation. our main contribution consists of two parts: a detailed analysis of a number of factors that impact the performance of the generated queries; and extensions and re nements of current query models in terms of term selection and non uniform document priors. this results in query models whose replicative validity can be established. the remainder of this paper is structured as follows. review the related work in this area before describing a generative probabilistic approach to query generation for known item nding tasks. then, in section # we perform an empirical analysis on the webclef multilingual web retrieval tracks using di erent query models. we analyse and revise the models in section # and. finally, we discuss our ndings and conclude in section #. we consider the following full text search autocompletion feature. imagine a user of a search engine typing a query. then with every letter being typed, we would like an instant display of completions of the last query word which would lead to good hits. at the same time, the best hits for any of these completions should be displayed. we present a new indexing data structure that uses no more space than a state of the art compressed inverted index, but with times faster query processing times. even on the large trec terabyte collection, which comprises over million documents, we achieve, on a single machine and with the index on disk, average response times of one tenth of a second. we have built a full fledged, interactive search engine that realizes the proposed autocompletion feature combined with support for proximity search, semi structured text, subword and phrase completion, and semantic tags. known indexing data structures that apply to this problem either incur large processing times for a substantial class of queries, or they use a lot of space. one of its early uses was in the unix shell, where pressing the tabulator key gives a list of all le names that start with whatever has been typed on permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. to copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speci. ingmar weber max planck institutur informatik saarbr ucken, germany iweber mpi inf mpg de the command line after the last space. recently, autocompletion has been integrated into a number of search engines like google suggest or applespotlight. for the unix shell, this is the list of all le names in all directories listed in the path variable. for the text editors, this is the list of all words entered into the le so far. in google suggest, completions appear to come from a precompiled list of popular queries. for these kinds of applications we can easily achieve fast response times by two binary ortree searches in the sorted list of candidate strings. the problem we propose and discuss in this paper is of this kind. more informally, imagine a user of a search engine typing a query. all this should preferably happen in less time than it takes to type a single letter. promising completions might then be sigir, sigmod, etc, but not, for example, signature, assuming that, although signature by itself is a pretty frequent word, the query conference signature leads to only few good hits. our results we have developed a new indexing data structure, named hyb, which uses no more space than a state of the art compressed inverted index, and which can respond to autocompletion queries as described above within a small fraction of a second, even for collection sizes in the terabyte range. our main competitor in this paper is the inverted index, referred to as inv in the following. other data structures that could be directly applied to our problem either use a lot of space or have other limitations; we discuss these in section #. we give a rigorous mathematical analysis of hyb and inv with respect to both space usage and query processing times. concerning space usage, we de ne a notion of empirical figure #: a screenshot of our search engine for the query conference sig searching the english wikipedia. entropy, which captures the inherent space complexity of an index independent of a particular compression scheme. we prove that the empirical entropy of hyb is essentially equal to that of inv, and we nd that the actual space usage of our implementation of the two index structures is indeed almost equal, for each of our three test collections. we also take into account the di erent latencies of sequential and random access to data. one of our collections has been publicly searchable over the last year, so that we have autocompletion queries from real users for it. we have built a full edged search engine that supports autocompletion queries of the described kind combined with support for proximity phrase search, xml tags, subword and phrase completion, and category information. typed so far would lead to highly ranked documents. we get a related feature by the subword phrase completion mechanism described in section #. our autocompletion problem is related to but distinctly di erent from multi dimensional range searching problems, where the collection consists of tuples, and queries are asking for all tuples that match a given tuple of ranges. for fast processing times, however, the space consumption of any of these structures is on the order of, where nis the size of an inverted index, and grows with the dimension. for our autocompletion queries, we can achieve fast query processing times and space. finally, there is a large variety of alternatives to the inverted index in the literature. for example, approaches that consider document by document are bound to be slow due to a poor locality of access; in contrast, both inv and hyb are mostly scanning long lists; see section #. signature les were found to be in no way superior to the inverted index in all major respects in. autocompletion is a widely used mechanism to get to a desired piece of information quickly and with as little knowledge and. or commercial advantage and that copies bear this notice and the full citation on the rst page. nowadays, we nd a similar feature in most text editors, and in a large variety of browsing guis, for example, in le browsers, in the microsoft help suite, or when entering data into a web form. in the simpler forms of autocompletion, the list of completions is simply a range from a list of words. more advanced forms of autocompletion take into account the context in which the to be completed word has been typed. the formal problem de nition will be given in section #. then with every letter being typed, we would like an instant display of completions of the last query word which would lead to good hits at the same time, the best hits for any of these completions should be displayed. see figure # for a screenshot of our search engine responding to that query. for a live demo, see http: search mpi inf mpg de wikipedia. our analysis accurately predicts the real behavior on our test collections. the list of completions and hits is updated automatically and instantly after each keystroke, hence the absence of any kind of search button. the number in parentheses after each completion is the number of hits that would be obtained if that completion where typed. query words need not be completed, however, because the search engine does an implicit pre. search: if, for example, the user continued typing conference sig proc, completions and hits for proc, eg, proceedings, would be fromthe hits for conference sig. concerning processing times, we give a precise quanti cation of the number of operations needed, from which we derive bounds for the worst, best, and average case behavior of inv and hyb. we compare inv and hyb on three test collections with di erent characteristics. our largest collection is the trec terabyte benchmark with over million documents. on all three collections and on all the queries we considered, hyb outperforms inv by a factor of in worst case query processing time, and by a factor of in average case query processing time. in absolute terms, hyb achieves average query processing of one tenth of a second or less on all collections, on a single machine and with the index on disk. all of these extensions are described in section #. related work the autocompletion feature as described so far is reminiscent of stemming, in the sense that by stemming, too, pre xes instead of full words are considered. but unlike stemming, our autocompletion feature gives the user feedback on which completions of the pre. the user can then assess the relevance of these completions to his or her search desire, and decide to type more letters for the last query word, eg, in the query from figure #, typeandso that the query is then conference sigir, or to start with the next query word, eg, type a space and then proc, or to stop searching as, eg, the user was actually looking for one of the hits shown in figure #. there is no way to achieve this by a stemming preprocessing step, because there is no way to foresee the userintent. this kind of user interaction is well known to improve retrieval. while our autocompletion feature is for the purpose of nding information, autocompletion has also been employed for the purpose of predicting user input, for example, for typing messages with a mobile phone, for users with disabilities concerning typing, or for the composition of standard letters. in, contextual information has been used to select promising extensions for a query. paynter et al have devised an interface with a zooming in property on the word level, and based on the identi cation of frequent phrases. these data structures could be used for our autocompletion problem, provided that we were willing to limit the number of query words. ciency at the same time because we have the set of documents matching the part of the query before the last word already computed. in a sense, our autocompletion problem is therefore a dimensional range searching problem. we have considered those we are aware of with regard to their applicability to our autocompletion problem, but found them either unsuitable or inferior to the inverted index in that respect. arrays and related data structures address the issue of full substring search, which is not what we want here; a direct application of a data structure like would have the same. ciency problems as inv, whereas multi dimensional variants like require super linear space, as explained above. most searchers do not know how to use web search engines as effectively as possible. this is due, in part, to search engines not providing feedback about how search behavior can be improved. because feedback is an essential part of learning, we created the search dashboard, which provides an interface for reflection on personal search behavior. the dashboard aggregates and presents an individual search history and provides comparisons with that of archetypal expert profiles. via a five week study of search dash board users, we find that users are able to change aspects of their behavior to be more in line with that of the presented expert searchers. we also find that reflection can be beneficial, even without comparison, by changing participants views about their own search skills, what is possible with search, and what aspects of their behavior may influence search success. our findings demonstrate a new way for search engines to help users modify their search behavior for positive outcomes. query length in best match information retrieval systems is well known to be positively related to effectiveness in the ir task, when measured in experimental, non interactive environments. however, in operational, interactive ir systems, query length is quite typically very short, on the order of two to three words. we report on a study which tested the effectiveness of a particular query elicitation technique in increasing initial searcher query length, and which tested the effectiveness of queries elicited using this technique, and the relationship in general between query length and search effectiveness in interactive ir. results show that the specific technique results in longer queries than a standard query elicitation technique, that this technique is indeed usable, that the technique results in increased user satisfaction with the search, and that query length is positively correlated with user satisfaction with the search. it is well understood and documented that, in best match information retrieval systems, increased query length leads to increased performance, as measured by recall and precision in batch mode experimental ir systems, and it is well documented that query length in typical operational interactive ir systems is rather short, typically between two and three words long. this evident mismatch has led to a significant research effort at increasing query length. the most popular approach has been to automatically expand short queries without user intervention by various techniques, most often by some type of pseudo relevance feedback, sometimes by thesaural or other type expansion. such studies have shown that these sorts of query expansion lead to increased performance, again as measured in experimental, batch mode evaluation. there have also been a few attempts at increasing query length by encouraging searchers to enter longer queries in the first instance. although such studies have indicated that there seem to be relatively simple techniques that can encourage longer queries, they have not systematically investigated whether these queries actually result in better performance in interactive ir. thus, the current situation is that, although there is evidence that longer queries perform better in non interactive best match ir systems, we can only infer that automatically enhanced queries may perform better in interactive ir, and we have almost no evidence that longer queries obtained through searcher encouragement will lead to better performance in interactive ir. in this paper, we report on a study which explicitly investigated one technique designed to elicit longer than usual queries from searchers, and the effect of the technique, and of query length in general, on performance in interactive ir. belkin, et al compared two query elicitation modes, a query entry line and a scrollable query entry box, to determine whether the box mode would result in longer queries than the line mode. they also compared two query types: queries constructed as lists of key words and or phrases, versus queries constructed as full sentences or questions. they found that the box mode led to somewhat longer queries, and that the full sentence or question type led to significantly longer queries. although their study was not designed explicitly to evaluate the effect of query length on performance, they did find a consistent relationship between query length and one measure of performance in the task, completeness of answer. this was, however, only a descriptive finding, and not inferential. based on the results of belkin, et al, we designed a study within the trec year# interactive track to explicitly investigate the effect of method of query elicitation on query length, and the effect of query length on various measures of interactive ir performance. in particular, with respect to query length, we investigated two major research questions: rq: what can make searchers query length in interactive ir longer, and will searchers find such techniques acceptable and usable within this research question, we posed the following hypothesis: a search interface which asks searchers to describe their information problems at length will lead to longer queries than one which asks searchers to simply input a query as a list of words or phrases. this hypothesis was based on the results of belkin, et al, on a survey of query elicitation techniques used in digital reference situations, and on the problem statement elicitation techniques described in belkin, oddy brooks. from the data and ideas in these sources, we designed a query elicitation mode which asked people to describe their information problems, rather than to enter a query. this hypothesis was tested by comparing query length in this mode, with query length in a default, list of keywords and or phrases elicitation mode. we investigated the usability of the information problem elicitation mode through one objective measure, number of iterations, and one subjective measure, ease of starting a search. furthermore, we investigated the effect of several factors which might influence query length. one was type of information task that the searcher was engaged in; another was the type of topic of the search; a third was familiarity of the searcher with the topic and task; and the fourth was perceived difficulty of the search. rq: does query length affect any measures of performance or effectiveness in the search task within this research question we posed two hypotheses: a system which encourages long queries will lead to better performance in the search task than one which does not. with this hypothesis, we were explicitly concerned with testing whether the information problem elicitation interface, given that it did encourage long queries, led to better performance than one which elicited keyword and or phrase queries. performance was measured by an objective measure, correctness of answer for the search task, and a subjective measure, searchersatisfaction with the search results. in addition, number of query iterations per search was considered an indicator of search effectiveness. query length will be positively correlated with performance in the search task. with this hypothesis, we were concerned with determining whether query length, regardless of query elicitation mode, affected performance in the search task. the same measures were used to test as. in their daily lives people constantly interact with a wide range of electronically stored information objects; email messages, web pages, digital images, video samples, etc. these objects come from different sources, are in different formats and can be stored in different locations, including on distributed devices such as mobile phones, pdas and mp players. the wealth and diversity of digital information that people access and use makes it incredibly difficult for an individual to organise his her information in such a way that it can be re accessed and re used when it is needed in the future. our research investigates pim from the perspective of the psychology of memory. re finding information is different from finding information that has not been accessed before and involves different psychological processes. when re finding information, the user knows that the information they are looking for exists because they have seen it before. the details remembered are clues to help re access the information, while the details forgotten represent the barrier to re finding. however, current pim tools require specific attributes of information objects to be remembered and consequently make it difficult to re access and re use information. our research is based on the premise that pim tools should support the function of memory and has three objectives: to develop an increased understanding of the role memory plays in the management of personal information. what do people remember about their information objects, how do they use these recollections when re finding, and what factors influence what people remember and use to design, implement and evaluate pim tools that have been specifically designed to support characteristics of human memory. to address the difficulties involved in performing pim evaluations. the work is grounded by the theoretical understanding of how memory works. a review of appropriate cognitive psychology literature offers a means to critique existing pim tools and a basis from which to start designing novel tools that support the function of memory. building on this, our early experimental work compares pim behaviour to everyday memory problems, examining the problems people encounter and the strategies they employ to prevent and recover from memory lapses. we uncover a range of memory problems and solutions and relate these to the memory difficulties experienced in a pim context. by combining the psychology findings with the particpants explanations for the behavioural changes they make to prevent and recover from memory lapses, we develop a set of design principles for pim tools that are hypothesized to assist the user when re finding. the evaluation work not only allows the interfaces themselves to be evaluated, but also offers the chance to learn about what the experimental participants remember about the information they need to re find. another important finding from the email study is that people tend to remember different attributes of email messages in different situations and that the attributes remembered will depend on a number of factors, including the time that has elapsed since the information was last accessed, the amount of experience the participant has with re finding, the number of email messages in their collection, the way that they file their email messages, and their preferred means of re finding. the evaluation of the interfaces also allows several discoveries to be made regarding which features of the evaluated interfaces are supportive and which are restrictive, as well as the reasons why. the main finding, however, is that, like recollections, the interface features that help participants re find change in different situations. it is important that pim interfaces support multiple varieties of memory so that different memories can be used in different situations. another finding is that it can be helpful when pim interfaces supply cues to help people remember more about the information they need to find. however, again the evaluations reveal that different types of memory cues are useful in different situations. therefore, it is important that the pim tool designers consider the factors that our studies show to affect this: the type of information object being re found, the tasks that cause people to re find this type of object, and re finding strategies that the participants may already have. the method of evaluation used is in itself a contribution to the field of pim. a major limitation of the pim research performed to date is that few tool evaluations have been performed. several scholars have proposed that this situation stems from the difficulties involved in conducting evaluations. the difficulties include incorporating the personal connections people have with their own information in evaluations, creating balanced experimental designs, preparing experimental tasks, and protecting the privacy of participants. based on a study of the types of task that cause people to re find email messages and web pages, we propose, evaluate and then use a methodology for performing pim evaluations that overcomes difficulties outlined above. our work, therefore, offers contributions associated with each of our three objectives. we offer an increased understanding of the role of memory in pim, provide insight into how pim tools can be designed to support human memory, and propose a method of evaluation that allows pim behaviour and interfaces to be studied with a laboratory based approach. personal information management as a research field covers attempts to understand pim behaviour and develop systems to help people manage and re find their information effectively. whereas finding involves understanding an information need and recognising information that is relevant, re finding relies on memory. this means that the problems associated with managing and re finding personal information are related both to the limitations of human memory and to the failure of pim tools to account for these limitations. using these principles we develop two novel re finding interfaces one for personal photographs and one for personal email messages and evaluate these using current tools as benchmarks. in this respect, we discover that for both email messages and personal photographs, what people tend to remember is the context surrounding previous interactions with the sought after photograph email message. however, our findings suggest that people tend to have fuller recollections of the emails they need to re find, with recollections for photographs being more fragmented. the evaluations also highlight the usefulness of supporting visual memory, which few existing pim tools and research prototypes support. in almost all computer applications, users must enter correct words for the desired objects or actions. for success without extensive training, or in first tries for new targets, the system must recognize terms that will be chosen spontaneously. we studied spontaneous word choice for objects in five application related domains, and found the variability to be surprisingly large. in every case two people favored the same term with probability. in an era of online retrieval, it is appropriate to offer guidance to users wishing to improve their initial queries. one form of such guidance could be short lists of suggested terms gathered from feedback, nearest neighbors, and term variants of original query terms. to verify this approach, a series of experiments were run using the cranfield test collection to discover techniques to select terms for these lists that would be effective for further retrieval. the results show that significant improvement can be expected from this approach to query expansion. personalisation is an important area in the field of ir that attempts to adapt ranking algorithms so that the results returned are tuned towards the searcher interests. in this work we use query logs to build personalised ranking models in which user profiles are constructed based on the representation of clicked documents over a topic space. our experiments show that by subtly introducing user profiles as part of the ranking algorithm, rather than by re ranking an existing list, we can provide personalised ranked lists of documents which improve significantly over a non personalised baseline. further examination shows that the performance of the personalised system is particularly good in cases where prior knowledge of the search query is limited. instead of employing a human generated ontology, we use novel latent topic models to determine these topics. the vocabulary problem, where people use the same terms to describe di erent needs, is a well known issue. ecting ir systems and was identi ed early in the elddevelopment. despite this, most ir systems treat all users equally and attempt to return an optimal ranked link for the average user. recent years have seen a slight increase in the use of personalisation to improve search results and a correspondingly gradual increase in our understanding of how to tackle the problem. by understanding more about the user issuing a query, we can tailor the ranked list such that the likelihood of highly ranked urls being relevant is increased. much early work was unsuccessful and studies have subsequently shown that great care must be taken when applying personalisation so as to avoid damaging an already near optimal ranked list. to construct a personalised ranking we require some knowl permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies bear this notice and the full citation on the rst page. copyrights for components of this work owned by others than acm must be honored. this user pro le should represent the topical interests of the user and can be built by considering searches made by the user prior to the current one, more speci cally the query terms used and urls clicked. in early work these pro les were simply the raw terms of prior queries or the content of clicked documents, however these pro les often proved to be ine ective, perhaps being too ne grained given the limited amount of data available. this approach is problematic as many urls may not be present in the online categorisation scheme and requires that people determine the correct categories for each url, an expensive and error prone process. click through data, in the form of query logs, is an abundant source of information regarding search behaviour and is therefore often used for personalised search. query logs generally take the form of triples, consisting of a user id, a search query and a clicked url. each clicked url is assumed to be either a vote con rming its relevance or a preference for that url over other un clicked urls presented higher in the list. in this work we assume each click on a url represents an implicit vote of its relevance to the query and that the query words used to search for it represent its content. this allows us to construct representations of urls, build personalised search models and then fairly evaluate their performance, since the query logs represent user speci. we use query logs to build personalised models in which user pro les are constructed based on the representation of clicked urls over a topic space. the topic space is therefore extracted directly from the query log itself and there is no need for human intervention to de ne the topics. our experiments show that by subtly introducing user pro les as part of the ranking algorithm, we can provide personalised ranked lists of documents which improve signi cantly over a non personalised baseline, especially in cases where prior knowledge of the search query is limited. to copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speci. cikm october november year#, san francisco, ca, usa copyright year# acm year#. to deal with the sparsity, pro les can be based on the topics of each document, using categorisations from human derived resources such as the odp. however, instead of employing a human generated ontology we use latent topics. web search engines are traditionally evaluated in terms of the relevance of web pages to individual queries. however, relevance of web pages does not tell the complete picture, since an individual query may represent only a piece of the user information need and users may have different information needs underlying the same queries. in this work, we address the problem of predicting user search goal success by modeling user behavior. we show empirically that user behavior alone can give an accurate picture of the success of the user web search goals, without considering the relevance of the documents displayed. in fact, our experiments show that models using user behavior are more predictive of goal success than those using document relevance. we build novel sequence models incorporating time distributions for this task and our experiments show that the sequence and time distribution models are more accurate than static models based on user behavior, or predictions based on document relevance. web searchers often exhibit directed search behaviors such as navigating to a particular website. however, in many circumstances they exhibit different behaviors that involve issuing many queries and visiting many results. in such cases, it is not clear whether the user rationale is to intentionally explore the results or whether they are struggling to find the information they seek. being able to disambiguate between these types of long search sessions is important for search engines both in performing retrospective analysis to understand search success, and in developing real time support to assist searchers. the difficulty of this challenge is amplified since many of the characteristics of exploration are also observed in sessions where people are struggling. in this paper, we analyze struggling and exploring behavior in web search using log data from a commercial search engine. we first compare and contrast search behaviors along a number dimensions, including query dynamics during the session. we then build classifiers that can accurately distinguish between exploring and struggling sessions using behavioral and topical features. finally, we show that by considering the struggling exploring prediction we can more accurately predict search satisfaction. permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. copyrights for components of this work owned by others than acm must be honored. to copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and or a fee. http: dx doi org year# web search engines are a primary mechanism by which people seek information and solve problems. when searchers experience diffi culty in finding information, their struggle may be evident in their search behavior via indicators such as issuing numerous search queries or visiting many results within a search session. how ever, these same search behaviors may also be indicative of explor atory search activity, whereby people actively try to learn a topic and discover new information. accurately distinguishing between struggling and exploring is an important issue for search engines. for example, during post hoc analysis of search logs, the ability to distinguish between these two situations can help to more accurately identify underperforming scenarios, signaling user frus tration or unhappiness. in addition, predictive models could be ap plied to provide appropriate system support if the search situation can be discerned, eg, providing a revised experience for explora tory searches such as a guided tour through related topics. since searchers may be reluctant to describe their situation explic itly to the search engine it is be desirable to predict this automati cally from observed search activity. there is a need to develop methods to automatically identify strug gle and exploration from search behavior. research on leveraging implicit feedback has shown that we can learn when users are dissatisfied based on features of their search activity such as short landing page dwell times and post click query reformulation. previous work on behavioral analysis has shown that multiple query refinements and multiple search result clicks are associated with users experiencing difficulty, frustration, and to events such as search engine switching. however, more querying is not necessarily a negative indicator if the user is learning and con suming content on their journey, and searchers can benefit from the information that they are exposed to as they search. to illustrate the challenge of distinguishing between struggling and exploring automatically, let us present an example of user behavior with a single search session. figure # shows an example of a search session where the user is seeking information on tax soft ware. we can see that in this session the searcher issued many re lated queries and clicked on many results, providing some evidence that they are exploring. however, the queries are closely related, and the inter query time is relatively short for some queries. this provides stronger evidence that the user is in fact struggling to find relevant information pertaining to the annual purchase of specific tax software. in figure #, we see an example of a user exploring different aspects of a topic career development and issuing mul tiple queries and having multiple clicks. while the difference be tween the two types of sessions may be discernible to human judges, existing automatic methods may be unable to perform this distinction using limited information such as the number of queries in the session or session duration. to date, researchers have not de veloped methods to automatically distinguish between struggling and exploring. such mechanisms would have utility for a range of applications, including, as we demonstrate later in the paper, en hancing search satisfaction models, eg, we address this shortcoming with the research presented in this paper. we use behavioral data gathered from a large commercial web search engine and consensus judgments about the type of session from external human assessors. through our analysis, we show clear behavioral differences between struggling and exploring, and use these insights to develop machine learned models capable of accurately distinguishing between the two situations. specifically, we make the following three research contributions with this work presented in this paper: characterize differences in the search behavior associated with struggling and exploring. build predictive models to distinguish between struggling and exploring given behavioral data. integrate the prediction into model of search satisfaction and demonstrate gains in prediction accuracy by considering whether the searcher is struggling or exploring. the remainder of this paper is structured as follows. in section #, we describe related work in areas such as search satisfaction and searcher frustration. section # defines struggling versus exploring and describes the labeled data that we use in our analysis. in section # we compare and contrast search behavior for each of search situ ations. section # describes the predictive model and we provide the findings of our experiments in section #. we discuss the implica tions and limitations in section #, and conclude in section #. his paper reports results from a study in which we automatically classified the query reformulation patterns for, web searching sessions in order to predict what the next query reformulation would be. findings show that reformulation and assistance account for approximately percent of all query reformulations. searchers seem to seek system searching assistant early in the session or after a content change. the results of our evaluations show that the first and second order models provided the best predictability, between and percent overall, and higher than percent for some patterns. we employed angram modeling approach to describe the probability of searchers transitioning from one query reformulation state to another and predict their next state. we developed first, second, third, and fourth order models and evaluated each model for accuracy of prediction. implications are that thegram approach can be used for improving searching systems and searching assistance in real time. one of the major problems users experience searching for information in libraries is the number of places they have to search. it has long been posited that a single search box that searched a range of library resources would solve these problems and make users more effective information seekers in libraries. in this paper we use log analysis to compare user search behaviour in a single search box system with that in a traditional library catalogue. we discover that behaviour varies in response to the results produced by the different systems. web search performance can be improved by either improving the search engine itself or by educating the user to search more efficiently. there is a large amount of literature describing techniques for measuring the former; whereas, improvements resulting from the latter are more difficult to quantify. in this paper we demonstrate an experimental methodology that proves to successfully quantify improvements from user education. the user education in our study is realized in the form of tactical search feature tips that expand user awareness of task relevant tools and features of the search application. initially, these tips are presented in an idealized situation: each tip is shown at the same time as the study participants are given a task that is constructed to benefit from the specific tip. however, we also present a follow up study roughly one week later in which the search tips are no longer presented but the study participants who previously were shown search tips still demonstrate improved search efficiency compared to the control group. this research has implications for search user interface designers and the study of information retrieval systems. research on improving search performance often focuses on the algorithm, input modality, and visualization improvements. however, substantial improvements may also come from research on improving searcher expertise. other researchers share this vision, and one approach has been to improve pedagogical methods for search instruction permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. to copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and or a fee. jacob bien david mease stanford universitygooglestanford, ca mountain view, ca jbien stanford edu dmease google com and opportunities for modeling expertise of others. our study tests the idea that educating searchers can produce a large and valuable improvement in search behavior. search engines have grown increasingly sophisticated and have evolved past the traditional query response paradigm to include scores of tools and options for specifying queries, targeting certain corpora, visualizing results, browsing result sets, and so on. these tools are often hidden but have the potential to offer tremendous efficiency gains to users who know how to use them appropriately. thus, beyond term selection and query formulation, search actions include search techniques, corpus selection, features, and strategies used to solve information needs. a tactic is a low level plan to achieve a search goal, where the goal is simply to solve the present information need. we believe that, in addition to suggesting relevant documents or query reformulations, there is high latent value in making relevant search tactics more salient to users. we illustrate this with two studies: first, a study which demonstrates that users can apply search tactics effectively to improve their search performance, and second a study which demonstrates that some improvements are retained when the tactical tips are removed and roughly one week passes. the results of the study are followed by a discussion of implications for designers and researchers of ir systems and expertise. much attention has been paid to the relative effectiveness of interactive query expansion versus automatic query expansion. although interactive query expansion has the potential to be an effective means of improving a search, in this paper we show that, on average, human searchers are less likely than systems to make good expansion decisions. to enable good expansion decisions, searchers must have adequate instructions on how to use interactive query expansion functionalities. we show that simple instructions on using interactive query expansion do not necessarily help searchers make good expansion decisions and discuss difficulties found in making query expansion decisions. permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. to copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and or a fee. the main argument in favour of iqe is that interactive query expansion gives more control to the user. as it is the user who decides the criteria for relevance in a search, then the user should be able to make better decisions on which terms are likely to be useful, a number of comparative user studies of automatic versus interactive query expansion have come up with inconclusive findings regarding the relative merits of aqe versus iqe. in their experiments they estimated the performance that might be gained if a user was making very good iqe decisions compared to that of real users making the query modification decisions. their conclusion was that users tend to make sub optimal decisions on query term utility. in this paper we revisit this claim to investigate more fully the potential effectiveness of iqe. we also compare human assessment of expansion term utility with those assessments made by the system. the remainder of the paper is structured as follows. query expansion techniques, eg, aim to improve a usersearch by adding new query terms to an existing query. a standard method of performing query expansion is to use relevance information from the user those documents a user has assessed as containing relevant information. the content of these relevant documents can be used to form a set of possible expansion terms, ranked by some measure that describes how useful the terms might be in attracting more relevant documents, all or some of these expansion terms can be added to the query either by the user interactive query expansion or by the retrieval system automatic query expansion. one argument in favour of aqe is that the system has access to more statistical information on the relative utility of expansion terms and can make better a better selection of which terms to add to the userquery. for example, koenemann and belkin demonstrated that iqe can outperform aqe for specific tasks, whereas beaulieu showed aqe as giving higher retrieval effectiveness in an operational environment. one reason for this discrepancy in findings is that the design of the interface, search tasks and experimental methodology can affect the uptake and effectiveness of query expansion techniques. magennis and van rijsbergen attempted to gauge the effectiveness of iqe in live and simulated user experiments. in particular we investigate how good a userquery term selection would have to be to increase retrieval effectiveness over automatic strategies for query expansion. in section # we discuss the motivation behind our investigation and that of magennis and van rijsbergen. in section # we describe our experimental methodology and data. in section # we investigate the potential effectiveness of iqe and in section # we compare potential strategies for helping users make iqe decisions. the trec robust retrieval track explores methods for improving the consistency of retrieval technology by focusing on poorly performing topics. the retrieval task in the track is a traditional ad hoc retrieval task where the evaluation methodology emphasizes a system least effective topics. the year# edition of the track used topics that had been demonstrated to be difficult on one document collection, and ran those topics on a different document collection. relevance information from the first collection could be exploited in producing a query for the second collection, if desired. as in previous years, the most effective retrieval strategy was to expand queries using terms derived from additional corpora. the relative difficulty of topics differed across the two document sets. domain experts search differently than people with little or no domain knowledge. previous research suggests that domain experts employ different search strategies and are more successful in finding what they are looking for than non experts. in this paper we present a large scale, longitudinal, log based analysis of the effect of domain expertise on web search behavior in four different domains. we characterize the nature of the queries, search sessions, web sites visited, and search success for users identified as experts and non experts within these domains. large scale analysis of real world interactions allows us to understand how expertise relates to vocabulary, resource use, and search task under more realistic search conditions than has been possible in previous small scale studies. building upon our analysis we develop a model to predict expertise based on search behavior, and describe how knowledge about domain expertise can be used to present better results and query suggestions to users and to help non experts gain expertise. web searchers differ from each other in many ways that can greatly influence their ability to carry out successful searches. one way in which they can differ is in their knowledge of a subject or topic area. domain expertise is not the same as search expertise, as it concerns knowledge of the subject or topic of the information need, rather than knowledge of the search process. studies of domain expertise have highlighted several differences between experts and non experts, including: site selection and sequencing, task completion time, vocabulary and search expression, the number and length of queries, and search effectiveness. these studies involved small numbers of subjects with carefully controlled tasks, making it difficult to generalize their findings. permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. to copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and or a fee. wsdm, february, year#, barcelona, spain copyright year# acm. in this paper we build on this previous research via a large scale log based study of web search behavior. we contrast the search strategies of domain experts with those of non experts through analysis of naturalistic interaction log data over a three month period of time. this large scale analysis allows us to identify greater diversity in vocabulary, web site visits, and user tasks than is possible with smaller scale laboratory studies. in addition we develop methods for identifying domain experts using online search interaction patterns rather than offline tests of expertise. we focus on four domains medicine, finance, law, and computer science with complex subject matter and a large potential benefit to non experts in identifying effective search strategies. in addition to highlighting differences in the search behavior of experts and non experts, we describe the possible benefits of being able to identify domain experts and leverage their querying strategies and source selection abilities. search tools currently provide the same experience to users regardless of expertise. a cardiologist searching for the latest research studies on heart disease gets the same search results for the query heart disease as a newly diagnosed patient with little background in the area. we believe that by understanding how peopledomain expertise affects their search behavior, we can better support interactions at the appropriate level, and help non experts gain expertise. the remainder of this paper is structured as follows. section # presents related work on domain expertise. section # describes the search logs, and section # the approach used to identify experts within them. in section # we discuss differences and commonalities in the interaction behavior of domain experts and domain non experts. section # presents a classifier that can identify users, actions, and sessions as expert or non expert based on observable behavior, and discusses how such a classifier can be used to improve the web search experience for people of varying domain expertise. domain expertise has been studied extensively in the information science community. one way to help all users of commercial web search engines be more successful in their searches is to better understand what those users with greater search expertise are doing, and use this knowledge to benefit everyone. in this paper we study the interaction logs of advanced search engine users to better understand how these user groups search. the results show that there are marked differences in the queries, result clicks, post query browsing, and search success of users we classify as advanced, relative to those classified as non advanced. our findings have implications for how advanced users should be supported during their searches, and how their interactions could be used to help searchers of all experience levels find more relevant information and learn improved searching strategies. the formulation of query statements that capture both the salient aspects of information needs and are meaningful to information retrieval systems poses a challenge for many searchers. commercial web search engines such as google, yahoo, and windows live search offer users the ability to improve the quality of their queries using query operators such as quotation marks, plus and minus signs, and modifiers that restrict the search to a particular site or type of file. these techniques can be useful in improving result precision yet, other than via log analyses, they have generally been overlooked by the research community in attempts to improve the quality of search results. ir research has generally focused on alternative ways for users to specify their needs rather than increasing the uptake of advanced syntax. research on practical techniques to supplement existing permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. to copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and or a fee. dan morris microsoft research one microsoft way redmond, a dan microsoft com search technology and support users has been intensifying in recent years. however, it is challenging to implement such techniques at large scale with tolerable latencies. typical queries submitted to web search engines take the form of a series of tokens separated by spaces. there is generally an implied boolean and operator between tokens that restricts search results to documents containing all query terms. de lima and pedersen investigated the effect of parsing, phrase recognition, and expansion on web search queries. they showed that the automatic recognition of phrases in queries can improve result precision in web search. however, the value of advanced syntax for typical searchers has generally been limited, since most users do not know about advanced syntax or do not understand how to use it. since it appears operators can help retrieve relevant documents, further investigation of their use is warranted. in this paper we explore the use of query operators in more detail and propose alternative applications that do not require all users to use advanced syntax explicitly. we hypothesize that searchers who use advanced query syntax demonstrate a degree of search expertise that the majority of the user population does not; an assertion supported by previous research. studying the behavior of these advanced search engine users may yield important insights about searching and result browsing from which others may benefit. using logs gathered from a large number of consenting users, we investigate differences between the search behavior of those that use advanced syntax and those that do not, and differences in the information those users target. we are interested in answering three research questions: is there a relationship between the use of advanced syntax and other characteristics of a search is there a relationship between the use of advanced syntax and post query navigation behaviors is there a relationship between the use of advanced syntax and measures of search success through an experimental study and analysis, we offer potential answers for each of these questions. a relationship between the use of advanced syntax and any of these features could support the design of systems tailored to advanced search engine users, or use advanced users interactions to help non advanced users be more successful in their searches. we describe related work in section #, the data we used in this log based study in section #, the search characteristics on which we focus our analysis in section #, and the findings of this analysis in section #. in section # we discuss the implications of this research, and we conclude in section #.