it is well recognised that searchers have diculties communicating their information needs. taylor writes of a series of stages a user goes through when seeking information. these range from experiencing a visceral need, which is probably inexpressible in linguistic terms to a compromised need a representation of the inquirerneed within the constraints of the system and its les. therefore, in order to generate successful queries, the user must overcome several cognitive challenges: to determine himself what the need is and what kind of document will solve it; to choose terms that describe that document well out of a very large set of possibilities and to communicate using the systemvocabulary and not his own. many interactive solutions have been designed to help the user overcome these challenges and improve the representations of information needs systems have to work with. interactive query support ir systems can attain better descriptions of information needs by explicitly asking for certain details. ered a means for users to provide terms and concepts they felt were important and identify relationships between these terms and other concepts in the domain. similarly, kelly and fu used clari cation forms to elicit additional information about the search context from users. the forms queried users on what they knew and what they would like to know about the topic and why. a second technique is to assist the user to iteratively improve their own queries by adding additional terms suggested by the system, commonly referred to as interactive query expansion. this approach gives the user much more control over the search than if the query were to be expanded automatically. er improved performance, it has been shown that users are poor at identifying the terms that will. this nding is intriguing with respect to our aims as it begs the question of whether or not users are able to identify qualities of good terms or whether they just assume terms suggested by a system will automatically be of a high quality. relevance feedback systems are a further means to expand queries without explicitly choosing terms. instead, relevance judgements are solicited on the returned documents. in addition to expanding queries, other scholars have investigated the performance of systems suggesting similar or related queries eg, improving user queries need not be achieved via technical solutions. one group in the year# sigir workshop breakout group identi ed a spectrum of possible solutions from manually led approaches through to automatic, system based approaches. the following section reviews literature on changing user behaviour via primarily non technical means. changing behaviour behaviour change support systems are information systems designed to form, alter, or reinforce attitudes or behaviours or both without using coercion or deception. within the context of search, changes can be made to the underlying retrieval engine or to the interface to nudge people towards submitting longer or better queries or to look deeper in the results list. altering the size and wording of the search box, for example, has been shown to in uence the length of queries submitted. moreover providing a simple google like search interface as opposed to a complicated multi eld catalogue search can radically alter user behaviour. training users on how to construct queries can improve search behaviour. for example, providing guidance on the advanced features that can help with speci. search tasks can improve performance for these tasks and users are able to preserve and use the knowledge gained weeks later. moreover, allowing users to re ect on their own behaviour and, importantly, compare their behaviour to other, expert users, enables individuals to improve their own habits. in users, after re ection, spent longer considering search results and issued longer queries. they also used a wider range of techniques and search engine features. we extend some of the ideas in here. rather than inviting users to compare their behaviour with that of experts, however, we investigate if they are able to learn by comparing their own queries to examples generated by the system to be near optimal for the task at hand. in doing so we relate the kinds of approaches shown in section # with the approaches in this section. we attempt to nudge users to improve their queries via high quality examples shown via widgets similar to those described above. these were shown to be helpful in achieving improved retrieval performance.