regression based modeling of design space over the past few years, a number of excellent regressionbased techniques have been applied to dse and performance analysis. joseph et al employed linear regression to construct linear predictive models of the performance of architecture con gurations. these linear models, however, are not capable of characterizing non linear response behavior of sophisticated design spaces. as a result, joseph et al later employed radial basis function networks to construct non linear regression models of processor performance. in parallel with the above work, pek et al proposed to use anns, and lee and brooks proposed to use spline functions, to model processor responses under superscalar or cmp design scenarios. compared with ann, the results of spline function are easier to interpret but requires human interventions; both methods were found to have similar accuracy. in another piece of work, lee and brooks further demonstrated the effectiveness of spline regression models through pareto front analysis, pipeline depth analysis, as well as multiprocessor heterogeneity analysis. guo et al designed a co training like algorithm to further enhance the accuracy of regression based design space modeling, which was inspired by the paradigm of disagreement based semi supervised learning. lee and brooks proposed the composable performance regression technique to predict the performance of multiple workloads executed on multiprocessor systems, where the cpr technique is based on the combination of spline regression models characterizing uniprocessor performance and contention, respectively. dubach et al proposed to construct a cross application regression model for superscalar architectures executing different applications. their crossapplication model linearly combines a number of applicationspeci. regression models, which predicts processor responses of con gurations with respect to an unseen application at moderate simulation cost for extracting the signature of that application. khan et al independently proposed a similar approach to construct a cross program regression model for a multicore design space. dubach et al employed support vector machine to model a joint architecture compiler design space, and the trained svm can predict the compiler performance across different architecture con gurations. azizi et al proposed to characterize and predict the energy performance trade off of a joint circuit architecture design space with posynomial functions. the above regression techniques for dse had been shown to be accurate on predicting processor responses, yet it is still not clear how they predict relative rankings of con gurations given a limited amount of architectural simulations. our work is substantially different from the above investigations. we no longer stick to the hard regression formulation of dse, but, to the best of our knowledge, we propose for the rst time to formulate dse as a ranking problem. this new formulation can help drastically reduce the number of required simulations. analytical modeling analytical modeling captures architect knowledge and allows to estimate architecture behavior using few or no simulation. noonburg and shen estimate the performance of superscalar processors by probabilistically characterizing program parallelism and machine parallelism. rst order performance model for superscalar processors, which penalizes the ideal performance with miss events. eyerman et al further extended the above model by dividing the instruction execution ow into intervals separated by different miss events. chandra et al proposed a probabilistic model to predict the extra cache misses caused by cache contention between two different threads on a cmp. eklov et al proposed a statistical cache contention model called statcc to predict the performance of a set of co executed threads. chen and aamodt utilized markov chain to accurately model throughput of multicore architectures running multi threaded programs, and their model was later extended to estimate the throughput of multi programmed many core processors. sun et al proposed an analytical performance model called moguls to help architects quickly explore the design space of memory hierarchies. rst order mechanistic analytical model for computing the architectural vulnerability factor by estimating the occupancy of correct path state via inexpensive pro ling. analytical modeling is not simulation intensive, but it can be dif cult to grasp and integrate a large number of interacting parameters within such models. in contrast, our technique is applicable to large and complex design spaces. however, we view analytical models as potentially complementary to ranking models, due to the ability to integrate expert knowledge in ranking models. fast simulation techniques in addition to regression based ranking based techniques which reduce the total number of architectural simulations for dse, there are many fast simulation techniques which can cut down the cost of each simulation. iyengar et al proposed a metric of representativeness for re ned traces and developed a novel graph based heuristic to generate better re ned traces. nussbaum and smith proposed to extract intrinsic program characteristics from a program instruction trace, with which a compact synthetic instruction trace can be generated for simulation. eeckhout et al proposed an improved statistical simulation framework employing a statistical ow graph to accurately characterize the control ow behavior of a program. to reduce simulation overhead for cmp design, genbrugge and eeckhout proposed several statistical quantities to capture the behavior of cache access and shared resource contentions that are critical to the performance of multi programmed programs running on cmps. hughes and li proposed to leverage statistical characteristics that capture the behaviors of memory sharing and inter thread synchronization when constructing synthetic multi threaded programs. there are also techniques which directly extract several short but representative instruction phases from the original program. simpoint clusters execution phases of programs that are characterized by basic block vectors, and then takes the cluster centroids as the representative of simulation phases. smarts selects representative instruction segments from the original program based on statistical sampling theory, which can identify the number of samples suf cient to achieve a user speci ed con dence interval of the performance. fast simulation techniques, which reduce the cost persimulation, are orthogonal and again complementary to our ranking based dse technique, by reducing the time required to build the training set.