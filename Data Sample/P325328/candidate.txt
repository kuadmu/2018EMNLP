to optimize a processor for energy efficiency requires an examination of energy performance trade offs in all aspects of the processor design space, including both architectural and circuit design choices. in this paper, we apply an integrated architecture circuit optimization framework to map out energy performance trade offs of several different high level processor architectures. we show how the joint architecture circuit space provides a trade off range of approximately in performance for energy, and we identify the optimal architectures for different design objectives. we then show that many of the designs in this space come at very high marginal costs. our results show that, for a large range of design objectives, voltage scaling is effective in efficiently trading off performance and energy, and that the choice of optimal architecture and circuits does not change much during voltage scaling. power consumption has become a major constraint in the design of processors today. finally, we show that with only two designs a dual issue in order design and a dual issue out of order design, both properly optimized a large part of the energy performance trade off space can be covered within of the optimal energy efficiency. as the semiconductor industry has scaled into very small feature sizes, however, the need to control leakage current has prevented further threshold and supply voltage scaling. this break from dennard scaling has led to rapid increases in power density, and power consumption is now a primary constraint in all microprocessor design. not only does power dissipation impact battery life in embedded devices, it also constrains achievable performance in server architectures. ciency, a designer must consider the cost bene. of all design options, choosing those features and parameter values that. er the best return in terms of performance per unit energy. while this strategy is straightforward in theory, in practice, it has been di cult to automate since the space of processor design options is often extremely large, and one needs to consider trade. fortunately, previous research has already created many of the pieces needed to create such an optimization framework. recent advances in microarchitectural design space modeling through statistical sampling and regression techniques have opened the door to large scale architectural design space exploration and evaluation. at the circuit level, there also exist numerous tools that can characterize energy delay trade. moreover, work over the past few decades has created extremely. cient methods to nd the optimal solutions to problems with convex optimization objective functions. we leverage these prior works to characterize a joint circuit architecture design space; by creating architectural models and circuit trade. characterizations that have log convex forms, we use geometric program solvers to optimize our model over this joint design space to map out the overall energy performance trade. we have found that joint architecture and circuit optimization can save between to of the required energy, depending on the design objectives. in this paper, we use this framework to explore a broad space of designs ranging from a simple single issue in order design to an aggressive quad issue out of order machine. the results of the optimization determine the choice of underly log convex functions are convex after applying log transformation. ing microarchitectural parameters, circuit implementations, and operating voltage. yielded a performance range that was modest: the resulting optimal energy performance curves tend to have rapidly changing marginal energy costs. enhancing architecture design parameters to improve performance quickly requires large increases in energy. cient for a broad range of performance and energy targets. technology scaling has historically been a driving force behind microprocessor performance. in the architecture, the circuit design and potentially the technology. conversely, trying to save energy quickly leads to rapid losses in performance. our results show that, without voltage scaling, the architectural and circuit trade. voltage scaling has more slowly diminishing marginal costs and we nd, with voltage scaling, a small subspace of architectures and circuits are. power dissipation and thermal issues are increasingly significant in modern processors. as a result, it is crucial that power performance tradeoffs be made more visible to chip architects and even compiler writers, in addition to circuit designers. most existing power analysis tools achieve high accuracy by calculating power estimates for designs only after layout or floorplanning are complete. in addition to being available only late in the design process, such tools are often quite slow, which compounds the difficulty of running them for a large space of design possibilities. this paper presents wattch, a framework for analyzing and optimizing microprocessor power dissipation at the architecture level. wattch is year#x or more faster than existing layout level power tools, and yet maintains accuracy within of their estimates as verified using industry tools on leading edge designs. this paper presents several validations of wattch accuracy. in addition, we present three examples that demonstrate how architects or compiler writers might use wattch to evaluate power consumption in their design process. we see wattch as a complement to existing lower level tools; it allows architects to explore and cull the design space early on, using faster, higher level tools. it also opens up the field of power efficient computing to a wider range of researchers by providing a power evaluation methodology within the portable and familiar simplescalar framework. the microarchitectural design space of a new processor is too large for an architect to evaluate in its entirety. even with the use of statistical simulation, evaluation of a single configuration can take excessive time due to the need to run a set of benchmarks with realistic workloads. this paper proposes a novel machine learning model that can quickly and accurately predict the performance and energy consumption of any set of programs on any microarchitectural configuration. this architecture centric approach uses prior knowledge from off line training and applies it across benchmarks. this allows our model to pre dict the performance of any new program across the entire microarchitecture configuration space with just further simulations. we compare our approach to a state of the art program specific predictor and show that we significantly reduce pre diction error. we reduce the average error when predicting performance from to just and increase the cor relation coefficient from to. we then show that this predictor can be used to guide the search of the design space, selecting the best configuration for energy delay in just further simulations, reducing it to. we also eval uate the cost of off line learning and show that we can still achieve a high level of accuracy when using just bench marks to train. finally, we analyse our design space and show how different microarchitectural parameters can af fect the cycles, energy and energy delay of the architectural configurations. architects use cycle accurate simulators to explore the design space of new processors. however, in superscalar processors the number of different variables and the range of values they can take makes the design space too large to be completely evaluated. this is coupled with the fact that cycle accurate simulation can be slow due to the need for detailed modelling of the microarchitecture and the desire to simulate many benchmarks with realistic workloads. recently, several techniques based on statistical sampling have been developed to reduce the time taken for simulation, such as simpoint and smarts. however, although these schemes increase the number of simulations possible within a given time frame, given the huge size of the design space to be explored, a full evaluation remains unrealistic. several studies have proposed the use of machine learning to help evaluate this massive space. these schemes require a number of simulations of a benchmark to be run, the results from which are used to train a predictor. this can then be used to determine the rest of the design space without the need for further simulation. however, existing techniques suffer from several major drawbacks. whenever a new program is considered, a new predictor must be trained and built, meaning there is a large overhead even if the designer just wants to compile with a different optimisation level. our approach learns across programs and captures the behaviour of the architecture rather than the program itself; a large number of training simulations are needed to use these existing predictors, offsetting the bene ts of the schemes. in our approach, having previously trained off line on a small number of programs, we only need a few simulations, called a signature, in order to characterise each new program we want to predict. we show that, in fact, this can be as low as just simulations to maintain a high level of accuracy; existing works only give the error of their models. no information is given on how the models are used in prediction real prediction real energy energy year# year# year# year# year# year# year# year# configurations configurations program speci. the design space of applu when considering energy. we show the predictions given by a program speci. both models are given the same simulations from this program, with the architecture centric predictor having also been trained off line on different benchmarks. practice to select good con gurations by searching the design space. we show how our model can be used to search for the best con guration in terms of cycles, energy and energy delay. this paper presents a new and different approach to design space exploration using machine learning. we use existing knowledge to predict a new program on any given architecture con guration, something no other research has successfully attempted. we train our architecture centric model off line on a number of benchmark programs, then, using a completely new program never seen before, we run just simulations of the new program. we can then predict the rest of the design space of billion con gurations. this means that encountering a new program, or simply exploring the compiler optimisation space, can be done ef ciently, at the same time as microarchitectural design space exploration, with low overhead. this is an order of magnitude less than the current state of the art, program speci. approaches and shows the ability to learn across programs, using prior knowledge to predict new programs. although absolute error is an important metric to evaluate the accuracy of our predictor, in this setting of design space exploration, correlation is equally important. this shows how the model can follow the trend of the space. hence we show the rmae and correlation coef cient for our architecture centric predictor and prove that it is better than other, existing approaches. we then use our model to perform a search of the architectural design space and compare it against an existing program speci. we show that after training we can nd the best point in randomly selected con gurations by performing just further simulations per benchmark, compared to the programspeci. one reasonable criticism of our work could be that the cost of off line training is too high. we address this by considering the use of just factory programs and show that even with exactly the same number of total simulations our model has an error times smaller than program speci. we thus show that even if all off line training were considered part of the overall training budget, our approach still outperforms existing techniques. finally, we analyse the design space and provide a statistical characterisation of it. we show how different architectural parameters affect cycles, energy and ed and characterise good design points. the rest of this paper is structured as follows. section # provides a simple example showing the accuracy of our predictor. we describe our design space in section # and then show the use of our model to predict the performance of an architecture con guration on any new program in section #. section # evaluates the use of our model in searching the whole space, then section # addresses the cost of offline training. we characterise our design space in section # and describe work related to ours, especially the programspeci. predictor that we compare against throughout this work, in section #. finally, we conclude this paper in section #. embedded processor performance is dependent on both the underlying architecture and the compiler optimisations applied. however, designing both simultaneously is extremely difficult to achieve due to the time constraints designers must work under. therefore, current methodology involves designing compiler and architecture in isolation, leading to sub optimal performance of the final product. this paper develops a novel approach to this co design space problem. for any microarchitectural configuration we automatically predict the performance that an optimising compiler would achieve without actually building it. once trained, a single run of on the new architecture is enough to make a prediction with just a error rate. this allows the designer to accurately choose an architectural configuration with knowledge of how an optimising compiler will perform on it. we use this to find the best optimising compiler architectural configuration in our co design space and demonstrate that it achieves an average performance improvement and energy savings of compared to the baseline, leading to an energy delay value of. embedded system performance is usually achieved via ef cientprocessordesign and optimising compilertechnology. fast time to market is critical for the success of any new product and therefore it is crucial to design new microprocessors quickly, without sacri cing performance. however, during early design stages, architectural decisions must be taken with only limited knowledge of other system components, especially the compiler. ideally we would like to consider both architecture and optimising compiler design simultaneously, selecting the best combination. unfortunatelyexploring this combineddesign or co design space is extremely time consuming. for each architecture to consider we would have to build an optimising compiler, whichisclearlyimpractical. instead, typicaldesignmethodology consists of rst selecting an architecture under the assumption that the optimising compiler can deliver a certain level of performance. then, a compiler is built and tuned forthat architecture which willhopefully delivertheperformance levels assumed. clearly this is a sub optimal way of designing systems. the compiler team may not be able to deliver a compiler that achieves the architectexpectations. more fundamentally, if we could predict the performance of the eventual optimising compiler on any architecture, then an entirely di erent architecture may have been chosen. this inability todirectlyinvestigate the combined architecture optimising compilerinteractions means we end updesigning tomorrowarchitectures based on yesterdaycompiler technology. inthispaper wepropose a novelapproachtothis co design space problem. we build a machine learning model that can automatically predict the performance of an optimising compiler across an arbitrary architecture space without tuning the compiler rst. this allows the designer to accurately determine the performance of any architecture as if an optimising compiler were available. given a small sample of the architecture and optimisation space, our model canpredicttheperformance of ayet to be tuned optimising compiler using information gained from a nonoptimising baseline compiler. this achieves an error rate of across all microarchitectures in the co design space. the use of predictors, particularly to reduce simulation time, is not new. several authors have shown that it is possibletopredicttheperformanceof. in thisistaken one step further where a figure #: execution time, energy and ed of each benchmark from mibench when compiled with and, normalised by. table #: microarchitectural parameters and the rangeof valuesthey cantake. eachparametervaries as a power of, with, total con gurations. model predicts the performance of compiler settings on different architecturesfora xedprogram. however, aswe will show in section #, this approach fails to accurately predict the performance of an optimising compiler. to the best of ourknowledge, weproposethe rst modeltopredicttheperformance of an optimising compiler across the architecture space before the compiler is tuned. in this work we separately explore the microarchitectural and compiler optimisation spaces. we then show that there is thepotentialfor signi cantimprovementover thebaseline processor and compiler by exploring the combined co design space. we also demonstrate that the optimal compiler for one architecture is not the best for all. we build our model that predicts the performance of an optimising compiler on any microarchitectural con guration. we then use it to nd thebest architectural optimising compiler con guration and demonstrate that for this architecture, an optimising compilercandeliverthepredictedperformance. thebestdesign achievessigni cantperformanceincreases resultingina improvement in execution time, savings in energy and an energy delayproduct of. the rest of this paper is structured as follows. section # characterises the microarchitectural and compiler optimisation spaces in isolation whilst section # explores the combined design space. we build a machine learning model in section # and evaluate it against a state of the art alternative approach in section #. here we also show how our model is used to select the best architecture optimising compiler combination and that this con guration does achieve the predicted level of performance. finally, section # describes related work and section # concludes. adaptive micro architectures are a promising solution for designing high performance, power efficient microprocessors. they offer the ability to tailor computational resources to the specific requirements of different programs or program phases. they have the potential to adapt the hardware cost effectively at runtime to any application needs. however, one of the key challenges is how to dynamically determine the best architecture configuration at any given time, for any new workload. this paper proposes a novel control mechanism based on a predictive model for micro architectural adaptivity control. this model is able to efficiently control adaptivity by monitoring the behaviour of an application different phases at runtime. we show that using this model on spec year#, we double the energy performance efficiency of the processor when compared to the best static configuration tuned for the whole benchmark suite. this represents \ of the improvement available if we knew the best micro architecture for each program phase ahead of time. in addition, we show that the overheads associated with the implementation of our scheme have a negligible impact on performance and power. designing a new microprocessor is extremely time consuming one of the contributing reasons is that computerdesigners rely heavily on detailed architectural simulations, which are very time consuming. recent workhas focused on statistical simulation to address this issue the basic idea of statistical simulation is to measurecharacteristics during program execution, generate asynthetic trace with those characteristics and then simulatethe synthetic trace. the statistically generated synthetictrace is orders of magnitude smaller than the original programsequence and hence results in significantly fastersimulation this paper makes the following contributions to the statisticalsimulation methodology. first, we propose the useof a statistical flow graph to characterize the control flow ofa program execution. second, we model delayed update ofbranch predictors while profiling program execution characteristics experimental results show that statistical simulationusing this improved control flow modeling attainssignificantly better accuracy than the previously proposedhls system. we evaluate both the absolute and the relativeaccuracy of our approach for power performance modelingof superscalar microarchitectures. the results showthat our statistical simulation framework can be used to efficientlyexplore processor design spaces. designing a new microprocessor is both complex and time consuming. computer designers rely heavily on detailed architectural simulators to identify the optimal design in a large design space under a number of constraints such as chip area, power budget, etc. these architectural simulation tools are at least a factor of a thousand slower than native hardware execution. another issue that contributes to the long simulation time ece department the university of texas at austin ece utexas edu is the use of real world applications as benchmarks and the ever increasing number of dynamic instructions that need to be simulated. the increasing performance of current microprocessor systems coupled with the increasing complexity of current computer applications means that the dynamic instruction count must be increased proportionally to simulate a respectable time slice of a real system. for example, some benchmarks in the spec cpu benchmark suite have a dynamic instruction count that is greater than billion instructions. since several benchmarks may need to be simulated and various design points evaluated, the consequences are an impractically long simulation time and an undesirably long time to market. researchers have proposed several techniques to shorten the total simulation time such as sampling, reduced input sets and analytical modeling. over the last few years, interest has grown in yet another approach, namely statistical simulation. the basic idea of statistical simulation is simple: measure a well chosen set of program characteristics during execution, generate a synthetic trace with those characteristics and simulate the synthetic trace. if the set of characteristics re ects the key properties of the programbehavior, accurate performance power predictions can be made. the statistically generated synthetic trace is several orders of magnitude smaller than the original program execution, and hence simulation nishes very quickly. the goal of statistical simulation is not to replace detailed simulation but to be a useful complement. statistical simulation can be used to identify a region of interest in a large design space that can, in turn, be further analyzed through slower but more detailed architectural simulations. in this paper, we present an improved statistical simulation framework that extends previous work with two major contributions. first, we propose the use of a statistical ow graph to characterize the control ow of a programexecution. control ow behavior is characterized by modeling sequences of basic blocks along with their mutual transition probabilities and execution characteris tics. this statistical ow graph combines the graph representation proposed in the smart technique by iyengar et al with previously proposed statistical simulation frameworks. of smart, workload modeling accuracy, with the major bene ts of statistical simulation, simplicity and rapid convergence. second, we show that it is important to consider delayed update when characterizing the branch behavior. this improved statistical simulation framework is extensively evaluated by considering both absolute and relative accuracy in modeling the performance and energy consumption of superscalar microarchitectures. we report an average error of and for predicting performance and energy, respectively, on an way superscalar out oforder processor using specint benchmarks. we also show that our framework is signi cantly more accurate than the previously proposed hls framework. in addition, we demonstrate that the error when predicting relative performance power trends is generally less than. as a consequence, we conclude that statistical simulation is a useful tool for accurately and ef ciently exploring processor design spaces. section # presents our statistical simulation framework: the use of the statistical ow graph is discussed and our branch pro ling approach using delayed update is proposed. section # discusses our experimental setup which is used in section # during the evaluation. related work and how it differs from this work is discussed in section #. this work presents statcc, a simple and efficient model for estimating the contention for shared cache resources between co scheduled applications on chip multiprocessor architectures. statcc leverages the statstack cache model to estimate the co scheduled applications cache miss ratios, and a simple performance model that estimates their cpis based on the estimated miss ratios. these methods are combined into a system of equations that models the contention for the shared cache resources and can be solved to determine the cpis and miss ratios of the co scheduled applications. the result is a fast algorithm with a error across spec cpu benchmark suite compared to a simulated cmp system with a hierarchy of private and shared caches. furthermore, the profiling data used by statcc is collected with a runtime overhead of only. chip multiprocessor architectures sharing on chip resources, such as last level caches, have recently become a mainstream computing platform. the performance of such systems can vary greatly depending on how co scheduled applications compete for these shared resources. each type of miss event results in characterizable performance behavior for the execution time interval. by considering an interval type and length, execution time can be predicted for the interval. the mechanistic model provides several advantages over prior modeling approaches, and, when estimating performance, it differs from detailed simulation of a wide out of order processor by an average of. second, we use the mechanistic model to study scaling of both pipeline depth and width in balanced processor designs. for example, we show that at optimal design points, the pipeline depth times the square root of the processor width is nearly constant. finally, we consider the behavior of unbalanced, overprovisioned processor designs based on insight gained from the mechanistic model. a mechanistic model for out of order superscalar processors is developed and then applied to the study of microarchitecture resource scaling. first, we use the model to determine size relationships among microarchitecture structures in a balanced processor design. we corroborate previous results in this area and provide new results. designs where a processor dispatch width is wider than its issue width are of particular interest. the model divides execution time into intervals separated by disruptive miss events such as branch mispredictions and cache misses. overall execution time is then determined by aggregating the execution time over all intervals. the mechanistic model is applied to the general problem of resource scaling in out of order superscalar processors. we show that in certain situations an overprovisioned processor may lead to improved overall performance. although detailed simulation provides accurate feedback regarding speci. most readers will readily recognize the primary resources, and section # will discuss them in a more detail. under ideal conditions the processor sustains a level of performance roughly equal to the superscalar dispatch bandwidth. interval analysis thereby provides a way of visualizing the signi cant performance events that take place in an out of order processor without requiring detailed tracking of extremely large numbers of individual instructions. eyerman et al approaches typically lump together program characteristics and or microarchitecture effects, often characterizing multiple effects with a single parameter. to demonstrate the usefulness of the mechanistic model, we apply it to study resource scaling in out of order processors. we study scaling relationships between pipeline depth and performance. superscalar pipeline depth scaling has been extensively studied or over two decades. these relationships have not been widely studied previously. we show that for maintaining optimal designs, simultaneously scaling toward wider and deeper pipelines are in opposition. we show that some overprovisioned processor designs may provide performance improvements due to transient conditions caused by miss events. we rst summarize superscalar out of order processor microarchitecture in section #. subsequently, in section #, we use the model for studying resource scaling of out of order processors. design con gurations, individual simulations give relatively little insight into the fundamental interactions that take place within the processor. it requires a very large number of detailed simulations to capture trends and relationships involving microarchitecture parameters and applications. in this article we propose a mechanistic model, interval analysis, as a better method for gaining insight into superscalar out of order processors and for guiding higher level design decisions. where the average behavior of key performance related phenomena provides the needed insight. mechanistic processor modeling interval analysis is a mechanistic model; that is, it is derived from the actual mechanisms in the processor that lead to performance related behavior. a mechanistic model has the advantage of directly displaying the performance effects of individual, underlying mechanisms, expressed in terms of program characteristics and machine parameters, such as instruction level parallelism, misprediction rates, processor width, and pipeline depth. our proposed mechanistic model, in contrast, is built up from internal processor structure and does not need detailed processor simulation to. using the interval model for superscalar out of order processor performance estimation with the spec cpu integer benchmarks as a workload, we nd that estimated performance differs from detailed simulation by about on average for a wide out of order processor. in addition, we demonstrate that across a wide processor design space the mechanistic model closely tracks performance estimates from detailed simulation. in addition, we provide the new insight that these back end buffer resources also scale quadratically with pipeline depth in a balanced processor design. we study scaling relationships between pipeline width and performance, as well as the relationship between pipeline width and depth. in fact, we derive the result that for a combination of optimum pipeline depth and width, the depth times the square root of the width is nearly constant. for example, there is an overall performance advantage in having a front end dispatch width greater than the issue width, and we study this con guration in some detail. section # then discusses and validates the mechanistic model in detail. for studying superscalar out of order processors, both researchers and designers rely heavily on detailed simulation. figure # illustrates a typical superscalar out of order processor with some of the key microarchitecture resources identi ed. in its current formulation, interval analysis focuses on the ow of instructions through the dispatch stage of a superscalar out of order processor in this article, dispatch refers to the movement of instructions from the front end pipeline into the reorder and issue buffers. the basis for interval analysis is the observation that, in the absence of miss events such as branch mispredictions and cache misses, a well balanced superscalar out of order processor should smoothly stream instructions through its pipelines, buffers, and functional units. however, the smooth dispatch of instructions is intermittently disrupted by miss events. the effects of these miss events at the dispatch stage divide execution time into intervals, and these intervals serve as the fundamental entity for analysis and modeling; see figure #. both pipelined instruction processing and the interactions among instructions are modeled at a statistical level in previous versions, we focused on the issue stage, but have since found that focusing on the dispatch stage leads to a simpler formulation. performance can be analyzed by dividing time into intervals between miss events. the mechanistic structure is in contrast to the more common empirical models which use machine learning techniques to empirically infer a performance model or hybrid mechanistic empirical modeling which begins with high level parameterized equations that have parameters adjusted to. or infer the model; however, we do use detailed simulation to demonstrate the accuracy of the model after it has been constructed. resource scaling of superscalar out of order processors an important consideration when designing an out of order processor is the way that the various structure sizes and bandwidths scale with respect to one another. because the various resources and instructions interact in complex ways, a structural, or mechanistic, model is very useful for understanding the fundamental relationships between the instruction stream and these interacting resources. we discuss scaling relationships among front end and back end processor resources and pipeline depth. we reenforce the already known fact that in a balanced processor design most of the back end buffer resources scale quadratically with the pipeline width. however, our model breaks pipeline depth scaling into ner components so that the scaling effects of speci. article outline the article is organized as follows. for supervised learning, however, considerable simulation costs are required for attaining the labeled design configurations. empirical study demonstrates that coal significantly outperforms a state of the art dse technique by reducing mean squared error by to, and thus, promising architectures can be attained more efficiently. ever increasing design complexity and advances of technology impose great challenges on the design of modern microprocessors. one such challenge is to determine promising microprocessor configurations to meet specific design constraints, which is called design space exploration. in the computer architecture community, supervised learning techniques have been applied to dse to build regression models for predicting the qualities of design configurations. given limited resources, it is difficult to achieve high accuracy. in this article, inspired by recent advances in semisupervised learning and active learning, we propose the coal approach which can exploit unlabeled design configurations to significantly improve the models. xu, institute of computing technology, chinese academy of sciences, beijing, year#, china; zhou, national key laboratory for novel software technology, nanjing university, nanjing year#, china. permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies show this notice on the rst page or initial screen of a display along with the full citation. copyrights for components of this work owned by others than acm must be honored. to copy otherwise, to republish, to post on servers, to redistribute to lists, or to use any component of this work in other works requires prior speci. permissions may be requested from publications dept, acm, inc, penn plaza, suite, new york, ny year# usa, fax, or permissions acm org. along with the corresponding responses obtained by simulations, these labeled design con gurations are utilized to train a regression model that characterizes the relationship between the design parameters and processor responses. in the predicting phase, such a regression model is employed to predict the responses of new design con gurations that are not involved in the training set. since simulations are only required in the training phase, predictive modeling is relatively ef cient in comparison with traditional approaches. in fact, the design con gurations that have not been simulated may also be effective in enhancing the prediction accuracy of a regression model, which are overlooked by previous investigations on dse. the key intuition is that similar architectural con gurations would behave similarly, and thus, some unlabeled design con gurations can be labeled for enhancing the prediction accuracy. generally speaking, coal works in the cotraining style, which is an algorithm falling into the disagreementbased learning paradigm, where two learners label unlabeled instances for each other. at each iteration, coal also simulates the most informative unlabeled instance on which the two learners exhibit the largest disagreement, which is inspired by active learning. at the beginning of a typical dse procedure, coal initializes two regression trees by using an initial data set containing several labeled design con gurations. furthermore, we also conduct experiments to demonstrate that coal can achieve better prediction accuracy compared with pure cotraining semisupervised learning and pure active learning approaches, which further demonstrates the superiority of coal approach. when designing a microprocessor, the rst and probably the most important step is to decide appropriate design con gurations satisfying different performance power temperature reliability constraints, which is called as design space exploration. this work was partially supported by the strategic priority research program of the chinese academy of sciences, the nsfc, the program, the program, and the nationalt major project of china. year# acm year# year# art doi: http: dx doi org year# acm transactions on intelligent systems and technology, vol. it has become a great challenge to computer architects, since the size of design space grows exponentially with the number of interactive design parameters, and the simulation required by evaluating the quality of each con guration of design parameters is quite time consuming. moreover, the dif culty of dse task is further exacerbated by the increasing amount and complexity of computer workloads with signi cantly different characteristics. traditionally, computer architects employed large scale cycle accurate architectural simulations on representative benchmarks to explore the design space. however, timeconsuming simulations make it intractable to explore the entire design space. for instance, during the design of godson, which is a core chip multiprocessor with a recon gurable architecture, it takes several weeks to simulate only one design con guration on spec cpu benchmark suite. to reduce the simulation costs, several fast simulation approaches were proposed to reduce the number of simulated instructions with respect to each design con guration. however, the number of design con gurations to simulate is still quite large. to reduce the number of simulated con gurations and thus reduce the overall simulation costs, predictive modeling was proposed. as illustrated in figure #, a predictive modeling approach contains two phases, that is, training phase and predicting phase. in the training phase, some design con gurations are simulated. however, considerable simulation costs are required to attain the labeled design con gurations for supervised learning, which encumbers the models from achieving high prediction accuracies given limited computational resources and stringent design to market pressure. to enable the learned model to be comprehensible for computer architects and designers, coal employsp regression trees as the base learner. after that, coal starts the semisupervised active learning process consisting of a number of iterations. in every iteration, each regression tree is re ned by not only the design con guration labeled by the other regression tree, but also the con guration newly simulated by the processor simulator. the key issue here is how to select appropriate unlabeled con gurations to label or simulate, which will be elaborated in section #. to demonstrate the effectiveness of coal, we conduct comprehensive experiments to explore a typical superscalar microprocessor design space. experiments show that, given the same simulation budget to attain the labels of training design con gurations, coal can reduce by mean squared error of the state of the art ann dse technique. the rest of the article proceeds as follows. to circumvent these de ciencies of previous techniques, in this article, we propose the coal approach for the challenging dse problem. architects use cycle by cycle simulation to evaluate design choices and understand tradeoffs and interactions among design parameters. efficiently exploring exponential size design spaces with many interacting parameters remains an open problem: the sheer number of experiments renders detailed simulation intractable. we attack this problem via an automated approach that builds accurate, confident predictive design space models. we simulate sampled points, using the results to teach our models the function describing relationships among design parameters. the models produce highly accurate performance estimates for other points in the space, can be queried to predict performance impacts of architectural changes, and are very fast compared to simulation, enabling efficient discovery of tradeoffs among parameters in different regions. we validate our approach via sensitivity studies on memory hierarchy and cpu design spaces: our models generally predict ipc with only error and reduce required simulation by two orders of magnitude. we also show the efficacy of our technique for exploring chip multiprocessor design spaces: when trained on a sample drawn from a cmp design space with points and up to performance swings among different system configurations, our models predict performance with only error on average. our approach combines with techniques to reduce time per simulation, achieving net time savings of three four orders of magnitude. architects quantify the impact of design parameters on evaluation metrics to understand tradeoffs and interactions among those parameters. such analyses usually employ cycle by cycle simulation copyright year# association for computing machinery. acm acknowledges that this contribution was authored or co authored by a contractor or af liate of the. as such, the government retains a nonexclusive, royalty free right to publish or reproduce this article, or to allow others to do so, for government purposes only. of a target machine either to predict performance impacts of architectural changes, or to nd promising design subspaces satisfying different performance cost complexity power constraints. several factors have unacceptably increased the time and resources required for the latter task, including the desire to model more realistic workloads, the increasing complexity of modeled architectures, and the exponential design spaces spanned by many independent parameters. thorough study of even relatively modest design spaces becomes challenging, if not infeasible. nonetheless, sensitivity studies of large design spaces are often essential to making good choices: for instance, kumar et al. nd that design decisions not accounting for interactions with the interconnect in a cmp are often opposite to those indicated when such factors are considered. research on reducing time per experiment or identifying the most important subspaces to explore within a full parameter space has signi cantly improved our ability to conduct more thorough studies. even so, simulation times for thorough design space exploration remain intractable for most researchers. we attack this problem by using arti cial neural networks to predict performance for most points in the design space. we view the simulator as a nonlinear function of itsparameter con guration: sim. instead of sampling this function at every point of interest, we employ nonlinear regression to approximate it. we repeatedly sample small numbers of points in the design space, simulate them, and use the results to teach the anns to approximate the function. at each teaching step, we obtain highly accurate error estimates of our approximation for the full space. we continue re ning the approximation by training the anns on further sample points until error estimates drop suf ciently low. by training the anns on of a design space, we predict results for other design points with accuracy. the anns are extremely fast compared to simulation, and our approach is fully automated. combining our models with simpoint reduces required cpu time by threefour orders of magnitude, enabling detailed study of architectural design spaces previously beyond the reach of current simulation technology. this allows the architect to purge most of the uninteresting design points quickly and focus detailed simulation on promising design regions. most importantly, our approach fundamentally differs from heuristic search algorithms in scope and use. it can certainly be used for optimization, but we provide a superset of the capabilities of heuristics that intelligently search design spaces to optimize an objective function. speci cally, our technique: output output output outputoutput layer layer hidden layer hidden layer hidden layer input layer input layer input input input figure #. simpli ed diagrams of fully connected, feed forward ann generates accurate predictions for all points in the design space. unlike heuristic search techniques, our models can be queried to predict performance impacts of architectural changes, enabling ef cient discovery of tradeoffs among parameters in different regions. these increase con dence in results, and provide a well crafted knob for the architect to control the accuracy speed tradeoff inherent in architectural modeling. veri es that apparent performance gains from a novel proposal are not mere artifacts of other parameters chosen. allows architects to observe the sensitivity of a proposal to interacting parameters. this allows more thorough evaluation, increasing con dence in novel architectural ideas. after training on of our design spaces, querying our models to identify design points within of the predicted optimal ipc purges over of design points. querying again to identify points within a given power budget, for instance, could eliminate comparable portions of remaining subspaces. inspection of these spaces can then provide insight to guide subsequent design decisions. efficiently exploring exponential size architectural design spaces with many interacting parameters remains an open problem: the sheer number of experiments required renders detailed simulation intractable. we attack this via an automated approach that builds accurate predictive models. we simulate sampled points, using results to teach our models the function describing relationships among design parameters. the models can be queried and are very fast, enabling efficient design tradeoff discovery. we validate our approach via two uniprocessor sensitivity studies, predicting ipc with only error. in an experimental study using the approach, training on of a point cmp design space allows our models to predict performance with only error. our predictive modeling combines well with techniques that reduce the time taken by each simulation experiment, achieving net time savings of three four orders of magnitude. architects rely on this understanding to perform cost bene. one key point to take away from this work is that sampling design spaces at too coarse a granularity can lead us to draw inappropriate conclusions. quantifying the impact of design parameters on evaluation metrics and understanding tradeoffs and interactions among such parameters permeates the foundation of computer architecture. such analyses usually employ cycle by cycle simulation of a target machine either to predict performance impacts of architectural changes, or to nd promising design subspaces satisfying different performance cost complexity power constraints. several factors have unacceptably increased the time and resources required for the latter task, including the desire to model more realistic workloads, the increasing complexity of modeled architectures, and the exponential design spaces spanned by many independent parameters. thorough study of even relatively modest design spaces becomes challenging, if not infeasible. nonetheless, sensitivity studies of large design spaces are often essential to making good choices: for instance, kumar et al. nd that design decisions not accounting for interactions with the interconnect in a chip multiprocessor are often opposite to those indicated when such factors are considered. research on reducing the time required for individual experiments or on identifying the most important subspaces to explore within a full parameter space has signi cantly improved our ability to conduct more thorough studies. even so, simulation times for thorough design space exploration remain intractable for most researchers. the community inevitably relies on experience and intuition about architectural design spaces in choosing subspaces to study or in deciding how to apply the various tools at our disposal, but rapid changes in technologies and the growing complexities of both the architectural design spaces and workload con guration spaces suggest that our historical experiences and intuitions may no longer apply in the same ways. we need tools and methodologies to validate our intuitions as we move into an era of multiclock domain, many core systems that execute increasingly complex software stacks. we attack these design space problems by using arti cial neural networks to predict performance for most points in very large design spaces. we view the architecture simulator as a nonlinear function of itsparameter con guration: sim. instead of sampling this function at every point of interest, we employ powerful nonlinear regression to approximate it. we repeatedly sample small numbers of points in the design space, simulate them, and use the results to teach the anns to approximate the function. at each teaching step, we obtain highly accurate error estimates of our approximation for the full space. we continue re ning the approximation by training the anns on further sample points until error estimates drop suf ciently low. by training the anns on of a design space, we predict results for other design points with high accuracies. the anns are extremely fast compared to simulation and our approach is fully automated. combining our models with simpoint reduces required cpu time by three to four orders of magnitude, enabling detailed study of architectural design spaces previously beyond the reach of current simulation technology. this allows the architect to purge uninteresting design points quickly and focus detailed simulation on the most promising design subspaces. most importantly, our approach fundamentally differs from heuristic search algorithms in scope and use. it can certainly be used for optimization, but we provide a superset of the capabilities of heuristics that intelligently search design spaces to optimize an objective function. speci cally, our technique: generates accurate predictions for all points in the design space. unlike heuristic search techniques, our models can be queried to predict performance impacts of architectural changes, enabling ef cient discovery of tradeoffs among parameters in different regions. these increase con dence in results, and provide a well crafted knob for the architect to control the accuracy speed tradeoff inherent in architectural modeling. veri es that apparent performance gains from a novel proposal are not mere artifacts of other parameters chosen. allows architects to observe the sensitivity of a proposal to interacting parameters. this allows more thorough evaluation, increasing con dence in novel architectural ideas. since all regression methods ultimately rely on interpolation between training samples, a global optimum that is an outlier with much higher performance than any of the training data is unlikely to be predicted with high accuracy. this limitation does not constitute an important drawback to our approach: our primary goal is not nding a single point that optimizes an objective function, but rather building models that can predict performance for all points in the design space. this allows architects to: compute correlations among parameters in different regions using statistical tests. query the models to nd high performance regions of the space that satisfy a cost or power budget. visualize query results to inspect trends, trade offs, and performance sensitivity across the design space. calculate interaction costs among all parameters with high accuracy. evaluate novel architectural features across large design spaces, leading to more thorough and objective comparisons among a multitude of alternatives. ipek et al observe performance plateaus to nd the right combination of architectural features that can be appropriately downsized to reduce area overheads with minimal performance loss. after training on of our design spaces, querying our models to identify design points within of the predicted optimal ipc purges over of the design points. querying again to identify points within a given power budget, for instance, could eliminate comparable portions of remaining subspaces. inspection of these spaces can then provide insight to guide subsequent design decisions. our approach is truly a design space exploration method, not simply an optimization technique. given appropriate training data, our models can answer queries such as which points in the design space are likely to provide a given level of performance, not exceed a given power budget, not exceed a given cost, in a speci ed footprint, and never exceed a given temperature we expect that many quite different design points will meet such criteria, but here we present the validation of our approach. future work will use the approach to answer such questions in the design of next generation systems. designing and optimizing high performance microprocessors is an increasingly difficult task due to the size and complexity of the processor design space, high cost of detailed simulation and several constraints that a processor design must satisfy. in this paper, we propose the use of empirical non linear modeling techniques to assist processor architects in making design decisions and resolving complex trade offs. we propose a procedure for building accurate non linear models that consists of the following steps: selection of a small set of representative design points spread across processor design space using latin hypercube sampling, obtaining performance measures at the selected design points using detailed simulation, building non linear models for performance using the function approximation capabilities of radial basis function networks, and validating the models using an independently and randomly generated set of design points. we evaluate our model building procedure by constructing non linear performance models for programs from the spec cpu benchmark suite with a microarchitectural design space that consists of key parameters. our results show that the models, built using a relatively small number of simulations, achieve high prediction accuracy across a large processor design space. our models can potentially replace detailed simulation for common tasks such as the analysis of key microarchitectural trends or searches for optimal processor design points. the modelalso provides insights into the workings of superscalarprocessors and long term microarchitecture trends such aspipeline depths and issue widths. we propose regression modeling as an efficient approach for accurately predicting performance and power for various applications executing on any microprocessor configuration in a large microarchitectural design space. this paper addresses fundamental challenges in microarchitectural simulation cost by reducing the number of required simulations and using simulated results more effectively via statistical modeling and inference specifically, we derive and validate regression models for performance and power. such models enable computationally efficient statistical inference, requiring the simulation of only in million points of a joint microarchitecture application design space while achieving median error rates as low as percent for performance and percent for power. although both models achieve similar accuracy, the sources of accuracy are strikingly different. we present optimizations for a baseline regression model to obtain application specific models to maximize accuracy in performance prediction and regional power models leveraging only the most relevant samples from the microarchitectural design space to maximize accuracy in power prediction. assessing sensitivity to the number of samples simulated for model formulation, we find fewer than, samples from a design space of approximately billion points are sufficient. collectively, our results suggest significant potential in accurate and efficient statistical inference for microarchitectural design space exploration via regression models. ef cient design space exploration is constrained by the signi cant computational costs of cycle accurate simulators. these simulators permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies bear this notice and the full citation on the rst page. to copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speci. provide detailed insight into application performance for a wide range of microprocessor con gurations, exposing performance and power trends in the microarchitectural design space. long simulation times require designers to constrain design studies and consider only small subsets of the full design space. however, such constraints may lead to conclusions that may not generalize to the larger space. addressing these fundamental challenges in microarchitectural simulation methodology becomes increasingly urgent as chip multiprocessors introduce additional design parameters and exponentially increase design space size. we apply regression modeling to derive simulation free statistical inference models, requiring a small number of sampled design points in a joint microarchitecture application design space for initial simulation. such an approach modestly reduces detail in return for signi cant gains in speed and tractability. although we consider advantages in computational cost for microarchitectural design space exploration in this paper, these models may also provide increased pro ling ef ciency and fast performance prediction for system software and algorithms, such as thread scheduling for heterogeneous multi processors. techniques in statistical inference and machine learning are increasingly popular for approximating solutions to intractable problems. even for applications in which obtaining extensive measurement data is feasible, ef cient analysis of this data often lends itself to statistical modeling. these approaches typically require an initial set of data for model formulation or training. the model responds to predictive queries by leveraging trends and correlations in the original data set to perform statistical inference. regression modeling follows this predictive paradigm in a relatively cost effective manner. knowledge is used to specify predictors of a response, formulating the model from observed data requires numerically solving a system of linear equations and predicting the response simply requires evaluating a linear equation. model formulation and evaluation are computationally ef cient due to well optimized numerical linear algebra libraries. we use a modest number of simulations to obtain sample observations from a large design space. in section #, we describe a sampling methodology to obtain, samples drawn uniformly at random from a design space with approximately billion points. each sample maps a set of architectural and application speci. these samples are used to formulate regression models that predict the performance and power of previously unsampled con gurations based on the same predictors. in section #, we summarize a statistically rigorous approach for deriving regression models that includes variable clustering, association testing, assessing strength of response predictor relationships, and signi cance testing withtests. these techniques ensure statistically signi cant architectural and applicationspeci. given a baseline model that accounts for predictor interaction and non linearity, section # presents model optimizations to improve prediction accuracy by stabilizing residual variance, deriving application speci. models, and deriving regional models with samples most similar in architectural con guration to the predictive query. the following summarizes experimental results of section # from four different performance and power regression models formulated with, samples drawn from a joint microarchitectureapplication design space with nearly billion microarchitectural con gurations and benchmarks: performance prediction: application speci. models predict performance with median error as low as percent. to percent of predictions achieve error rates of less than percent depending on the application. we propose and apply a new simulation paradigm for microarchitectural design evaluation and optimization. this paradigm enables more comprehensive design studies by combining spatial sampling and statistical inference. specifically, this paradigm defines a large, comprehensive design space, samples points from the space for simulation, and constructs regression models based on sparse simulations. this approach greatly improves the computational efficiency of microarchitectural simulation and enables new capabilities in design space exploration. we illustrate new capabilities in three case studies for a large design space of approximately, points: pareto frontier, pipeline depth, and multiprocessor heterogeneity analyses. in particular, regression models are exhaustively evaluated to identify pareto optimal designs that maximize performance for given power budgets. these models enable pipeline depth studies in which all parameters vary simultaneously with depth, thereby more effectively revealing interactions with nondepth parameters. heterogeneity analysis combines regression based optimization with clustering heuristics to identify efficient design compromises between similar optimal architectures. these compromises are potential core designs in a heterogeneous multicore architecture. increasing heterogeneity can improve bips efficiency by as much as, a theoretical upper bound on heterogeneity benefits that neglects contention between shared resources as well as design complexity. collectively these studies demonstrate regression models ability to expose trends and identify optima in diverse design regions, motivating the application of such models in statistical inference for more effective use of modern simulator infrastructure. microarchitectural design space exploration is a computationally expensive combinatorial problem, requiring a large number of detailed simulations for performance and power estimation. furthermore, recent industry trends suggest a number of new challenges as designers consider the multiprocessor domain. designers are increasingly targeting differentiated market segments each with particular metric emphases. for example, designs might implement different compromises between latency, throughput, power, and temperature depending on application and operating cost factors speci. thus, increasing market differentiation implies increasing metric diversity, which further implies more interesting optimization objectives and constraints. increasing metric diversity will also lead to nonintuitive design optima that potentially occupy very different regions of the design space. design diversity has already been observed in the set of interesting microarchitectures considered for industry implementation. for example, the ibm power, intel pentium and sun ultrasparc occupy very different parts of the design space. power implements relatively wide pipelines, pentium implements relatively deep pipelines, and ultrasparc cores are relatively simple in order pipelines. metric and design diversity illustrate the need for scalable techniques to more comprehensively explore a space and assess the relative advantages of very different design options. current approaches to design evaluation are often inef cient and ad hoc due to the signi cant computational costs of modern simulator infrastructure. the detail in modeling microprocessor execution result in long simulation times. designers circumvent these challenges by constraining the design space considered and reducing the size of simulator inputs via instruction trace sampling. however, by pruning the design space with intuition before a study, the designer risks obtaining conclusions that simply reinforce prior intuition and may not generalize to the broader space. instruction trace sampling, while effective in reducing the simulator input size by orders of magnitude, only impacts per simulation costs and does not address the number of simulations required in a comprehensive design space study. trace sampling alone is insuf cient as per simulations costs decrease linearly, albeit by a large factor, while the number of potential simulation points increase exponentially with the number of design parameters. this exponential increase is currently driven by the design of multicore, multithreaded microprocessors targeting diverse metrics including single thread latency, throughput for emerging parallel workloads, and energy. these trends will also lead to more variety in the set of viable and interesting designs, thereby requiring a more thorough exploration of a comprehensive design space. techniques in statistical inference are necessary for a scalable simulation approach that addresses these fundamental challenges, modestly reducing detail for substantial gains in speed and tractability. even for applications acm transactions on architecture and code optimization, vol. in which obtaining extensive measurement data is feasible, ef cient analysis of this data often lends itself to statistical modeling. such an approach typically requires an initial data set for model formulation or training. the model responds to predictive queries by leveraging correlations in the original data for inference. regression modeling is integrated into a simulation paradigm designed to increase the information content for a given simulation cost. this paradigm speci es a large, comprehensive design space, selectively simulates a modest number of designs sampled from that space, and more ef ciently leverages that simulation data using regression models to identify trends and optima. design space sampling and statistical inference enables the designer to perform a tractable number of simulations independent of design space size or resolution. applying this simulation paradigm, we sample, points uniformly at random from a design space of, points for simulation. given these samples, we formulate nonlinear regression models for microarchitectural performance and power prediction, achieving median error rates of and, respectively, relative to simulation. we apply the derived models to comprehensively explore a design space for three optimization problems pareto frontier analysis. we comprehensively characterize the design space, constructing a regression predicted pareto frontier in power delay coordinates. we nd predictions for pareto optima exhibit median errors comparable to those for the broader space. we compare a constrained pipeline depth study against an enhanced study that varies all parameters simultaneously via regression modeling. we nd constrained sensitivity studies may not generalize when many other design parameters are held at constant values. furthermore, such generalized studies more effectively reveal interactions between design parameters. we identify ef ciency maximizing architectures for each benchmark via regression modeling and cluster these architectures to identify design compromises. we quantify the powerperformance bene ts from varying degrees of core heterogeneity, quantifying a theoretical upper bound on bips ef ciency gains. we nd modest heterogeneity may provide substantial ef ciency bene ts relative to homogeneity. for each case study, we provide an assessment of predictive error and sensitivity of observed trends to such error. collectively these studies demonstrate the applicability of regression models for performance and power prediction in practical design space optimization. uniprocessor simulators track resource utilization cycle by cycle to estimate performance. multiprocessor simulators, however, must account for synchronization events that increase the cost of every cycle simulated and shared resource contention that increases the total number of cycles simulated. these effects cause multiprocessor simulation times to scale superlinearly with the number of cores. composable performance regression fundamentally addresses these intractable multiprocessor simulation times, estimating multiprocessor performance with a combination of uniprocessor, contention, and penalty models. the uniprocessor model predicts baseline performance of each core while the contention models predict interfering accesses from other cores. uniprocessor and contention model outputs are composed by a penalty model to produce the final multiprocessor performance estimate. trained with a production quality simulator, cpr is accurate with median errors of, percent for dual, quad core multiprocessors. furthermore, composable regression is scalable, requiring the simulations required by prior regression strategies. modern simulator infrastructure is ill suited to handle current technology trends and the transition to multiprocessors. cycle accurate multiprocessor simulation inherently lacks scalability; simulation times increase superlinearly with the number of simulated cores and simulators are not easily parallelized. most challenges in microarchitectural simulation arise from the need for a high degree of synchronization. detailed uniprocessor simulation proceeds cycle by cycle, tracking resource utilization to produce a detailed estimate of performance at the cost of long simulation times. just as multiprocessors are built from multiple instantiations of uniprocessor cores, multiprocessor simulators often run multiple instantiations of a uniprocessor simulator. however, multiprocessor simulators must also account for inter processor this work was done while. lee interned at intel and studied at harvard. synchronization that increase the cost of every cycle simulated and shared resource contention that increases the total number of cycles simulated. collectively, these effects cause multiprocessor simulation times to scale superlinearly with the number of cores. recent advances in applying statistical inference to the microarchitectural domain have enabled qualitatively new capabilities in uniprocessor analysis, uniprocessor inferential models leverage best known practices in statistical inference for highly ef cient simulation and analysis. trained by simulating points sparsely sampled from the design space, these models are computationally ef cient surrogates for cycle accurate simulation, which capture mappings between design parameters and design metrics. however, these same techniques are unlikely to scale as we consider multiprocessor performance models. while a few hundred training simulations are tractable xed costs for uniprocessor modeling, they are prohibitively expensive for multiprocessor modeling due to superlinear increases in simulation time. thus, multiprocessor regression models derived from multiprocessor simulations alone are impractical. exacerbating these greater multiprocessor simulation times, multiprogrammed workloads produce combinatorial growth in the number of possible workload combinations. the number of such combinations will increase rapidly with the number of cores. taking the benchmarks in this paper for example, we are confronted with dual core and quad core workload combinations. furthermore, for industrial microprocessor design, benchmarks are only a small representative set from a much more comprehensive study list with over benchmarks. for benchmarks, we could potentially analyze dual core and quad core workload combinations. thus, in addition to ensuring scalability as the number of cores increases, an effective multiprocessor modeling framework must also ensure the marginal cost of model training for each combination of workloads is computationally tractable. to address these fundamental challenges in multiprocessor simulation times, we propose composable performance regression. cpr extends prior successes in uniprocessor statistical inference to the multiprocessor domain while ensuring training costs remain tractable. the framework controls training costs by abstracting the uniprocessor, taking the core as the primary determinant of multiprocessor performance and considering shared resource contention as a secondary penalizing effect. within this framework, uniprocessor models are the primary building blocks supported by secondary contention and penalty models. such a framework is highly ef cient, building on the information captured by relatively inexpensive uniprocessor models while requiring a far fewer number of multiprocessor simulations to train contention and penalty models to predict multiprocessor performance. we de ne scalability as the rate of increase in training costs when the number of modeled cores increases. composable models are trained and evaluated separately but composed to estimate. cpr uses composable models to deliver scalability for multiprocessor performance estimates. the following summarizes the key contributions of this work: industrial infrastructure: we demonstrate regression models effectiveness for the intel core microarchitectural family, using industry strength simulators actively employed in product development. we construct these models for a broad array of workloads ranging from multimedia to server applications. uniprocessor model: we rst derive uniprocessor regression models, demonstrating the accuracy of these basic building blocks before applying them in the multiprocessor model. furthermore, we demonstrate the application of these models to evolutionary design optimization, re tuning design parameters after fundamentally new microarchitectural features are added between consecutive product generations. multiprocessor model: we propose composable performance regression that includes uniprocessor, contention, and penalty models. the uniprocessor model predicts the baseline performance of each core while the contention models predict interfering accesses to shared resources from other cores. uniprocessor and contention model outputs are composed in a penalty model that produces the nal multiprocessor performance prediction. case for scalable multiprocessor models: in addition to being individually accurate, the uniprocessor, contention and penalty models combine to predict dualcore and quad core performance with median errors of and percent, respectively. composable regression is a scalable, ef cient approach for constructing these multiprocessor models. training costs for proposed composable regression are those for naively constructed models as the number of multiprocessor cores increases. collectively, this work establishes a rigorous foundation for ef ciently extending advances in statistical machine learning for uniprocessor design into the multiprocessor domain. the task of learning to rank has emerged as an active and growing area of research both in information retrieval and machine learning. the goal is to design and apply methods to automatically learn a function from training data, such that the function can sort objects according to their degrees of relevance, preference, or importance as defined in a specific application. the model is constructed from the first principles of out of order processor execution in order to provide novel insight into the interaction of the workload with the microarchitecture to determine avf. we show that the model estimates the avf for the reorder buffer, issue queue, load and store queue, and functional units in a wide issue machine with a mean absolute error of less than. soft error reliability has become a first order design criterion for modern microprocessors. architectural vulnerability factor modeling is often used to capture the probability that a radiation induced fault in a hardware structure will manifest as an error at the program output. avf estimation requires detailed microarchitectural simulations which are time consuming and typically present aggregate metrics. moreover, it requires a large number of simulations to derive insight into the impact of microarchitectural events on avf. in this work we present a first order mechanistic analytical model for computing avf by estimating the occupancy of correct path state in important microarchitecture structures through inexpensive profiling. we demonstrate that the model can be used to perform design space explorations to understand trade offs between soft error rate and performance, to study the impact of scaling of microarchitectural structures on avf and performance, and to characterize workloads for avf. the current trace driven simulation approach to determine superscalar processor performance is widely used but has some shortcomings. modern benchmarks generate extremely long traces, resulting in problems with data storage, as well as very long simulation runtimes. more fundamentally, simulation generally does not provide significant insight into the factors that determine performance or a characterization of their interactions. this paper proposes a theoretical model of superscalar processor performance that addresses these shortcomings. performance is viewed as an interaction of program parallelism and machine parallelism. both program and machine parallelisms are decomposed into multiple component functions. methods for measuring or computing these functions are described. the functions are combined to provide a model of the interaction between program and machine parallelisms and an accurate estimate of the performance. the computed performance, based on this model, is compared to simulated performance for six benchmarks from the spec suite on several configurations of the ibm rs instruction set architecture. abstract: statistical simulation is a technique for fast performance evaluation of superscalar processors. first, intrinsic statistical information is collected from a single detailed simulation of a program. this information is then used to generate a synthetic instruction trace that is fed to a simple processor model, along with cache and branch prediction statistics. because of the probabilistic nature of the simulation, it quickly converges to a performance rate. the simplicity and simulation speed make it useful for fast design space exploration; as such, it is a good complement to conventional detailed simulation. the accuracy of this technique is evaluated for different levels of modeling complexity. both errors and convergence properties are studied in detail. a simple instruction model yields an average error of compared with detailed simulation. a more detailed instruction model reduces the error to but requires about three times as long to converge. modern architecture research relies heavily on detailed pipeline simulation. simulating the full execution of a single industry standard benchmark at this level of detail takes on the order of months to complete. this problem is exacerbated by the fact that to properly perform an architectural evaluation requires multiple benchmarks to be evaluated across many separate runs. to address this issue we recently created a tool called simpoint that automatically finds a small set of simulation points to represent the complete execution of a program for efficient and accurate simulation. in this paper we describe how to use the simpoint tool, and introduce an improved simpoint algorithm designed to significantly reduce the simulation time required when the simulation environment relies upon fast forwarding. many real world data mining tasks require the achievement of two distinct goals when applied to unseen data: first, to induce an accurate preference ranking, and second to give good regression performance. in this paper, we give an efficient and effective combined regression and ranking method that optimizes regression and ranking objectives simultaneously. we demonstrate the effectiveness of crr for both families of metrics on a range of large scale tasks, including click prediction for online advertisements. results show that crr often achieves performance equivalent to the best of both ranking only and regression only approaches. in the case of rare events or skewed distributions, we also find that this combination can actually improve regression performance due to the addition of informative ranking constraints. understanding program behavior is at the foundation of computer architecture and program optimization. many programs have wildly different behavior on even the very largest of scales. this realization has ramifications for many architectural and compiler techniques, from thread scheduling, to feedback directed optimizations, to the way programs are simulated. however, in order to take advantage of time varying behavior, we must first develop the analytical tools necessary to automatically and efficiently analyze program behavior over large sections of execution our goal is to develop automatic techniques that are capable of finding and exploiting the large scale behavior of programs. the first step towards this goal is the development of a hardware independent metric that can concisely summarize the behavior of an arbitrary section of execution in a program. to this end we examine the use of basic block vectors. we quantify the effectiveness of basic block vectors in capturing program behavior across several different architectural metrics, explore the large scale behavior of several programs, and develop a set of algorithms based on clustering capable of analyzing this behavior. we then demonstrate an application of this technology to automatically determine where to simulate for a program to help guide computer architecture research. programs can have wildly different behavior over their run time, and these behaviors can be seen even on the largest of scales. understanding these large scale program behaviors can unlock many new optimizations. these range from new thread scheduling algorithms that make use of information on when a thread behavior changes, to feedback directed op timizations targeted at not only the aggregate performance of the code but individual phases of execution, to creating simulations that accurately model full program behavior. to enable these optimizations, we must first develop the analyt ical tools necessary to automatically and efficiently analyze permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. to copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and or a fee. in order to perform such an analysis we need to develop a hardware independent metric that can concisely summarize the behavior of an arbitrary section of execution in a pro gram. in, we presented the use of basic block vectors, which uses the structure of the program that is ex ercised during execution to determine where to simulate. a bbv represents the code blocks executed during a given in terval of execution. our goal was to find a single continuous window of executed instructions that match the whole pro gram execution, so that this smaller window of execution can be used for simulation instead of executing the program to completion. using the bbvs provided us with a hardware independent way of finding this small representative window. in this paper we examine the use of bbvs for analyzing large scale program behavior. we use bbvs to explore the large scale behavior of several programs and discover the ways in which common patterns, and code, repeat themselves over the course of execution. we quantify the effectiveness of basic block vectors in capturing this program behavior across several different architectural metrics. in addition to this, there is a need for a way of classifying these repeating patterns so that this information can be used for optimization. we show that this problem of classifying sections of execution is related to the problem of cluster ing from machine learning, and we develop an algorithm to quickly and effectively find these sections based on clustering. our techniques automatically break the full execution of the program up into several sets, where the elements of each set are very similar. once this classification is completed, anal ysis and optimization can be performed on a per set basis. we demonstrate an application of this cluster based be havior analysis to simulation methodology for computer ar chitecture research. by making use of clustering information we are able to accurately capture the behavior of a whole program by taking simulation results from representatives of each cluster and weighing them appropriately. this results in finding a set of simulation points that when combined ac curately represents the target application and input, which in turn allows the behavior of even very complicated pro grams such as gcc to be captured with a small amount of simulation time. we provide simulation points for alpha binaries of all of the spec year# programs. in addition, we validate these simula tion points with the ipc, branch, and cache miss rates found for complete execution of the spec year# programs. the rest of the paper is laid out as follows. first, a sum mary of the methodology used in this research is described in section #. section # presents a brief review of basic block vectors and an in depth look into the proposed techniques and algorithms for identifying large scale program behaviors, and an analysis of their use on several programs. section # describes how clustering can be used to analyze program be havior, and describes the clustering methods used in detail. section # examines the use of the techniques presented in sections and on an example problem: finding where to simulate in a program to achieve results representative of full program behavior. related work is discussed in section #, and the techniques presented are summarized in section #. in recent years, the increasing number of processor cores and limited increases in main memory bandwidth have led to the problem of the bandwidth wall, where memory bandwidth is becoming a performance bottleneck. this is especially true for emerging latency insensitive, bandwidth sensitive applications. designing the memory hierarchy for a platform with an emphasis on maximizing bandwidth within a fixed power budget becomes one of the key challenges. to facilitate architects to quickly explore the design space of memory hierarchies, we propose an analytical performance model called moguls. the moguls model estimates the performance of an application on a system, using the bandwidth demand of the application for a range of cache capacities and the bandwidth provided by the system with those capacities. we show how to extend this model with appropriate approximations to optimize a cache hierarchy under a power constraint. the results show how many levels of cache should be designed, and what the capacity, bandwidth, and technology of each level should be. in addition, we study memory hierarchy design with hybrid memory technologies, which shows the benefits of using multiple technologies for future computing systems. recently, the importance of applications that are bandwidth sensi tive and latency insensitive has increased signi cantly. at the same time, the growth rate of the computation abilities of a processor has continued to outstrip the growth rate of main memory bandwidth. a key subset of bandwidth sensitive and latency insensitive ap plications is known as throughput computing applications. through put computing refers to trading off single thread performance for higher overall computational throughput. throughput computing applications span many domains and are already critical on a va riety of platforms, including high performance computing machines, commercial servers, and client machines. memory bandwidth is critical to many throughput computing applications because of two main reasons: throughput computing applications inherently have generous amounts of parallelism that processors can take advantage of via multi threading and single instruction multiple data execution; thus, hardware can consume data at high rates. systems designed to perform well on throughput computing applications achieve high performance by exploiting their inherent parallelism. these systems support large numbers of threads and or use wide simd execution, which puts a lot of pressure on the memory system. in throughput computing, memory latency is typically not a bottleneck since the latency can be hidden via multithreading or hardware prefetching. many throughput computing applications have inherently large working sets, which are unlikely to. in conventional on die sram caches for the foreseeable future. further, unlike more traditional workloads, some throughput computing applications show a sharp drop in performance once caches are too small to hold their working sets we refer to this as a performance cliff. thus, these applications are likely to be bandwidth bound at main memory unless some signi cant changes are made to the memory hierarchy. even in the general purpose computing community, memory bandwidth was predicted to become a performance bottleneck, for example, due to reduced bandwidth ef ciency from overly aggressive hardware prefetching. throughput computing can be conducted on either cpu based or gpu based systems. cpus historically have used multi level cache hierarchies to reduce average latency and reduce bandwidth demands on larger capacity levels. gpus have so far relied on shallow hierarchies they hide latency with multithreading and use much higher bandwidth in main memory than cpus. the common wisdom is that the gpu approach is bet ter for throughput computing applications. while this may be true, gpus are designed primarily for graphics. consequently, neither gpus nor cpus have a memory hierarchy designed speci cally for throughput computing with an emphasis on bandwidth improve ment. there are a few simple techniques to improve bandwidth ef ciency of a system, but they are insuf cient for the large band width requirements of some throughput computing applications. we also cannot rely on ever increasing main memory bandwidth to meet the needs of throughput computing. for example, todaysystems that tout good performance for throughput computing ap plications do so by providing large main mem ory bandwidth via the use of gddr rather than improving band width ef ciency. however, gddr has fairly strict capacity limits and is much more power hungry than conventional dram mod ules, which reduces its desirability for throughput computing, and makes it an unfavorable choice for general purpose systems try ing to improve their throughput computing performance. further more, technology trends indicate that growth in bandwidth demand outpaces growth in bandwidth supply for all dram based mem ory. consequently, it is necessary to study the memory hierarchy design for throughput computing platforms with an emphasis on bandwidth improvement. architects would like to optimize the mem ory hierarchy design with bandwidth improvements as the rst pri ority design goal and try to nd out the number of levels in the optimal cache hierarchy, the capacity and bandwidth of each level, and the appropriate memory technology of each level. to help computer architects quickly explore the design space for memory hierarchies to improve bandwidth, this paper makes the following contributions. the model is based on the bandwidth demand of an application and the bandwidth provided by the memory hierarchy design. the bandwidth demand provided is de ned at all memory capacities, and is described as a capacity bandwidth curve. the cb curve can facilitate a quick estimation of whether the bandwidth provided by the memory hierarchy can satisfy the bandwidth demand, and guide design improvements. the usefulness and the effectiveness of the model is demonstrated by exploring the memory hierarchy design for multi programmed workloads running on a high throughput processor. first order approximations are proposed to help us quantitatively determine: the most energy ef cient capacity and bandwidth of the levels in the cache hierarchy, the optimal number of cache levels, potential performance bene ts of multiple levels of memory assuming. that is, given a power budget, our model and theories suggest the best memory hierarchy. we also explore how to choose the optimal levels, capacity, and bandwidth when multiple memory technologies are provided. in order to validate our theories, we nd the optimal memory hierarchy design with exhaus tive simulations for real cases. we show that our theories match experimental results. an analytical model calledmogulsisproposedtoquickly estimate the performance for applications on speci. the splash suite of parallel applications has recently been released to facilitate the study of centralized and distributed shared address space multiprocessors. the properties we study include the computational load balance, communication to computation ratio and traffic needs, important working set sizes, and issues related to spatial locality, as well as how these properties scale with problem size and the number of processors. for example, by characterizing the working sets of the applications, we describe which operating points in terms of cache size and problem size are representative of realistic situations, which are not, and which re redundant. using splash as an example, we hope to convey the importance of understanding the interplay of problem size, number of processors, and working sets in designing experiments and interpreting their results. in this context, this paper has two goals. one is to quantitatively characterize the splash programs in terms of fundamental properties and architectural interactions that are important to understand them well. the other, related goal is methodological: to assist people who will use the programs in architectural evaluations to prune the space of application and machine parameters in an informed and meaningful way. current software based microarchitecture simulators are many orders of magnitude slower than the hardware they simulate. hence, most microarchitecture design studies draw their conclusions from drastically truncated benchmark simulations that are often inaccurate and misleading. this paper presents the sampling microarchitecture simulation framework as an approach to enable fast and accurate performance measurements of full length benchmarks. smarts accelerates simulation by selectively measuring in detail only an appropriate benchmark subset. smarts prescribes a statistically sound procedure for configuring a systematic sampling simulation run to achieve a desired quantifiable confidence in estimates analysis of of the possible specbenchmark input combinations show cpi and energy per instruction can be estimated to within with confidence by measuring fewer than million instructions per benchmark. in practice, inaccuracy in microarchitectural state initialization introduces an additional uncertainty which we empirically bound to for the tested benchmarks. our implementation of smarts achieves an actual average error of only on cpi and on epi for the tested benchmarks, running with average speedups of and over detailed simulation of way and way out of order processors, respectively. computer architects have long relied on software simulation to study the functionality and performance of proposed hardware designs. despite phenomenal improvement in processor performance over the last decades, the disproportionate growth in hardware complexity that needs to be modeled has steadily eroded simulation speed. today, the fastest cycle accurate modern microprocessor performance simulators are more than five orders of magnitude slower than the hardware they model simulating at a detailed simulators and register transfer level simulators are easily six or more orders of magnitude slower than the proposed hardware. one minute of execution in real time can correspond to days, if not weeks, of simulation time. current approaches to mitigate prohibitively slow simulation speeds, researchers often use abbreviated instruction execution streams of benchmarks as representative workloads in design studies. more than half of the recent papers in toptier computer architecture conferences presented performance claims extrapolated from abbreviated runs researchers predominantly skip the initial million to two billion instructions and then measure a single section of million to one billion instructions. unfortunately, several studies have concluded that results based only on a single abbreviated execution stream are inaccurate or misleading because they fail to capture global variations in program behavior and performance. another common approach to curtail simulation time is to use fewer or smaller input sets. recent papers, however, have also shown benchmark behavior varies significantly across test, train and reference inputs for a number of specbenchmarks. to obtain performance results based on complete benchmarks and input sets, many proposals have advocated statistical or profile driven simulation sampling. simulation sampling measures only chosen sections from a benchmarkfull execution stream. the sections in between sampling units are fast forwarded using functional simulation that only maintains programmer visible architectural state. we faced two key challenges to simulation sampling: choosing an appropriate subset with the minimum number of instructions to meet a given error bound, and reconstructing an. this past year, papers presented at isca, micro, and hpca include simulation results; used a single sampling unit, used nominal rate of mips on a ghz pentium. more reduced input sets or microbenchmarks, and used other approaches. accurate microarchitectural state for unbiased sample measurement following an extended period of functional fast forwarding. current proposals for simulation sampling suffer from several key shortcomings. on the efficiency front, most proposals sample several orders of magnitude more instructions than are statistically necessary for their stated error. this inefficiency is often rooted in their excessively large sampling units, either to amortize the overhead of reconstructing microarchitectural state or to capture coarse grain performance variations by brute force. on the accuracy front, most proposals either do not offer tight error bounds on their performance estimations, or require unrealistic assumptions about the microarchitecture. the smarts approach we propose the sampling microarchitecture simulation framework which applies statistical sampling theory to address the aforementioned issues in simulation sampling. unlike prior approaches to simulation sampling, smarts prescribes an exact and constructive procedure for selecting a minimal subset from a benchmarkinstruction execution stream to achieve a desired confidence interval. smarts uses a measure of variability to determine the optimal sample that captures a programinherent variation. an optimal sample generally consists of a large number of small sampling units. unbiased measurement of sampling units as small as year# instructions is possible by applying careful functional warming maintaining large microarchitectural state, such as branch predictors and the cache hierarchy during fast forwarding between sampling units. we evaluate smarts in the context of a wide issue out of order superscalar simulator called smartsim which is based on simplescalar. we employed smartsim to estimate the cpi and energy per instruction for out of specbenchmark input combinations on two microarchitecture configurations. we make the following primary contributions: optimal sampling: smartsim achieves an actual average error of only on cpi and on epi by simulating fewer than million instructions in detail for each of the specbenchmarks. this represents an exceedingly small fraction of the complete benchmark streams, which range between and billion instructions. simulation speedup: on a ghz pentium, smartsim can achieve average speedups of and relative to sim outorder for way and way super scalar processor models, respectively. at current processor speeds, these speedups enable simulation speeds of over mips. future impact: smarts sampling simulation rate is, for all practical purposes, decoupled from the speed of the detailed simulator. this result has fundamental bearings on future simulator designs. first, designers should focus less on elaborate performance shortcuts in detailed simulators, and more on increasing the detailed simulatoroverall design flexibility and accuracy. second, designers should focus on developing techniques which speed up fast forwarding and functional warming, as these ultimately determine sampling simulation rate. the rest of this paper is organized as follows. section # presents an implementation of smarts in the context of a microarchitecture simulation infrastructure. section # evaluates the effectiveness of the smarts framework at accelerating microarchitecture simulation.