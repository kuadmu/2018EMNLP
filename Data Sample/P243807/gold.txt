with the proliferation of multimedia contents on the web, research on multimedia information retrieval and questionanswering are beginning to emerge. the early work that addresses the issues of qa in video in a system named videoqa is reported in. this system extends the textbased qa technology to support factoid qa in news video by leveraging on visual contents of news video as well as the text transcripts generated from asr. users interact with the system using short natural language questions with implicit constraints on contents, duration, and genre of expected videos. in the preprocessing stage, it performs video story segmentation and classification, as well as video transcript generation and correction. during the question answering stage, it employs modules for: question processing, query reinforcement, transcript retrieval, answer extraction and video summarization. following this work, several video qa systems were proposed with most of them relying on the use of text transcripts derived from video ocr and asr outputs. developed a lexical pattern matching based ranking method for domaindependent video qa. designed a cross language video qa system based on retrieving and extracting pre defined named entity entries in text captions. the system enables users to query with english questions to retrieve the chinese captioned videos. the system was subsequently extended to support bilingual video qa that permits users to retrieve chinese videos through english or chinese natural language questions. presented a robust passage retrieval algorithm to extend the conventional text based qa to video qa. as discussed earlier, shot retrieval as proposed in trecvid can also be regarded as a kind or base technology for factoid video qa. for example, if the user issues a query who is barack obama, the shot retrieval system would aim to return a video that visually depict the query subject. in this sense, the body of work done on shot retrieval as part of trecvid efforts can be considered as research towards factoid multimedia qa. the first step in shot retrieval is to extract relevant semantic information for the shot. this includes asr text, as well as possible presence of high level concepts, such as the face, car, building etc. given a query, most shot retrieval systems follow similar retrieval pipeline of: query analysis, shot retrieval, shot ranking and answer selection. query analysis performs query expansion and inference of relevant high level concepts by considering the correlation between query text and concepts. given the expanded query, a combination of text and high level concept matching is performed to retrieve relevant list of shots. a multi modal approach is then employed to re rank the shots for presentation to the users. few works have been done on image based qa except the one presented in that describes a photo based qa system to find information about physical objects. the first layer performs template matching of query photo to online images to extract structured data from multimedia databases in order to help answer questions about the photo; it uses question text to filter images based on categories and keywords. the second layer performs searches on internal repository of resolved photo based questions to retrieve relevant answers. in the third human computation qa layer, it leverages community experts to handle the most difficult cases. overall, it can be seen that work on factoid multimedia qa has just been started, whereas little work has been done on the more challenging and practical tasks of definition and how to qa.