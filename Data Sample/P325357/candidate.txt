recent research in deterministic record replay seeks to ease debugging, security, and fault tolerance on otherwise nondeterministic multicore systems. the important challenge of handling shared memory races can be made more efficient with hardware support. recent proposals record how long threads run in isolation on top of snooping coherence, implicit transactions, or directory coherence. as core counts scale, rerun directory based parallel record gets more attractive, but its nearly sequential replay becomes unacceptably slow. this paper proposes karma for both scalable recording and replay. karma builds an episodic memory race recorder using a conventional directory cache coherence protocol and records the order of the episodes as a directed acyclic graph. karma also enables extension of episodes even after some conflicts. during replay, karma uses wakeup messages to trigger a partially ordered parallel episode replay. results with several commercial workloads on a core system show that karma can achieve replay speed within of native execution speed without record replay and four times faster than even an idealized rerun replay. additional results explore tradeoffs between log size and replay speed. the lack of repeatability makes it more difficult to do debugging, security analysis, and fault tolerance. moreover, dealing with multiprocessor nondeterminism heretofore limited to a few experts is now a concern of many programmers, as multicore chips become the norm in systems ranging from servers to clients to phones and the number of cores scales from a few to several to sometimes many. permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. to copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and or a fee. to this end, researchers have explored software and hardware approaches for a two phase deterministic record replay system. in the first phase, these systems record selective execution events into a log to enable the second phase to deterministically replay the recorded execution. a great challenge for record replay is handling shared memory races that can potentially occur on any memory reference, while other events, such as context switches and io can easily be handled by software. early hardware proposals for handling memory races record when threads do interact, but require substantial hardware state to make log sizes smaller. three recent hardware race recorders reduce this state by instead recording when threads dont interact: rerun, delorean and intel memory race recorder. let an episode be a series of dynamic instructions from a single thread that executes without conflicting with any other thread. all three recorders use bloom filters to track coherence events to determine when to end episodes. these recorders assume different coherence protocols that affect their scalability to many core chips and complexity of implementation: imrr assumes broadcast snooping cache coherence and proposes globally synchronized chunk termination among the cores for better replay speed. imrr reliance on broadcast and globally synchronized operation limits its scalability. delorean relies on bulksc bulk non traditional broadcast of signatures to commit abort implicit transactions and a centralized arbiter to record and replay chunk order. thus delorean demands a completely new coherence protocol and support for implicit transactions to make its scheme for deterministic record replay feasible. rerun operates with relatively minor changes to more conventional point to point directory protocol that allows scalable recording while demanding minimal hardware extension. thus, going forward, rerun approach seems most promising as it is scalable to chips with many cores and to systems with multiple sockets, while requires moderate changes to conventional hardware. during replay, however, rerun does not scale, because its replay is nearly sequential due to its use of lamport scalar clocks. fast, parallel replay can expand the applicability of deterministic record replay systems, which in turn, can further justify deploying them. fast replay is valuable for scenarios that include: in security analysis, fast replay can help quick analysis of an attack and allow urgent fix to critical security flaws. a quick replay, even when the attack is underway, can help to trace the attacker. in fault tolerance, where one might wish to maintain availability of a critical primary server in presence of faults, a secondary server following the primary, needs to quickly work done while at uw madison. for classic use of debugging, deterministic record replay utility will decline if scaling to, or more cores, requires a sequential replay that is at least, or more slower. replaying for small intervals of time may be acceptable, but the situation quickly worsens if replay for longer intervals and or large number of cores are needed. we believe that the need for scalable and fast deterministic record replay assumes further importance with respect to supercomputing where hundreds of cores nodes interact during computation. this paper proposes karma for both scalable recording and replay, that minimally extends conventional directory coherence protocol. karma proposed novel episodic memory race recorderreplayer records the order of episodes as a directed acyclic graph. karma also extends lengths of episodes that conflict during recording by ensuring that they do not conflict during replay. during karma replay, special wakeup messages trigger parallel replay of independent episodes. we also show how to extend karma from sequential consistency to total store order, sufficient to implement the memory model. we evaluate karma on a core system and find that: karma can achieve replay speed within of native execution with no record replay and about times faster than even idealized rerun replay. karma log size is similar to rerun, but can be made smaller for uses that can tolerate slower replay. a multiprocessor memory consistency model imposes ordering constraints among loads, stores, atomic operations, and memory fences. even for consistency models that relax ordering among loads and stores, ordering constraints still induce significant performance penalties due to atomic operations and memory ordering fences. several prior proposals reduce the performance penalty of strongly ordered models using post retirement speculation, but these designs either maintain speculative state at a per store granularity, causing storage requirements to grow proportionally to speculation depth, or employ distributed global commit arbitration using unconventional chunk based invalidation mechanisms. in this paper we propose invisifence, an approach for implementing memory ordering based on post retirement speculation that avoids these concerns. invisifence leverages minimalistic mechanisms for post retirement speculation proposed in other contexts to track speculative state efficiently at block granularity with dedicated storage requirements independent of speculation depth, provide fast commit by avoiding explicit commit arbitration, and operate under a conventional invalidation based cache coherence protocol. invisifence supports both modes of operation found in prior work: speculating only when necessary to minimize the risk of rollback inducing violations or speculating continuously to decouple consistency enforcement from the processor core. overall, invisifence requires approximately one kilobyte of additional state to transform a conventional multiprocessor into one that provides performance transparent memory ordering, fences, and atomic operations. stalls due to memory ordering constraints in shared memory multiprocessors can result in signi cant performance penalties. such stalls arise not just because of ordering requirements among loads and stores but also from atomic operations and explicit memory ordering fences, which occur frequently in highly tuned multithreaded applications due to these applications usage of ne grained locking and lock free synchronization. thus, even relaxed consistency models can incur signi cant performance penalties due to memory ordering. to reduce this performance penalty, current processors employ in window speculative memory reordering and post retirement store buffers. however, performance penalties remain because of limited capacity of fifo store buffers and or latency of atomic operations and fences. as figure shows, memory ordering constraints block instruction commit for a signi cant fraction of time not only for sequential consistency but also for consistency models that relax only store to load ordering and even for models with fully relaxed ordering. whereas conventional processors enforce ordering constraints conservatively, the vast majority of these ordering stalls are dynamically unnecessary. hence, researchers have proposed using post retirement speculation, that is, speculation beyond the instruction window, to eliminate the performancegap between strong consistencymodels and relaxed consistencymodels. one class of proposals directly extends the instruction window with ne grained buffers for speculatively retired instructions, detecting consistency violations by snooping incoming cache coherence requests. this approach has been shown to match or exceed the performance of a conventional rmo implementation. however, tracking speculative state at a per instruction or per store granularity requires post retirement buffers that must grow proportionally to the duration of speculation. furthermore, these proposals either have rollback or commit cost that is proportional to the duration of speculation. the high store miss latency of current systems can be fully tolerated only by deep speculation, leading to high storage requirements and rollback commit costs. a second class of proposals takes a more radical approach by enforcing consistency at coarse granularity on chunks of instructions rather than individual memory operations, thus amortizing the cost of maintaining speculative state and acquiring store permissions. this approach has also been shown to achieve high performance. however, these proposals require unconventional extensions to the memory system, such as ef cient support apache zeus oltp oracle oltp db dss db barnes ocean figure #. ordering stalls in conventional implementations of sc, tso, and rmo as a percent of execution time. the sb drain segments represent stall cycles due to store buffer drains triggered by atomic operations and fences or any memory operation. the sb full segmentsrepresent stall cycles due to limited storebuffer capacity. for global commit arbitration, update based cache coherence protocols, and or support forbulk operations on read set and write set signatures, potentially hindering widespread adoption. to enable performance transparent memory ordering in conventional multiprocessors, this work builds upon techniques for deep speculation pioneered in other contexts to create invisifence, a new design that uses post retirement speculation to implement any consistency model ef ciently. invisifence employs a standard cache coherence protocol, cache hierarchy, and coalescing store buffer sized to hold only outstanding misses. during speculative execution, invisifence buffers data for speculative stores in the coalescing store buffer until the miss completes and in the data cache afterwards, using the second level of cache to preserve non speculative state. invisifence detects ordering violations by snooping external cache coherence requests via per block speculatively read written bits in the data cache. to abort speculation, invisifence ash invalidates speculatively written blocks and restores checkpointed register state. to commit speculation, invisifence simply ash clears the speculatively read written bits. by default, invisifence initiates speculation only when the processor would otherwise stall retirement due to consistency constraints. this selective speculation minimizes time spent speculating and consequently vulnerability to rollback inducing violations. moreover, nvisifence opportunistically commits speculation in constant time whenever the ordering requirements for all in ight memory operations have been satis ed. this instantaneous opportunistic commit obviates prior proposals need to tolerate long latency commit operations, allowing invisifence to obtain high performance with hardware support for only a single in ight speculation. alternatively, nvisifence can employ the continuous speculation espoused by prior work on chunk based designs. instead of initiating speculation only upon a potential ordering stall, continuous speculation executes all memory operations speculatively, allowing it to subsume in window mechanisms for enforcing memory consistency at the cost of a second checkpoint to pipeline chunk commit with subsequent execution. continuous speculation increases vulnerability to ordering violations, causing a straight forward implementation to suffer substantial performance degradation relative to selective speculation to mitigate this penalty, we propose an alternative policyfor resolving potential ordering violations: commit on violate. cov avoids unnecessary rollbacks by deferring for a bounded timeout interval those requests that would otherwise cause a violation. this timeout interval provides an opportunity to commit the speculation instead of immediately aborting. invisifence is the rst approach for implementing memory consistencythat allows deep post retirement speculation in the context of a standard cache coherence protocol while avoiding negrained post retirement store buffering. our performance results show that the selective and continuous variants of invisifence outperform a conventional rmo implementation. in its highestperforming con guration, invisifence adds only an eight entry coalescing storebuffer, a register checkpoint, and two bits per primary data cache block approximately kb of additional state to a conventional multiprocessor. debugging parallel program is a well known difficult problem. a promising method to facilitate debugging parallel program is using hardware support to achieve deterministic replay. a hardware assisted deterministic replay scheme should have a small log size, as well as low design cost, to be feasible for adopting by industrial processors. to achieve the goals, we propose a novel and succinct hardware assisted deterministic replay scheme named lreplay. the key innovation of lreplay is that instead of recording the logical time orders between instructions or instruction blocks as previous investigations, lreplay is built upon recording the pending period information. according to the experimental results on godson, the overall log size of lreplay is about k inst for sequential consistency, and k inst for godson consistency. the log size is smaller in an order of magnitude than state of art deterministic replay schemes incuring no performance loss. furthermore, lreplay only consumes about area of godson, since it requires only trivial modifications to the existing components of godson. the above features of lreplay demonstrate the potential of integrating hardware assisted deterministic replay into future industrial processors. motivation nowadays, multi core processor has become the mainstream of general purpose processor. to fully exploit the computational ability of mcp, parallel programming is one of the reasonable solutions. however, debugging parallel program is a wellknown dif cult problem. for example, the non determinism of parallel programming may introduce some heisen bugs of which exhibit an erroneous behavior under certain conditions but disappear when in probing or attempting to isolate it. a promising method to tackle the above non determinism is called the deterministic replay. such a scheme continuously records the non deterministic factors in the original execution of a parallel program as logs, and utilizes the logs to force another execution exhibiting the same logical behavior as the production run. during the last two decades, deterministic replay has been employed not only debugging parallel programs but also many other applications, such as fault tolerance, performance prediction, and intrusion detection. due to the broad applications, deterministic replay has received intensive investigations in the architecture society. in general, deterministic replay schemes mainly focus on dealing with the uncertainty of memory races, ie, the execution order between a pair of successive con icting memory instructions accessing the same memory location. in production run, they dynamically identify and record the logical time order between instructions, which is the transitive closure of program and execution orders; in replay run, they use the execution orders inferred from the recorded logical time orders to constrain the execution of parallel program. according to the current methodology of implementing deterministic replay, there are mainly two categories of schemes: the software only schemes and the hardwareassisted schemes. to deal with execution order, the software only schemes purely rely on the supports of speci. system software environments, such as operating system, virtual machine, and library. however, these schemes impose many restrictions on system software. therefore, they have to suffer remarkable performance losses. furthermore, although software only schemes can guarantee the replay run to behave the same as to the production run, given the same speci. software environment, they cannot guarantee that a bug happened in a normal software environment is reproducible in the speci. such reproducibility problem may limit the usage of software only schemes. unlike software only schemes, which impose many restrictions on system software, the hardware assisted deterministic replay sche mes pursue dedicated hardware support to ef ciently record and replay, and do not require speci. hence, hardware assisted te scheme have made signi cant academic contributions. nevertheless, implementing them may still encounter some practicality problems, such as large log size, design complexity, and relatively high area impacts. a potential way to overcome these dif culties is to design a hardware assisted deterministic replay scheme complying the following typical industrial guidelines of design for debug: dfd functionality should affect the performance in production run as little as possible; dfd functionality should be decoupled from the normal functionality of design to avoid introducing extra design cost; the area consumption figure #: example of recovering execution order from physical time order. among these of dfd should be low; the log size of dfd should be small enough to. the rest of the paper will execution orders, only focus on designing such a hardware assisted scheme that can potentially be integrated as a dfd feature. hence, to replay all the execution or by taking the guidelines of dfd into account, we propose a ders illustrated in figure #, one needs to only record the end time novel hardware assisted deterministic replay scheme named lre of the instructions in the upper block, the start time of the instrucplay to bridge the gap between the academia and industry. the key tions in the lower block, and the only non inferable execution order innovation of lreplay is that it considers the existence of a global clock, records the pending period information in productionrun, and cost effectively stores them. most execution orders can be inferred from the recorded pending period information, only the non inferable execution orders are directly recorded by lreplay. to be speci, the pending period of an instruction is a time interval on the global clock in which the instruction starts and nishes. meanwhile, in multiprocessor systems providing store atomicity, the perform time of an instruction, which is the time when a memory instruction is observed by all processors, must be in its pending period. hence, two instructions with disjoint pending periods can be naturally ordered by the sequence of their perform times. chen et al called the above order the physical time order. it can be proved that the execution orders cannot violate the physical time orders, implying that many execution orders can be inferred from the physical time orders. intuitively, consider a load instructiongetting its value stored by a store instruction. to record pending period, lreplay periodically samples the memory instruction counter of each processor, and records an approximate increment between the values of the memory instruction counter in two successive samplings. with such a lossy compression technique, the pending period log of lreplay costs only bit per sample period. for the non inferable execution orders, lreplay identi es them by comparing the address of each memory instruction missing in dcache with the addresses of the most recent store instructions. to be speci, if the former address hits one of the latter addresses, the corresponding execution order is identi ed to be non inferable, and then recorded in the non inferable execution order log. furthermore, to support relaxed memory consistency models such as processor consistency and godson consistency, lreplay can record the load instructions violating sequential consistency in the memory consistency log, which is a log dedicated to record the additional information for relaxed memory consistency models. can be inferred by the existing physical time order. an example of inferring execution orders from the physical time orders is illustrated in figure #. all the instructions in the upper block nish before the time, and all the instructions in the lower block start after the time. according to the de nition of physical time order, any instruction in the upper block must precede any instruction in the lower block in physical time order. consequently, among the execution orders represented by the arrows in figure #, most of them are inferable to evaluate lreplay empirically, we implemented it on the rtl design of a commercial multi core processor godson. the implementation of lreplay on godson requires only adding few registers for observing the state of the core, while keeping most components of the multi core processor such as cache, memory controller, cache coherence protocol and network on chip unmodi ed. such trivial modi cation incurs no performance penalties. the experimental results on godson show that lreplay needs only about byte per kilo instruction to record the pending period information in ppl. only the residual non most modern multi core processors support store atomicity. in inferable execution orders, those between this paper we only consider store atomic multiprocessor systems. instructions without physical time order, are directly recorded in marks, the resultant physical time order of ppl can infer more from physical time orders, except the execution order nel with k inst. moreover, the log size of nel can be further reduced if adopting transitive reduction technique as regulated transitive reduction. on the other hand, to support relaxed memory consistency models such as godson consistency, lreplay requires additional k inst to record mcl. in summary, the overall log size of lreplay is only k inst for sequential consistency, and k inst for godson consistency; with the fact that a small log can be dynamically transferred to outside with jtag, which compiles to common technique of debug io in the industry. to our best knowledge, this is the rst time that a hardware assisted deterministic replay scheme is implemented and evaluated on a system with a relaxed memory consistency model. the main contributions of lreplay can be summarized as the following. first, it is the rst time that a pending period based deterministic replay scheme is proposed. the pending period, which is a novel and fundamental concept proposed for multiprocessor systems with global clock, is easy to record in multi core processors. moreover, it can be employed to infer most execution orders. secondly, to our best knowledge, lreplay has the smallest log size among all deterministic replay schemes incuring no performance loss in production run. thirdly, lreplay is an open scheme which can be incorporated with other logical time order based schemes to further reduce the cost on recording non inferable execution orders. last but not least, lreplay meets most industrial dfd requirements. the above notable feature, together with the promising performance of lreplay in the context of the relaxed memory consistency models, shows the potential of integrating hardware assisted deterministic replay into future industrial processors. rest of the paper introduces the theoretical basis of lreplay, including pending period, physical time order; presents the implementation details of lreplay; empirically evaluates lreplay via analyzing the corresponding experimental results; brie. reviews some related work; discusses some issues about lreplay; and concludes the paper. finally, practical implementation issues are discussed, concentrating on issues relevant to scalable architectures. scalable shared memory multiprocessors distribute memory among the processors and use scalable interconnection networks to provide high bandwidth and low latency communication. in addition, memory accesses are cached, buffered, and pipelined to bridge the gap between the slow shared memory and the fast processors. unless carefully controlled, such architectural optimizations can cause memory accesses to be executed in an order different from what the programmer expects. the set of allowable memory access orderings forms the memory consistency model or event ordering model for an architecture. this paper introduces a new model of memory consistency, called release consistency, that allows for more buffering and pipelining than previously proposed models. a framework for classifying shared accesses and reasoning about event ordering is developed. the release consistency model is shown to be equivalent to the sequential consistency model for parallel programs with sufficient synchronization. possible performance gains from the less strict constraints of the release consistency model are explored. architectures for deterministic record replay of multithreaded code are attractive for program debugging, intrusion analysis, and fault tolerance uses. however, very few of the proposed designs have focused on maximizing replay speed a key enabling property of these systems. the few efforts that focus on replay speed require intrusive hardware or software modifications, or target whole systemr rather than the more useful application level. this paper presents the first hardware based scheme for unintrusive, application levelr that explicitly targets high replay speed. our scheme, called cyrus, requires no modification to commodity snoopy cache coherence. it introduces the concept of an on the fly software backend pass during recording which, as the log is being generated, transforms it for high replay parallelism. this pass also fixes up the log, and can flexibly trade off replay parallelism for log size. we analyze the performance of cyrus using full system simulation. our results show that cyrus has negligible recording overhead. in addition, for processor runs of splash, cyrus attains an average replay parallelism of, and a replay speed that is, on average, only about lower than the recording speed. deterministic record replay seeks to monitor the execution of a program and exactly reproduce it on a subsequent execution. r has broad uses in at least program debugging, where, for example, a concurrency bug can be reproduced, intrusion analysis, where an intrusion can be traced back to an attackeractions, and fault tolerant, highlyavailable systems, where a backup machine can resume where the primary failed. this paper focuses onr for multithreaded applications on multiprocessor machines. in such a scenario, r typically involves recording all the non deterministic events that occurred during the initial executionie, application inputs and memory access interleavings. then, during replay, logged inputs are provided to the application at the correct times, and the memory accesses are forced to interleave in the same manner as in the log. there are several proposals of schemes forr of multithreaded programs. on the one hand, there are those that do not require any special hardware, typically relying on the os, compiler and or run time libraries for recording and replaying. being software only solutions, these systems are relatively inexpensive to implement but tend to run slowly during recording. other schemes record with the aid of some special hardware module. these systems add negligible overhead during recording, but can be expensive to implement. in addition, some schemesr the whole machineexecution, while there are others that onlyr a single or a group of applications running on the machine. typically, it is the latter that the users actually need rather than the former. in addition, recreating the whole machine state during replay is often very hard and, to work correctly, needs to deal with many non portable operating system and hardware issues of the platform. application level, in contrast, tends to be more portable and adds less overhead. traditionally, hardware basedr schemes have attempted to minimize log size requirements. software based schemes, instead, have focused on minimizing the overhead of recording in some cases, even at the cost of potentially having to replay multiple times. very few schemes have focused on maximizing replay speed most notably delorean capo, double play, and karma. all three use parallel replay mechanisms for this purpose. each of the three previous systems has shortcomings that could limit its practicality. speci cally, delorean capo uses transactional record and replay hardware, which requires a redesign of current commodity processor hardware. as indicated above, this is not what users typically need and, in addition, it is hardly portable. in addition, karma requires augmenting the cache coherence protocol messages which we want to avoid. finally, doubleplay is a software based scheme, which requires modifying and recompiling the application, marking its synchronizations. this is unfortunate, given that fast replay is a key enabling property forr systems. for example, debugging can be more productive if buggy executions can be quickly replayed to the point of the bug. analysis of how the attack is taking place. finally, in fault tolerance, a backup machine has to quickly catch up with a failed one to provide hot replacement. to attain effective low overhead, we believe that, in addition to providing fast parallel replay, the system needs to: support application level, and rely on unintrusive hardware design. in particular, it should avoid system level hardware changes such as any changes to the cache coherence protocol. we believe this is fundamental for acceptance ofr hardware. since most multiprocessors today use snoopy cache coherence, we require our design to be compatible with snoopy protocols. in this paper, we make the following contributions: we present the rst hardware based approach for unintrusive, application levelr that explicitly targets high speed replay. the approach, called cyrus, requires no modi cation to commodity snoopy cache coherence. cyrus introduces the concept of an on the. software backend pass during recording which, as the log is being generated, consumes it and transforms it. this pass xes up the log, which has incomplete information due to our recording requirements of only application level interactions and no cache coherence protocol changes. in addition, the backend pass exposes a high degree of parallelism for replay. finally, as the backend pass produces the nal log, it can also exibly trade off replay parallelism for log size. we modi ed the linux kernel to control and virtualize a simulated version of the cyrus hardware. our results show that cyrus adds negligible recording overhead, even with the backend pass. in addition, for processor runs of splash, cyrus attains an average replay parallelism of, and a replay speed that is, on average, only about lower than the recording speed. the rest of the paper is organized as follows: section # discusses background issues and challenges inr; section # presents cyrus architecture; section # describes implementation issues; sections and evaluate cyrus; section # discusses related work; and section # concludes the paper. record and deterministic replay of multithreaded programs on relaxed consistency multiprocessors has been a long standing problem. while there are designs that work for total store ordering, finding a general solution that is able to record the access reordering allowed by any relaxed consistency model has proved challenging. this paper presents the first complete solution for hard ware assisted memory race recording that works for any relaxed consistency model of current processors. with the scheme, called relaxreplay, we can build an rnr system for any relaxed consistency model and coherence protocol. relaxreplay core innovation is a new way of capturing memory access reordering. each memory instruction goes through a post completion in order counting step that detects any reordering, and efficiently records it. we evaluate relaxreplay with simulations of an core release consistent multicore running splash programs. we observe that relaxreplay induces negligible overhead during recording. in addition, the average size of the log produced is comparable to the log sizes reported for existing solutions, and still very small compared to the memory bandwidth of modern machines. finally, deterministic replay is efficient and needs minimal hardware support. record and deterministic replay of multithreaded programs in multiprocessors is a concept that involves log permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies bear this notice and the full citation on the rst page. copyrights for components of this work owned by others than acm must be honored. to copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speci. asplos, march, year#, salt lake city, utah, usa. http: dx doi org year# ging enough of a parallel execution to be able to replay it later deterministically. rnr has broad uses in parallel program debugging, security analysis, and fault tolerant, highly available systems. rnr for a program typically requires logging two sources of nondeterminism during execution, namely, external inputs to the program and the interleaving of shared memory accesses from different processors. the latter consists of capturing the relative order of con icting memory accesses. while input recording is done by the operating system, mrr typically requires special hardware. this is because inserting software instrumentation for mrr results in signi cant execution slow down or increases the number of processors required. in addition, all these schemes distort the timing of execution, which can be a drawback in concurrency debugging. finally, they require modifying the binary of the program to be recorded. for these reasons, there are several proposals for hardwareassisted mrr. these schemes typically identify con icting accesses by leveraging cache coherence protocol transactions. most recent proposals record a processorexecution as a series of chunks of instructions executed between coherence actions with other processors. this approach results in low recording overhead and small logs. the majority of current proposals for hardware assisted mrr require that the recorded execution obeys sequential consistency. under sc, memory access instructions execute in program order, which substantially simpli es what events need to be logged and when. unfortunately, commercial machines almost universally use more relaxed memory consistency models, allowing loads and stores to reorder. there have been a few proposals for mrr under non sc models. all but one of them require the total store ordering memory model, which only allows loads to bypass stores. such proposals either log which stores are bypassed, or log the values read by the bypassing loads, or use off line analysis to identify the actual order that occurred. the other proposal, called rainbow, focuses on detecting sc violations as they happen, and recording enough information to replay them. however, this scheme requires a coherence protocol that is centralized and that needs substantial hardware changes. moreover, the operation of the schememajor components is not clearly described in the paper. all these schemes are discussed in detail in section #. overall, the long standing problem of nding a general mrr solution that works for any relaxed consistency model is still open. this paper contributes with the rst complete solution for hardware assisted mrr that works for any relaxedconsistency model of current processors. with the scheme, called relaxreplay, we can build an rnr system that works for any relaxed consistency model and any cache coherence protocol. relaxreplaykey innovation is a new approach to capture memory access reordering. speci cally, each memory instruction goes through a post completion in order counting step that detects any reordering, and ef ciently records it in the log. we present two designs, called relaxreplay base and relaxreplay opt, with different emphases on hardware requirements, log size, and replay speed. several salient characteristics of the relaxreplay mechanism to capture memory access reordering are: it only relies on the write atomicity property of coherence protocols, and not on knowing the detailed speci cations of the particular relaxed consistency model. such speci cations are often high level and hard to map to implementation issues. chunk ordering algorithm of any existing chunk based mrr proposal. as a result, that proposal, designed for a certain coherence protocol, can now record relaxed consistency executions. its hardware is local to the processors and requires no change to the cache coherence protocol. it produces a compact log representation of a relaxedconsistency execution. the resulting log enables ef cient deterministic replay with minimal hardware support. we evaluate relaxreplay with simulations of an core release consistent multicore running splash applications. the results show that relaxreplay induces negligible overhead during recording. in addition, the average size of the log produced is the log sizes reported by existing sc or tso based mrr systems. hence, the bandwidth required to save this log is still a small fraction of the bandwidth provided by current machines. finally, deterministic replay using this log is ef cient: the sequential replay of these processor executions with minimal hardware support takes on average as long as the parallel recording. this paper is organized as follows: section # provides a background; sections and presents relaxreplaydesign and implementation, respectively; section # evaluates relaxreplay and section # discusses related work. multiprocessor deterministic replay has many potential uses in the era of multicore computing, including enhanced debugging, fault tolerance, and intrusion detection. while sources of nondeterminism in a uniprocessor can be recorded efficiently in software, it seems likely that hardware support will be needed in a multiprocessor environment where the outcome of memory races must also be recorded we develop a memory race recording mechanism, called rerun, that uses small hardware state, writes a small race log, and operates well as the number of cores per system scales. rerun exploits the dual of conventional wisdom in race recording: rather than record information about individual memory accesses that conflict, we record how long a thread executes without conflicting with other threads. each episode is a dynamic instruction sequence that a thread happens to execute without interacting with other threads. rerun uses lamport clocks to order episodes and enable replay of an equivalent execution. a system exhibiting deterministic replay capability can record suf cient information during an execution to enable a replayer to create an equivalent execution despite inherent sources of nondeterminism that exist in modern computer systems. the information required includes initial state and nondeterministic events. recording a uniprocessor execution is viable in software, because the sources of nondeterminism, such as io, dma lls, and interrupts, are relatively rare events. deterministic replay of a uniprocessor machine has already proven useful for debugging and intrusion detection applications. most future systems, however, will use multicore chips that provide software with a shared memory model. this model adds memory races con icting accesses to both synchronization and data variables as an additional source of nondeterminism to be recorded. unfortunately, memory races have the potential to occur on almost every memory reference, making ef cient analysis dif cult for software. fortunately, recent work has proposed hardware support for multithreaded deterministic replay, in general, and, memory race recording, in particular. these systems log the outcome of memory races as they occur. to keep the storage and bandwidth needs reasonable, these systems only record a subset of all races that cannot be implied transitively, ie, races that are not implied through the combination of a previously recorded dependence and program order semantics. the flight data recorder, both original and enhanced, however, uses substantial hardware state to perform this reduction. hardware vendors would like to see this state reduced, in part, because it is cost paid even when recording is disabled. strata reduces this state, performs well for four core systems, but, suffers a substantial increase in per core log sizes as the number of cores per system grows. we advance the state of the art by proposing a new memory race recorder, called rerun, that achieves scalable race log sizes on par with prior work at only a fraction of the hardware state. while races are typically described in terms of con icts that occur between individual memory accesses, rerun records the dual of this information: how long a thread executes without con icting with any other thread in the system. rerun uses atomic episodes as the fundamental unit of ordering. an episode is a series of dynamic instructions from a single thread that happen to execute without con icting with any other thread in the system. episodes are created passively by observing system behavior without altering the normal execution ow. when recording is enabled, the entire system execution figure #: example of episodic recording. dotted lines indicate episode boundaries created during execution. in the blown up diagram of threadsand, the shaded boxes show the state of the episode as it ends, including the read and write sets, memory reference counter, and the timestamp. the darker shaded box in the last episode of threadshows what the episode state is initialized to when an episode begins. is viewed as a collection of ordered episodes so that every dynamic instruction logically resides within the boundaries of an episode. rerun records the outcome of an execution by simply logging the length and order of episodes. a causal ordering among episodes from different threads is established using lamport scalar clocks, which is a standard mechanism from distributed systems used to create a global notion of logical time in systems where no single point of ordering exists. using this mechanism, rerun associates each episode with a timestamp that correctly places the episode in a partial order of execution and preserves inter thread dependencies. we implement rerun by augmenting cores in the system with a small amount of state and by piggybacking on an existing coherence protocol. the coherence protocol allows rerun to ensure that no two concurrently active episodes con ict with one another and provides a substrate for keeping logical time consistent. with respect to prior memory race recorders, we show that rerun is simultaneously comparable to the recorder with the smallest hardware state and the recorder with the slowest log growth rate. the rest of the paper is organized as follows. section # presents the key ideas for rerun. section # discusses our implementation in a base system and then elaborates on how rerun can be extended to alternate architectures. in section # we explain our evaluation methods and in section # we present empirical results. we discuss related work and conclude in sections and, respectively. support for deterministic replay of multithreaded execution can greatly help in finding concurrency bugs. for highest effectiveness, replay schemes should record at production run speed, keep their logging requirements minute, and replay at a speed similar to that of the initial execution. in this paper, we propose a new substrate for deterministic replay that provides substantial advances along these axes. in our proposal, processors execute blocks of instructions atomically, as in transactional memory or speculative multithreading, and the system only needs to record the commit order of these blocks. our results show that delorean records execution at a speed similar to that of release consistency execution and replays at about of its speed. in contrast, most current schemes only record at the speed of sequential consistency execution. moreover, delorean only needs of the log size needed by a state of the art scheme. finally, delorean can be configured to need only of the log size of the state of the art scheme at the cost of recording at of rcexecution speed still faster than sc. in this configuration, the log of an processor ghz machine is estimated to be only about gb per day. past work has focused on detecting data races as proxies for sequential consistency violations. however, most data races do not violate sc. in addition, lock free data structures and synchronization libraries sometimes explicitly employ data races but rely on sc semantics for correctness. consequently, to uncover sc violations, we need to develop a more precise technique. this paper presents vulcan, the first hardware scheme to precisely detect sc violations at runtime, in programs running on a relaxed consistency machine. the scheme leverages cache coherence protocol transactions to dynamically detect cycles in memory access orders across threads. when one such cycle is about to occur, an exception is triggered. for the conditions considered in this paper and with enough hardware, vulcan suffers neither false positives nor false negatives. in addition, vulcan induces negligible execution overhead, requires no help from the software, and only takes as input the program executable. experimental results show that vulcan detects three new sc violation bugs in the pthread and crypt libraries, and in the fmm code from splash. moreover, vulcan negligible execution overhead makes it suitable for on the fly use. the model that programmers have in mind when they program and debug shared memory threads is sequential consistency. sc requires the memory operations of a program to appear to execute in some global sequence as if the threads where multiplexed on a uniprocessor. in practice, however, current hardware overlaps, pipelines, and reorders the memory accesses of threads. as a result, a programexecution can be unintuitive. processor pa allocates a variable and then sets. ag; later, pb tests the ag and, if set, it uses the variable. while the particular interleaving in figure # produces expected results, the interleaving in figure # does not. in this unlucky interleaving, pb ends up using an unallocated variable. from the hardware point of view, several conditions must be met for an scv to occur. first, we need to have at least two data racesie, races on variables buff and init in the example. secondly, these races must be of a very special type: they must be overlapping in time and intertwined in a manner that can form a cycle. for two threads, it requires a pattern like that in figure # where, if we follow program order, the two threads reference the same two this work was supported in part by the national science foundation under grants cns, ccf year# and cns year#, and by intel under the illinois intel parallelism center. abdullah muzahid is now with the university of texas at san antonio. variables in opposite orders, and each variable is written at least once. finally, the order of the references in these two racing pairs has to form a cycle at runtime. this is shown in figure #, where we have arbitrarily picked reads and writes: a must occur before and must occur before a. this is exactly what happened in figure #, wherewas init andwas buff. note, however, that if the timing at runtime is such that at least one of the two dependence arrows occurs in the opposite direction, there is no scv. this case corresponds to the timing in figure #. data race patterns that cause scvs are sometimes found in double checked locking constructs, some synchronization libraries, and code for lock free data structures. detecting scvs is important because, in practically all cases, they are harmful, clear cut bugs. the reason is that, as the example in figure # shows, they require memory access orders that contradict a programmerintuition. in addition, the programmer cannot reproduce them using a single stepping debugger. past work has attempted to nd scvs by focusing on detecting data races. however, as we just saw, using data races as proxies for scvs is very imprecise. in large commercial codes, conventional race detection tools typically ag many data races, often causing the programmer to spend time examining races that are much less likely to cause code malfunctioning than scvs. a second reason for not using data races as proxies is that we may want to nd scvs in codes that have intentional data races, such as in lock free data structures. we may want to debug the code for scvs, while being less concerned about non sc violating races. here, a race detection tool would not be a good instrument to use. if we want to detect scvs, we need to precisely zero in on the types of data races and interleavings that cause them. given the importance of these bugs and the dif culty in isolating them, this paper contributes with vulcan, the rst hardware scheme to precisely detect scvs at runtime, in programs running on a relaxed consistency machine. when a cycle is about to occur, an exception is triggered, providing information to debug the scv. the vulcan design in this paper focuses on nding cycles of overlapping races between only two processors since cycles involving three and more processors are much rarer. in addition, it does not consider speculative loads from mispredicted branch paths. vulcanapproach has several advantages: it induces negligible execution overhead, requires no help from the software, and only takes as input the program executable. experimental results show that vulcan detects three new bugs in popular codes. we have reported the bugs to the developers. in addition, vulcannegligible execution overhead makes it suitable for on the. this paper is organized as follows: section # gives a background; section # introduces a taxonomy of data races; sections and present vulcan; section # outlines its limitations; section # evaluates vulcan; and section # discusses related work. in here, the hardware reorders the completion of the stores in the two statements in pa. ppa pb aa: buff malloc a: buff malloc a: init true a: init true: if: if: buffb: buff figure #. pp pp ab ab a: wrb: rda: ref: ref a: wrb: rd a: ref: ref p aa: wrb: rd dependence edge a: wrb: rdprogram order edge figure #. for example, figure # shows the case when a executed before but a executed before. since there is no cycle, sc is not violated. race pattern and interleaving required for an scv is not necessarily common. vulcan leverages cache coherence protocol transactions to dynamically detect cycles in memory access orders across threads. moreover, it is not concerned with scvs due to compiler transformations vulcan only reports scvs due to hardware initiated reference reordering. within these constraints, and with large enough hardware structures, vulcan suffers neither false positives nor false negatives. speci cally, it nds scvs in the pthread and crypt libraries, and in the fmm program from splash. we also contribute with a new taxonomy of data races. significant time is spent by companies trying to reproduce and fix bugs. bugnet and fdr are recent architecture proposals that provide architecture support for deterministic replay debugging. they focus on continuously recording information about the program execution, which can be communicated back to the developer. using that information, the developer can deterministically replay the program execution to reproduce and fix the bugs in this paper, we propose using strata to efficiently capture the shared memory dependencies. a stratum creates a time layer across all the logs for the running threads, which separates all the memory operations executed before and after the stratum. a strata log allows us to determine all the shared memory dependencies during replay and thereby supports deterministic replay debugging for multi threaded programs. hardware techniques have been proposed to continuously record the programexecution with very little overhead to assist developers by supporting deterministic replay debugging. deterministic replay debugging enables a programmer to replay the exact same sequence of instructions that led up to the crash, and therefore it is an effective technique to understand the source of the bug. the hardware techniques can support deterministic replay of the last second of execution preceding the crash, which was found to be suf cient to debug the root cause of the bug. since the overhead of these hardware techniques are low enough, they are transparent and hence they can always be left on during production runs. one of those techniques is called the flight data recorder. fdr creates checkpoints based on safeynet to support full system deterministic replay. bugnet logs the load values executed by the application and supports deterministic replay of the application code and permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies bear this notice and the full citation on the rst page. to copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speci. shared libraries, as opposed to the full system replay supported by fdr. for debugging multi threaded programs, the techniques described above need an ef cient mechanism to record the shared memory dependencies between the threads. to accomplish this, fdr logs the shared memory dependencies in a memory race log, which is maintained for each processor node. fdr determines the shared memory dependencies for a thread by monitoring its coherence messages. in order to reduce the size of the memory race logs, fdr implemented the netzer optimization in hardware. bugnet assumed the same method for recording the shared memory dependencies in its memory race logs. we refer to the logging method used by fdr and bugnet as the point to point logging approach, because to capture a dependency, they log the instruction counts of both the dependent operations. in this paper, we propose capturing the shared memory dependencies using strata. a stratum is logged when a shared memory dependency needs to be captured. it consists of the memory counts of all the threads at the time when it is logged. a stratum separates all the memory operations that were executed in all the threads before the time when it is recorded, from those that will be executed after it is recorded. since the stratum is recorded just before the execution of the dependent memory operation, the stratum separates that memory operation from the earlier memory operation in which it is dependent on. sequential consistency is the most intuitive memory model, and sc violations produce unintuitive, typically incorrect executions. most prior scv detection schemes have used data races as proxies for scvs, which is highly imprecise. other schemes that have targeted data race cycles are either too conservative or are designed only for two processor cycles and snoopy based systems. this paper presents volition, the first hardware scheme that detects scvs in a relaxed consistency machine precisely, in a scalable manner, and for an arbitrary number of processors in the cycle. when a cycle is about to occur, an exception is triggered. our simulations of volition in a processor multicore with directory based coherence running splash and parsec programs shows that volition induces negligible traffic and execution overhead. in addition, it can detect scvs with several processors. volition is suitable for on the fly use. volition leverages cache coherence protocol transactions to dynamically detect cycles in memory access orders across threads. volition can be used in both directory and snoopy based coherence protocols. when programmers write and debug applications with sharedmemory threads, they intuitively assume the sequential consistency model. while the interleaving in figure # produces the expected results, the interleaving in figure # does not. here, while the two writes in a and a are retired in order, they complete out of order: the rst one after and, and the second one before and. in this interleaving, ends up using an unitialized. while this example is trivial, scvs often appear under subtle thread interleavings and timing conditions, even in popular codes. scvs are often found in double permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies bear this notice and the full citation on the rst page. to copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speci. checked locking constructs, some synchronization libraries, and code for lock free data structures. in section #, we show a typical example of scv. from the hardware perspective, an scv occurs only when multiple conditions are met. first, there needs to be two or more data races eg, the races on variablesand ok in figure #. finally, the order of the references in these races has to form a cycle at runtime. speci cally, for two threads, an scv requires a pattern like that in figure # where, if we follow program order, the two threads reference the same two variables in opposite orders, and each variable is written at least once. moreover, the references in these two racing pairs have to form a cycle as shown in figure # where we have arbitrarily picked reads and writes. speci cally, a must occur before, and must occur before a. this what happens in figure #, whereis ok andis. however, if the timing at runtime is such that at least one of the two dependence arrows occurs in the opposite direction, there is no scv. for example, figure # shows the case when a executes before, but a executes before. this case corresponds to the timing in figure #. it is important to detect scvs because, in virtually all cases, scvs are programming mistakes as shown in figure #, they are the result of memory access orders that contradict a programmerintuition. in addition, given their subtlety, they can potentially cause great harm to the program without being obvious to the programmer. finally, the programmer cannot reproduce them using a single stepping debugger, and has to largely rely on mental analyses of interleavings to uncover them. most prior work has attempted to nd scvs by focusing on detecting data races. however, using data races as proxies for scvs is very imprecise. race pattern and interleaving required for an scv is not necessarily common. in large codes, race detection tools typically ag a very large number of data races, often causing the programmer to spend time examining races that are much less likely to cause code malfunctioning than scvs. a second reason for not using data races as proxies is that we may want to uncover scvs in codes that have intentional data races perhaps in lock free data structures. we may want to debug such codes for scvs, while being less concerned about non scviolating races. here, a race detection tool would not be a good instrument to use. if we want to detect scvs, we need to precisely zero in on the data races and interleavings that cause them. given the importance of these bugs and the dif culty in isolating them, there have been two recent proposals for hardware supported detection of data race cycles. the rst one, by lin et al, focuses on detecting overlapping data races, even if they involve disjoint sets of processors. hence, the approach is fairly conservative, resulting in false positives. however, false positives are not a problem because the goal of that approach is to avoid scvs rather than to detect them and report them to the programmer. however, it is only designed to work for two processor cycles and relies on a broadcast based cache coherence protocol in the machine. we compare our work to these two approaches in section #. in this paper, we advance the state of the art by proposing the rst hardware scheme that detects scvs in a relaxed consistency machine precisely, in a scalable manner, and for an arbitrary number of processors in the cycle. volition can be used in both directory and snoopy based coherence protocols; it does not rely on any property of snoopy protocols such as the broadcast ability. the current volition design does not consider speculative loads from mispredicted branch paths. within these constraints, and with large enough hardware structures, volition suffers neither false positives nor false negatives for a given execution. overall, volitionpreciseness, scalability and low overhead make it suitable for on the. this paper is organized as follows: section # gives a background; section # shows the basic volition mechanisms; section # extends volition to work with multiple word cache lines; sections and discuss implementation and other issues; section # evaluates volition; and section # discusses related work. sc requires that the memory operations of a program appear to execute in some global sequence, as if the threads where multiplexed on a uniprocessor. in practice, however, processors and memory systems overlap, pipeline, and reorder the memory accesses of threads. as a result, the execution of a parallel program can violate sc. processor initializes variableand then sets ag ok; later, tests ok and, if it is set, uses. for example, muzahid et al discovered scvs in the pthread and crypt libraries of glibc. a: value a: value a: ok true a: ok true: if: if:b: figure #. dependence edge program order edge a: wx: ry a: wx: ry a: ref: ref a: ref: ref a: wy: rx a: wy: rx figure #. since there is no cycle, sc is not violated. the second appoach, by muzahid et al detects cycles that cause scvs, precisely. volition leverages cache coherence protocol transactions to dynamically detect cycles in memory access orders across threads. when a cycle is about to occur, an exception is triggered, providing information to debug the scv. in addition, it is unconcerned with scvs due to compiler transformations; it only reports scvs due to hardware initiated access reordering. in our experiments, we simulate volition in a core multicore with a directory based protocol under either the release consistency or the total store order model. our results running splash and parsec applications show that volition induces negligible network traf. moreover, by removing fences from several concurrent programs, we show that volition can detect scvs with several processors. as chip multiprocessors emerge as the prevalent microprocessor architecture, support for debugging shared memory parallel programs becomes important. a key difficulty is the programs nondeterministic semantics due to which replay runs of a buggy program may not reproduce the bug. the non determinism stems from memory races where accesses from two threads, at least one of which is a write, go to the same memory location. previous hardware schemes for memory race recording log the predecessor successor thread ordering at memory races and enforce the same orderings in the replay run to achieve deterministic replay. to reduce the log size, the schemes exploit transitivity in the orderings to avoid recording redundant orderings. to reduce the log size further while requiring minimal hardware, we propose timetraveler which for the first time exploits acyclicity of races based on the key observation that an acyclic race need not be recorded even if the race is not covered already by transitivity. timetraveler employs a novel and elegant mechanism called post dating which both ensures that acyclic races, including those through the, are eventually ordered correctly, and identifies cyclic races. to address false cycles through the, timetraveler employs another novel mechanism called time delay buffer which delays the advancement of the banks timestamps and thereby reduces the false cycles. using simulations, we show that timetraveler reduces the log size for commercial workloads by over the best previous approach while using only a byte time delay buffer. chip multiprocessors are emerging as a better alternative to uniprocessors in terms of power dissipation and performance. permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies bear this notice and the full citation on the rst page. to copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speci. however, cmps run shared memory parallel programs which are signi cantly harder to debug than sequential programs due to the programs non deterministic semantics. that is, multiple runs of a buggy shared memory program may result in the bug not manifesting. the reason for the non deterministic semantics is that memory races among threads via shared memoryie, accesses to a memory location at least one of which must be a write change based on the interleaving of the threads. if the interleaving changes due to variations in thread scheduling or access latencies, then the memory races change resulting in a different program outcome. one approach to address this problem is to provide system support for deterministic replay which achieves the same memory race order, and hence produces the same execution as the original run. system support for such replay handles two aspects: a checkpoint state of the program from which a replay may start; and additional state to capture the predecessor successor ordering of the threads involved in each memory race. while the former aspect is well studied, the latter aspect has recently been receiving attention. because such memory races always involve a write to shared memory and because cache coherence generates global events for such memory races, hardware support leverages cache coherence to capture the ordering. because the hardware treats alike all memory races synchronization accesses and data races, such schemes are applicable to programs with and without data races. while previous work has proposed both centralized and distributed schemes, we explore a distributed scheme due to its scalability. in distributed schemes, the hard ware records the predecessor successor ordering among the racing accesses by implementing lamportclocks. a per thread log in the programmemory records the races. the schemes incur two signi cant overheads: large log sizes and hardware overhead of the per block instruction count in the cache. reducing the log size enables longer debugging traces and reducing hardware overhead facilitates widespread adoption. targeting the rst overhead, previous work exploits transitivity in the ordering among threads to avoid logging redundant orderings. other transitivity based optimizations have also been proposed. targeting the second overhead, a recent distributed scheme, rerun, builds on strata to eliminate the per block instruction count in the caches. rerun partitions a threaddynamic instruction stream into episodes, each of which is an atomic sequence of instructions that ends at a current race. we call a memory race a past race if the race is between previously ended predecessor episode and a currently live successor episode, and a current race if the race is among currently live predecessor and successor episodes. rerun exploits the fact that past races are covered by transitivity and need not be recorded, whereas current races are not covered. while previous schemes use a full blown timestamp per block to establish thread ordering, rerun needs only to distinguish whether the block was accessed in a previously ended episode or in a currently live episode, and need not know the exact access time of the block. rerun combines this distinction with a single timestamp per thread to order the episodes. rerunbinary distinction requires signi cantly less hardware than the previous schemes. we propose timetraveler to achieve smaller logs than rerun while requiring minimal hardware by exploiting, for the rst time, acyclicity of races. bringing this completely new property to bear on the problem of memory race recording is the key intellectual novelty of this paper. timetraveler addresses three key limitations of rerun via two novel mechanisms. the first limitation is that the predecessor episode ends immediately upon a current race to address the potential threat that the predecessortimestamp will later advance past the successortimestamp. such ending prevents longer episodes and hence increases the log size. instead, we make the key observation that episodes may include multiple currentraces as long as the predecessor and successor episodes involved in every such race can eventually be ordered properly, and the predecessor successor ordering imposed by the currentraces on currently live episodes is not cyclic. clearly, cyclicity would make predecessor successor order illde ned. accordingly, timetraveler partitions a threaddynamic instruction stream into chapters, each of which ends only when the threads appear to be involved in a cyclic, current race. thus, a chapter is an atomic sequence of instructions that may include several acyclic, current races. from transitivity because current races are rarer than past races, we observe that cyclic current races are even rarer, enabling timetraveler to achieve longer chapters, and hence smaller log. rst novel and elegant mechanism, called post dating, satis es both the constraints of our observation. for the rst constraint, the predecessor chapter provides a post dated timestamp to the successor chapter with the guarantee that in the future the predecessor chaptertimestamp will not advance beyond the post dated timestamp; essentially, post dating creates some breathing room for the predecessor chapter. the successor chapter advances its own timestamp beyond the predecessorpostdated timestamp, guaranteeing that the successor is ordered after the predecessor and neither needs to end its chapter. cyclic ordering would imply that a chapter has to advance beyond its own postdated timestamp. thus, post dating easily detects when the second constraint is about to be violated and forces the offending chapter to end. post datingelegance stems from achieving the above functionality while adding merely one post dated timestamp register per core and not any complicated cycle detection hardware as one might expect. while post dating handles memory races viaresident blocks, the chapters would be shortened by rerunsecond limitation of ending an episode upon the eviction of an block accessed by the episode. rerun conservatively ends the episode because current races via the block may go undetected in the shared due to lack of coherence. we again employ postdating to overcome this limitation. upon evicting a current block, a chapter does not end and instead sends its post dated timestamp to the bank, guaranteeing that any successor is ordered after the predecessor. although post dating handles races via both resident blocks and evicted blocks, evictions cause another problem which is rerunthird limitation. to ensure correct ordering of races via the while avoiding the overhead of per block timestamps, rerun employs a single timestamp for each bank which inherits the latest timestamp among the in coming, evicted blocks. if timetraveler were to employ this scheme, a chapter that hits in an bank would advance its timestamp beyond the banktimestamp to ensure proper ordering with whichever previous chapter had last accessed the block. unfortunately, eviction of a single recently accessed block would force the entire bank to advance to the evicted blocktimestamp, even if all the other blocks in the bank were accessed at much older timestamps. such advancement would often cause the banktimestamp to exceed a chapterpostdated timestamp, inducing false cycles upon hits and forcing the chapter to end. we make the key observation that if evictions are delayed from advancing the banktimestamp, the current chapters post dated timestamps would not be exceeded and the false cycles would be prevented. to this end, we propose a per bank time delay buffer, timetravelersecond novel mechanism, to delay the advancement of the banktimestamp by holding a few recent evictions. timetravelerkey contributions are: while previous schemes exploit transitivity to reduce the log size, timetraveler is the rst to exploit acyclicity of races. timetraveler proposes two novel and elegant mechanisms, post dating and delay buffers, which achieve reduction in the log size while incurring minimal hardware overhead; using simulations, we show that timetraveler reduces the log size compared to rerun by and for commercial and scienti. benchmarks, respectively, while adding over rerun only a byte time delay buffer and two bit registers for post dated timestamp and past timestamp per core. the rest of the paper is organized as follows. we describe timetraveler and its mechanisms, post dating and time delay buffer, in section #. we show our results in section #, and conclude in section #. debuggers have been proven indispensable in improving software reliability. unfortunately, on most real life software, debuggers fail to deliver their most essential feature a faithful replay of the execution. the reason is non determinism caused by multithreading and non repeatable inputs. a common solution to faithful replay has been to record the non deterministic execution. existing recorders, however, either work only for datarace free programs or have prohibitive overhead as a step towards powerful debugging, we develop a practical low overhead hardware recorder for cachecoherent multiprocessors, called flight data recorder. like an aircraft flight data recorder, fdr continuously records the execution, even on deployed systems, logging the execution for post mortem analysis fdr is practical because it piggybacks on the cache coherence hardware and logs nearly the minimal threadordering information necessary to faithfully replay the multiprocessor execution. our studies, based on simulating a four processor server with commercial workloads, show that when allocated less than of system physical memory, our fdr design can capture the last one second of the execution at modest slowdown. an important challenge facing computer industry is to develop reliable software and to maintain it after deployment. debugging has been an effective solution to this this work is supported in part by the national science foundation, with grants eia, ccr, eia, ccr, and eia, a wisconsin romnes fellowship, universitat politcnica de catalunya and secretara de estado de educacinuniversidades de espaa, and donations from ibm, intel, microsoft, and sun. center universitat politcnica de hawthorne, ny year# catalunya barcelona, spain challenge. essential to any debugger, deterministic replay enables an expert to re execute the program and zero in on bugs that faithfully re appear. one problem in debugging that has been eluding a software only solution is how to perform deterministic replay of multiprocessor executions. as hardware costs diminish relative to software and maintenance costs, it is economical to seek hardware that facilitates debugging of complex systems. a common method for deterministic replay of multiprocessor executions is to record outcomes of all nondeterministic events, most notably those of memory races. the key problem addressed in this paper is how to record memory races with small overhead, to enable recording on deployed systems. low overhead recording has been an open problem: several systems record synchronization races, but without recording data races, they can faithfully replay only data race free programs. unfortunately, programs being debugged may not identify synchronization or may contain data races, harmful or harmless, and these races must be recorded for deterministic replay. furthermore, no existing system supports deterministic replay in the harsh full system environment, where applications and diverse io devices from different vendors interact via operating system mechanisms on multithreaded hardware. to illustrate the difficulties, consider finding a bug that manifest itself only when a device by a vendor a interrupts a driver by vendorbetween two instructions of what should have been an atomic update to enable full system deterministic replay of multiprocessor executions, we propose a flight data recorder that adds modest hardware to a directory based sequentially consistent multiprocessor. like an aircraft flight data recorder, fdr continuously records the execution in anticipation of a trigger, which can be a fatal crash or an software assertion violation. when triggered, fdr produces a log enhanced core dump for a replay interval preceding the trigger, to be analyzed in an off line replayer. the core dump includes three kinds of logs, each designed to meet performance, space, and complexity requirements of a practical recorder for continuous recording in deployed systems: to restore a consistent system state at the beginning of the replay interval, fdr modestly adapts an existing approach that logs old memory state whenever the memory is updated, and dumps the complete memory image at the time of the trigger. to record the outcomes of all races, fdr logs a subset of the races. we build on hardware ideas of bacon and goldstein and the software transitive reduction optimization of netzer. this optimization avoids logging races whose outcomes are implied by other races. a limitation of our design is its assumption of sequential consistency. to record system io, fdr logs interrupt timing and treats device interfaces as pseudo processors to ease dma logging. we propose a concrete fdr design, called fdr, and evaluate its practicality using full system simulation of a four processor system with four commercial workloads. we qualitatively discuss scaling to other systems and workloads. our experiments show that low time and space overhead allows fdr to be continuously enabled. specifically, we find that for a system with modern processors and ghz system clock, fdr generates logs at the bandwidth of mb second processor. the net result is that fdr can capture a replay interval of one billion cycles prior to the trigger with only of the system physical memory dedicated to its logs. the paper concludes with a discussion of how an offline software replayer would use fdrlogs to perform deterministic replay. this paper makes two key contributions: it designs an efficient full system recorder, called fdr, for sequentially consistent multiprocessors. fdr allows deterministically replaying full system activities of a system with speculative processors. fdr is easy to implement because it piggybacks on the directory based cache coherence protocol. fdr is efficient because it records a small subset of all races in the system. name enablesdeterministicreplay handlesos io hardwaresupport goal: deterministic replay flight data recorder instantreplay bacon goldstein netzer deja vu traceback always yes yes yes uni proc partially yes no no no no no yes no yes no no no goal: race detection dinning schonberg min choi eraser richard larus recplay no no no no sometimes no os no os no no yes no no no within designed replay interval. it evaluates the recorder on commercial workloads via full system simulations. the simulations show that fdr is practical: it generates relatively small logs and its modest time overhead allows it to be continuously enabled. multithreaded deterministic replay has important applications in cyclic debugging, fault tolerance and intrusion analysis. memory race recording is a key technology for multithreaded deterministic replay. in this paper, we considerably improve our previous always on flight data recorder in four ways: longer recording by reducing the log size growth rate to approximately one byte per thousand dynamic instructions. lower hardware cost by reducing the cost to kb per processor core. simpler design by modifying only the cache coherence protocol, but not the cache. broader applicability by supporting both sequential consistency and total store order memory consistency models. these improvements stem from several ideas: a regulated transitive reduction recording algorithm that creates stricter and vectorizable dependencies to reduce the log growth rate; a set lru timestamp approximation method that better approximates timestamps of uncached memory locations to reduce the hardware cost; an order value hybrid recording methodthat explicitly logs the value of potential sc violating load instructions to support multiprocessor systems with tso. deterministic replay of multithreaded programs has several important uses. first, determinism can help developers effectively debug multithreaded programs using cyclic debugging because the erroneous executions can be repeated. furthermore, determinism is also necessary in fault detection, fault recovery, and replay based intrusion analysis. to faithfully replay a multithreaded execution, we need to replay the following information: program initial states; program inputs; and memory races among threads. a recorder records these types of information through three mechanisms: checkpointing, input logging and memory race recording. existing software based recorders are often limited to offline usesdue to their prohibitive runtime overheads. as transistors get cheaper, spending a small amount of chip area on a hardware based, low overhead recorder is becoming more economical. in a previous paper, we proposed a hardware based flight data recorder, which includes checkpointing, input logging, and memory race recording with little runtime overhead. in this paper, we improve fdrmemory race recording with significant reduction in the log size and hardware cost. we focus on memory race recording for three reasons. the log size of fdrmemory race recorder is approximately mb ghz processor second. the size of both the memory race log and the checkpoint log limits fdr to only one second of recording, which may be sufficient for debugging. however, other applications may need much longer recording. to do that, we need to reduce the memory race log and the checkpoint log. it is relatively easy to reduce checkpoint log because it can be eliminated or amortized by longer checkpoint intervals. therefore, it is more important to reduce the memory race log. furthermore, fdrrace recorder requires the sequential consistency memory model, which is supported by alimited subset of existing multiprocessor systems. therefore, it is important to develop a new race recorder that supports more memory models. fdrmemory race recorder is integrated with the memory caches. this adds undesirable complexity to the caches, which are performance critical structures. fdr increases the chip area of the caches by. a hardware race recorder is more attractive if its hardware cost is reduced therefore, it is important to develop a new recorder that has lower complexity and requires smaller chip area. bugnet is another recorder, which improves fdrcheckpointing and input logging. by logging first time load values, bugnet reduces the log size of checkpointing and input logging, as well as the hardware cost. considering these improvements, memory race recording is likely a bottleneck for future recorders. netzertransitive reduction, generates the most compact log among existing partial order race recording algorithms. we show that further reduction of the log size is possible if we judiciously log stricter and vectorizable dependencies, which are not necessarily conflicts. we propose a new partial order recording algorithm regulated transitive reduction. rtr logs stricter dependencies, which are stricter because enforcing them is sufficient but not necessary for faithful replay. rtr creates stricter dependencies so that a large number of dependencies are vectorizable. vectorized dependencies are reminiscent to vectorized computations one type of computation is performed on multiple data. we show that rtr is better than tr and reduces the log size by on average. in order to find those dynamic instructions that race with each other, netzerrecorder incurs non trivial hardware cost by storing the last read write timestamps for each memory block. fdr reduces this hardware cost by storing only those timestamps of cached blocks and approximates the timestamp if a block is uncached. fdrapproximation method often causes a false race to be logged whenever a block is missed in the cache, ie, fdrlog growth rate goes up as the hardware cost goes down. in this paper, we propose a new timestamp approximation method, which simultaneously reduces the log size and the hardware cost. this new method approximates the missing timestamps using the least recently used blocktimestamp within the same associative set. we call this set lrutimestamp approximation, which reduces the hardware cost to kb per core and, together with rtr, reduces the log size by over fdr. this can introduce much design complexity to the memory caches, which are performance critical components. we move timestamps out of cache, which allows us to independently size the timestamp memory and potentially reduce the overall design complexity. when used with the total store order memory consistency model, existing race recorders can run into replay deadlocks because they assume sequential consistency. we propose a new order value hybrid recording method to support tso. the hybrid method avoids replay deadlocks and deterministically replays tso executions by recording additional information of the load values when load instructions potentially violate the sc ordering. we make the following contributions in this paper. we improve fdrrace recording algorithm, through rtr and set lru. the new algorithm enables significant log size and hardware cost reductions. we improve a race recorder implementation by lowering the design complexity and supporting tso. we design and evaluate a race recorder on a four way chip multiprocessor system using full system simulations and commercial workloads. we present the new recording algorithm with small log size and low hardware cost in sections. we propose moving the timestamps out of processor caches and present a method to support tso in sections. wedescribe a concrete recorder: rtr cmp, a cmp based hardware race recorder. we evaluate rtr cmp and explore a design space in section #. we discuss related work in section #and conclude in section #.