the task of erwd as answering arbitrary information needs expressed as keyword queries that aim at nding nodes or aspects of nodes in rdf graphs was rst introduced by pound et al. they also proposed to classify such queries into ve categories: entity queries, type queries, attribute queries, relation queries, and other queries. although multiple open entity retrieval evaluation campaigns providing test collections and query sets covering a variety of information needs and relevance judgments have been conducted, most of the previous work along this direction focused on one particular query type. for example, the sem search entity search challenge focused on nding one particular entity described by a keyword query. previous successful retrieval approaches for queries of this type involved construction of multi elded entity representations by grouping entity attributes together by type, into title and content, according to manually determined importance or into a two level hierarchy. several methods adopted a two stage approach, in which the initial retrieval results obtained using standard bag of words retrieval models were rst expanded using relations in the knowledge graph and then the expanded results were re ranked based on entity similarity. tonon et al used jaro winkler similarity between the entity names, while herzig et al used jenson shannon divergence between the language models of entities. zhiltsov and agichtein proposed a learningto rank based approach, which combines explicit entity information with semantic similarity between the entities in latent space determined using a modi ed algorithm for tensor factorization. the inex year# entity ranking track introduced an entity list completion task and provided an evaluation platform for type queries. the trec year# entity track focused on two related retrieval tasks related entity nding and entity list completion. the list search track from the semsearch challenge targets a group of entities that match a keyword query. bron et al proposed a hybrid approach that linearly combines the scores of the mixture of language models and a structure based method, which captures the statistics of predicate object pairs in triples shared by entity candidates. elbassouni et al focused on the case of structured queries consisting of rdf triples and proposed a method that constructs lms for both the queries and each possible result sub graph. the ranking is based on the kullback leibler divergence between the query lm and the lms of each result sub graph. the semsets model utilizes the relevance of entities to automatically constructed categories measured according to structural and textual similarity. their approach combines a retrieval model with the methods for spreading activation over the link structure of a knowledge graph and evaluation of membership in semantic sets. question answering over linked data evaluation campaigns aim at developing retrieval methods to answer sophisticated question like queries. the ma jority of queries are natural language questions that are focused on nding one particular entity as exact answers to these questions. a method based on integer linear http: km aifb kit edu ws semsearch\ http: wwws de demartini xer http: www sc cit ec uni bielefeld de qald programming for joint segmentation and disambiguation of question like queries was proposed in. shekarpour et al applied the hidden markov model to map question terms into entities and relations in the knowledge graph and translated keyword queries into structured sparql queries. multi elded extensions of di erent bag of words retrieval models have been proposed for structured document retrieval. bm allows to either combine the bm retrieval scores of individual document elds with di erent weights into the nal document retrieval score or calculate the aggregated basic retrieval statistics, such as tf and eld lengths across multiple elds and use them in the original retrieval formula. mixture of language models is a multi elded extension of the query likelihood retrieval model, a stan where qi is a query term, is a document, tfqi, is the frequency of qi in, is the document length, is a dirichlet prior, that is usually set to the average document length in the collection, cfqi is the collection frequency of qi andis the total number of terms in the collection. to adapt the mrf framework to multi elded entity descriptions, we propose to replace a single document language model with a mixture of language models for each document eld. hence, our model is an extension of sequential dependence model, although the same transformation can be applied to the full dependence model. consequently, the potential function for unigrams in case of fsdm is: cftfqi, djcqjtjj log logwd djj dard language modeling based retrieval model. in mlm, the where, is the number of elds, is a languageretrieval score of a structured document is a linear combina model of eldsmoothed using its own dirichlet priortion of probabilities of query terms in the language models and wj are the eld weights with the following constraints: calculated for each document eld. although individual eldwj, wj; tfqi, dj is the term frequency of qi in weights in bm and mlm can be tuned for a particular cf qjis the collection frequency of qi eldof document; collection, they are xed across di erent query terms. to overcome this limitation, probabilistic retrieval model for in eld; cj is the total number of terms in eldacross all the documents in the collection and dj is the length of semistructured data maps each query term eldin. into document elds using probabilistic classi cation based the potential functions for ordered and unordered bigrams on collection statistics. although prms was originally pro posed for xml retrieval, it was later applied to erwd. qi, in the query are de ned as follows: field relevance model is an extension of prms cf tf, djcj to the case of relevance feedback. fo logj djincorporating term dependencies into retrieval models. metzler and croft proposed the mrf retrieval model, which based on the assumption about the dependencies be cfj uw tf uw, djcj tween the query terms, has three variants: full independence fu log, sequential dependence and full dependence djmodels. bendersky et al extended sdm to allow learningoptimal weights for unigrams and bigrams as a linear combination of features that are based on internal and external collection statistics. huston and croft systematically evaluated a large number of bigram dependence models across short and long queries and concluded that retrieval models incorporating term dependencies consistently improve retrieval accuracy over the standard bag of words retrieval models. they also experimentally demonstrated that the performance of term dependence models can be signi cantly improved through parameter tuning.