in our framework we model the querying behavior of users by a probabilistic reformula tion graph, or query flow graph. providing recommendations can be seen as adding shortcuts in the query flow graph that nudge the reformulation paths of users, in such a way that users are more likely to follow paths with larger expected utility. query recommendation is an integral part of modern search engines. the goal of query recommendation is to facilitate users while searching for information. query recommendation also allows users to explore concepts related to their information needs. in this paper, we present a formal treatment of the problem of query recommendation. a sequence of queries submitted by a user can be seen as a path on this graph. we discuss in detail the most important questions that arise in the proposed framework. in particular, we provide examples of meaningful utility functions to optimize, we discuss how to estimate the effect of recommendations on the reformulation probabilities, we address the complexity of the optimization problems that we consider, we suggest efficient algorithmic solutions, and we validate our models and algorithms with extensive experimentation. our techniques can be applied to other scenarios where user behavior can be modeled as a markov process. assigning score values to queries allows us to define suitable utility functions and to consider the expected utility achieved by a reformulation path on the query flow graph. query recommendations are a prominent feature of modern search engines. we model the query recommendation problem as a problem of optimizing a global utility function. the nodes of this graph are distinct queries, and an edge is annotated with the probability that a user will submit query. we then model the querying behavior of users as random walks on this graph. query recommendations serve several purposes: correcting possible spelling mistakes, guiding users through their information seeking tasks, allowing them to locate information more easily, and helping them explore other concepts related to what they are looking for. the simplest form of query recommendation is spelling correction, a topic that we do not address in this paper. for instance, by submitting the query chocolate cookie a user may be prompted to other queries such as chocolate cookie recipe, or chocolate chip cookie recipe, but also to related concepts such as brownies, baking, and so on. a key technology for enabling query recommendations is query log mining, which is used to leverage information about how people use search engines, and how they rephrase their queries when they are looking for information. most of the proposed query recommendation algorithms in the literature use aggregate user information mined from query logs and allowing to identify queries that are relevant to what the user is searching. current state ofthe art methods often produce relevant query recommendations, but typically there is no clear objective to optimize and query recommendation methods are fairly ad hoc. in this paper we propose a general and principled methodology for generating query recommendations. second, we assume that the queries in the query ow graph have intrinsic score values, which model a desired property of the queries. for example, may represent the probability that users who submit querywill be satis ed with the search engine results. we assume that during the random walk on the query ow graph, users collect the scores of the nodes that they visit. the higher the total value collected, the higher the overall utility of the system. last, we assume that query recommendations can be viewed as a perturbation of the transition probabilities in the query ow graph. the motivation is that while searching for information users tend to follow edges according to their propensity to reformulate queries, but they also move to queries that are recommended to them by the search engine. given the objective to maximize the overall utility of the system, we formulate the query recommendation problem as deciding how to perturb the transition probabilities so as to maximize the expected utility of a random walk. the framework is based on the use of a random walk over the query ow graph. an important ingredient of our framework is a model, supported by experimental evidence, of the way in which the addition of query recommendation links. we design optimization algorithms to place query recommendation links so as to optimize the expected bene. ectiveness of the algorithms we propose is supported by theoretical analysis. for the special case of adding recommendation links to a single node, we are able to provide a characterization of optimal solutions. for the general case of adding recommendation links from each node, we propose a heuristic based on the optimization of a modi ed objective function, which is a good proxy of the original objective function when the perturbation induced by adding recommendations is relatively small. we perform experiments addressing the following issues: testing the validity of our model on real query log data; assessing the performance of our algorithms with respect to other reasonable heuristics on real data. note that the algorithms that we propose maximize the expected bene. over the entire navigation of the user, not just the bene. ects of this choice, we also present the results of a user study intended to assess the user perceived quality of query recommendations provided by our heuristics and the top ones returned by other systems. while we present the problem using query recommendations as a motivation, our model and methods can be applied to other scenarios where user behavior can be modeled as a markov process. a concrete application that also partly motivated our work is leisurerelated search in entertainment sites such as yahoo omg. usually, users start browsing these services either from the frontpage or by performing some query. our goal in this case is to show recommendations that take into account the browsing behavior of users in order to deliver an entertaining experience to the user, which involves a path along several of the best pages in the site. as another example, consider exploring media sites such as youtube or flickr, where the system allows for browsing the collection in a guided way, suggesting related contents in order to provide an entertaining experience. in such a scenario, content should be recommended according to some interestingness criteria, and recommendations should depend not only on the next step of the user navigation, but also on the user future browsing path. ective recommendations as a suitably de ned optimization problem. in section #, we present our analysis of historical data to model the user browsing behavior and query utility. in section # we build on this model to solve the query recommendation problem, and we compare our method with other natural baselines. finally, in section # we conclude and present some ideas for future work. instead we focus on more elaborate forms of query recommendations. our approach consists of the following ingredients: first, we assume that it is possible to aggregate historical information from a query log to build a queryreformulation graph. from the algorithmic point of view, the problem of ndingshortcut edges to add at each node order to maximize the overall utility is an nphard optimization problem. in this paper, we discuss the complexity of the problem and we propose approximate algorithms for obtaining solutions of high quality. we propose an optimization framework for query recommendation. achieved by navigating the perturbed query ow graph. our characterization allows to design a heuristic strategy that achieves nearoptimal performance. section # de nes the scenario that we are interested in and formally describes the model we adopt in the rest of the paper. section # addresses the complexity of the general problem we consider. in this paper, we propose a novel context aware query suggestion approach which is in two steps. in the offine model learning step, to address data sparseness, queries are summarized into concepts by clustering a click through bipartite. then, from session data a concept sequence suffix tree is constructed as the query suggestion model. query suggestion plays an important role in improving the usability of search engines. although some recently proposed methods can make meaningful query suggestions by mining query patterns from search logs, none of them are context aware they do not take into account the immediately preceding queries as context in query suggestion. in the online query suggestion step, a user search context is captured by mapping the query sequence submitted by the user to a sequence of concepts. by looking up the context in the concept sequence sufix tree, our approach suggests queries to the user in a context aware manner. we test our approach on a large scale search log of a commercial search engine containing billion search queries, billion clicks, and million query sessions. the experimental results clearly show that our approach outperforms two baseline methods in both coverage and quality of suggestions. ectiveness of information retrieval from the web largely depends on whether users can issue queries to search engines, which properly describe their information needs. writing queries is never easy, because usually queries are short and words are ambiguous. therefore, there is no standard or optimal way to issue queries to search engines, and it is well recognized that query formulation is a bottleneck issue in the usability of search engines. that is, by guessing a usersearch intent, a search engine suggests queries which may better re ect the userinformation need. it is hard to determine the usersearch intent, ie, whether the user is interested in the history of gladiator, famous gladiators, or the lm gladiator. moreover, the user is probably searching the lms played by russell crowe. in this paper, we propose a novel context aware query suggestion approach by mining click through data and session data. first, instead of mining patterns of individual queries which may be sparse, we summarize queries into concepts. to tackle these challenges, we develop a novel, highly scalable yet. we develop a novel structure of concept sequence su. third, we empirically study a large scale search log containing billion search queries, billion clicks, and million query sessions. we explore several interesting properties of the click through bipartite and illustrate several important statistics of the session data. the clustering algorithm and the query suggestion method are described in sections and, respectively. to make the problem even more complicated, di erent search engines may respond di erently to the same query. recently, most commercial search engines such as google, yahoo, live search, ask, and baidu provide query suggestions to improve usability. a commonly used query suggestion method is to nd similar queries in search logs and use those queries as suggestions for each other. another approach mines pairs of queries which are adjacent or co occur in the same query sessions. although the existing methods may suggest good queries in some cases, none of them are context aware they do not take into account the immediately preceding queries as context in query suggestion. without looking at the context of search, the existing methods often suggest many queries for various possible intents, and thus may have a low accuracy in query suggestion. if we nd that the user submits a query beautiful mind before gladiator, it is very likely that the user is interested in the lm gladiator. the query context which consists of the recent queries issued by the user can help to better understand the usersearch intent and enable us to make more meaningful suggestions. a concept is a group of similar queries. although mining concepts of queries can be reduced to a clustering problem on a bipartite graph, the very large data size and the curse of dimensionality pose great challenges. we may have millions of unique queries involving millions of unique urls, which may result in hundreds of thousands of concepts. second, there are often a huge number of patterns that can be used for query suggestion. how to mine those patterns and organize them properly for fast query suggestion is far from trivial. the data set in this study is several magnitudes larger than those reported in previous work. last, we test our query suggestion approach on the search log. the experimental results clearly show that our approach outperforms two baseline methods in both coverage and quality of suggestions. the rest of the paper is organized as follows. we rst present the framework of our approach in section # and review the related work in section #. we report an empirical study in section #. it has long been recognized that capturing term relationships is an important aspect of information retrieval. even with large amounts of data, we usually only have significant evidence for a fraction of all potential term pairs. it is therefore important to consider whether multiple sources of evidence may be combined to predict term relations more accurately. this is particularly important when trying to predict the probability of relevance of a set of terms given a query, which may involve both lexical and semantic relations between the terms we describe a markov chain framework that combines multiple sources of knowledge on term associations. the stationary distribution of the model is used to obtain probability estimates that a potential expansion term reflects aspects of the original query. we use this model for query expansion and evaluate the effectiveness of the model by examining the accuracy and robustness of the expansion methods, and investigate the relative effectiveness of various sources of term evidence. statistically significant differences in accuracy were observed depending on the weighting of evidence in the random walk. for example, using co occurrence data later in the walk was generally better than using it early, suggesting further improvements in effectiveness may be possible by learning walk behaviors. negotiations where, andrepresent co occurrence, synonymy, and morphology relations respectively. we also do not use a pre defined network for all queries, but customize each network for each query. associative models consider relationships between terms in addition to the terms themselves. they have been extensively considered and studied for information retrieval, eg, by bush, stiles, van rijsbergen and salton buckley among many others. there are many lexical and semantic relations that may be considered for associating a pair of terms. for example: stemming, based on common morphology; synonymy, where aspects of meaning are shared; cooccurrence, in which both words tend to appear together; and general association, where a person is likely to give one word as a free association response to the other. each relation may be thought of as an inference step, in which a source wordhas some property, and a new wordcan be inferred to have the property value with probability pr, based on their shared relation. for example, ifis the word matrix and the property is relevancy to a query, then one possible way to calculate pr is based on co occurrence, so that, for example, the term row also has some measure of relevance. note that this is not symmetric: row having more senses and being more common, it is less likely to imply relevance of matrix, unless another term is also present for context, such as column. while lexical and semantic relations may be useful individually, it is important to consider how they may be used in combination. one reason for this is a common problem in language processing called sparsity: for cooccurrence relations for example, even with a huge corpus, we only have reliable co occurrence data for a fraction of all potential term pairs. external semantic resources such as wordnet or stemming dictionaries supply a broad set of terms but are limited in the depth and currency of their vocabulary. by combining multiple relations into chains of inference, we can help bridge the gaps that exist in the data. a second reason is that the various relations between words represent potentially complimentary sources of evidence that may help to distinguish and disambiguate terms. for example, if bank and merger are known to be relevant to a query, then the following inference brain figure #. the walk uses co occurrence relations in early steps, then shifts to stemming and association for later steps in the walk. values inside the nodes are example probabilities from the stationary distribution. chains would provide evidence that negotiations may also be relevant: bank. note that chains can emphasize different types of evidence at different walk stages. in the above example, co occurring terms are found first, followed by their synonyms or stems. in this paper we propose and evaluate a markov chainbased framework for modeling term relations that can perform such combination of behavior and apply this model to query expansion. given a small set of initial query terms, we construct a term network and use a random walk to estimate the likelihood of relevance for potential expansion terms. the features used by the random walk can come from a variety of sources, such as term co occurrence in an external corpus, cooccurrence in the top retrieved documents, synonym dictionaries, general word association scores, and so on. unlike many previous related models used for information retrieval, we define a much richer set of potential walk behaviors that support a variety of link types, where different combinations of evidence can be used at different stages of the walk. for example, cooccurrence may initially be given higher weight early in the walk, with synonyms weighted more highly in later steps. we apply our model to the problem of query expansion in the language modeling approach to information retrieval. by estimating the probability that the various aspects of the query can be inferred from a potential expansion term, we essentially perform a form of semantic smoothing of the query language model. the main hypothesis of this paper is that combining query specific term dependencies from multiple sources can lead to more accurate and or robust expansion algorithms. simplified example of a stationary distribution induced by a random walk starting at the node parkinsondisease. search engines can record which documents were clicked for which query, and use these query document pairs as soft relevance judgments. however, compared to the true judgments, click logs give noisy and sparse relevance information. we apply a markov random walk model to a large click log, producing a probabilistic ranking of documents for a given query. a key advantage of the model is its ability to retrieve relevant documents that have not yet been clicked for that query and rank those effectively. we conduct experiments on click logs from image search, comparing our random walk model to a different random walk, varying parameters such as walk length and self transition probability. the most effective combination is a long backward walk with high self transition probability. a search engine can track which of its search results were clicked for which query. for a popular system, these click records can amount to millions of query document pairs per day. each pair can be viewed as a weak indication of relevance: that the user decided to at least view the document, based on its description in the search results. although clicks are not real judgments, there is evidence that they are useful, for example as training data, as annotations, for query suggestion or directly as evidence for ranking. permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies bear this notice and the full citation on the rst page. to copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speci. we can use the clicks of past users to improve the current search results. however, the clicked set of documents is likely to di er from the current userrelevant set. other di erences are due to presentation issues; for example, the user must decide whether to click based on a short summary and is in uenced by the ordering of results. for any given search, a large number of documents are never seen by the user, therefore not clicked. from the perspective of a user conducting a search, documents that are clicked but not relevant constitute noise in the click data. documents that are relevant but not clicked constitute sparsity in the click data. one class of approaches attempts to reduce noise in click data, by building a click model that may use additional information about the userbehaviour. these approaches can signi cantly reduce noise, by identifying some clicked documents as irrelevant. this paper focuses on the sparsity problem, although our model also has noise reduction properties. the model gives a probabilistic ranking of documents, which includes relevant documents that have not yet been clicked for the current query. the sparsity problem is evidenced by power law distributions observed in click logs. most queries in the click log have a small number of clicked documents. in such cases, it is useful to identify additional relevant documents. we rst describe the click information as a graph, and survey a range of click graph applications. then we detail our markov random walk model for nding relevant documents. the subsequent sections describe a real click dataset, and empirical evaluation of the new methods. some differences arise because we are aggregating clicks across users, who may simply disagree about which documents are relevant. for example, taking into account the userbrowsing patterns after clicking a document. the evaluation of these techniques has primarily, however, focused on proprietary query logs and selected samples of queries. in this paper, we suggest that anchor text, which is readily available, can be an effective substitute for a query log and study the effectiveness of a range of query reformulation techniques using standard trec collections. our results show that log based query reformulation techniques are indeed effective with standard collections, but expansion is a much safer form of query modification than word substitution. we also show that using anchor text as a simulated query log is as least as effective as a real log for these techniques. query reformulation techniques based on query logs have been studied as a method of capturing user intent and improving retrieval effectiveness. when users interact with a search engine, they not only nd documents satisfying their information need, they also provide the search engine with implicit feedback about the results returned by the system. the search engine keeps track of this information in the form of a query log, which basically includes queries submitted by users and documents from the result pages that have been clicked on to view. permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies arenot made or distributed for pro. or commercial advantage and that copies bear this notice and the full citation on the rst page. to copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speci cpermission and or a fee. wsdm, february, year#, new york city, new york, usa. bruce croft center for intelligent information retrieval department of computer science university of massachusetts amherst, ma croft cs umass edu since a query log is a rich information source about users, the analysis of these logs has recently become an active research area. query logs have been used for many tasks, one of which is query reformulation. query reformulation aims to solve the vocabulary mismatch problem in information retrieval by changing the original query to a form that is a better match with relevant documents. much of the previous work operates on the whole query level, which is more commonly known as query recommendation. the techniques that we focus on generate new queries by substituting or adding words or phrases to the original query. another example of recent work on log based query reformulation is that of wang and zhai, which works on the word level. the method rst extracts term associations based on their context distribution. for a new query, the method will decide whether to substitute a term with one of its similar words based on whether this new word matches the context of the query better than the original term. ective with web queries using click data as relevance judgments. instead of reducing words into their root forms at indexing time, the stemmer determines at query time which word variants should be used to expand the query. although it was demonstrated in the work of peng et al that context sensitive stemming is useful for web search, they evaluate it on a sample of web queries and do not compare it against traditional stemming approaches. these and other studies of query reformulation based on query logs nearly all make use of nonstandard approaches to evaluation and proprietary query logs. this makes the comparison of techniques di cult and their applicability to new applications and domains unclear. in this paper, we compare reformulation techniques using trec collections and suggest modi cations based on the results. in particular, we nd that expansion is a more reliable form of modi cation than substitution. to address the problem of the lack of availability of query logs, we instead propose to use anchor text to simulate the important parts of a log. previous researchers have also noted the similarity of anchor text to queries. kraft and zien demonstrated that using anchor text to re ne a query is better than doing so with the document collection. there have also been studies showing that anchor text resembles real queries in terms of term distribution and length. given these results, in this paper we construct a simulated query log or anchor log from the anchor text in a web test collection. we then evaluate the log based query reformulation techniques using both the anchor log and a real query log and show that the anchor log produces results that are at least as. in the next section, we describe how we construct the anchor log and compare it to the msn log. section # presents the query substitution technique that we use in more detail. section # describes the context sensitive query stemming technique. section # contains the experimental results based on the anchor log and query log, as well as a discussion of those results. mentions some more related work and section # concludes. this class of techniques rst clusters similar queries based on commonly clicked documents or the similarity of vocabulary used in clicked documents, and uses queries in the same cluster as recommendations for one another. for example, the technique proposed by jones et al works on the phrase level by looking at successive pairs of queries in user sessions. two queries that are di erent from each other by only one phrase are selected and the corresponding pairs of phrases are recorded as substitution candidates, which are used to generate substitutions for new queries. this study, however, did not evaluate the retrieval. context sensitive stemming based on query logs is another type of query reformulation that has been studied. anchor text is well known to be an important feature for. for example, nallapati et al used anchor text as relevant queries to train a retrieval model. query log analysis has received substantial attention in recent years, in which the click graph is an important technique for describing the relationship between queries and urls. state of the art approaches based on the raw click frequencies for modeling the click graph, however, are not noise eliminated. nor do they handle heterogeneous query url pairs well. in this paper, we investigate and develop a novel entropy biased framework for modeling click graphs. the intuition behind this model is that various query url pairs should be treated differently, ie, common clicks on less frequent but more specific urls are of greater value than common clicks on frequent and general urls. based on this intuition, we utilize the entropy information of the urls and introduce a new concept, namely the inverse query frequency, to weigh the importance of a click on a certain url. the iqf weighting scheme is never explicitly explored or statistically examined for any bipartite graphs in the information retrieval literature. we not only formally define and quantify this scheme, but also incorporate it with the click frequency and user frequency information on the click graph for an effective query representation. to illustrate our methodology, we conduct experiments with the aol query log data for query similarity analysis and query suggestion tasks. experimental results demonstrate that considerable improvements in performance are obtained with our entropy biased models. moreover, our method can also be applied to other bipartite graphs. recently query log analysis has been studied widely for improving search engines. such stud permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies bear this notice and the full citation on the rst page. to copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speci. ies mined the logs to improve numerous search enginecapabilities, such as query suggestion and classi cation, ranking, targetedadvertising, etc. theclickgraph, abipartite graphbetweenqueries andurls, is animportanttechnique for describing the information contained in the query logs, in which edges connect a query with the urls that were clicked by users as a result. an example of a click graph with queries and urls is depicted in figure #. the edges of the graph can capture some semantic relations between queries and urls. for example, queries map and travel are related to each other, since theyare co clickedwith some urls such as www mapquest com and so on. therefore, howtoutilizeand model theclickgraph torepresentqueries becomes an interesting and challenging problem. traditionally, the edge ofthe clickgraphis weightedbased on the raw clickfrequency from aquery to a url. the transition probability can be further determinedbythenormalized clickfrequency. takingthe edgefrom map to www mapquest com infigure asanexample, the rawclickfrequencyis and thenormalized click frequencyis. however, thetraditionalqueryrepresentation for the click graph has its own disadvantages. one of thesedisadvantagesisits robustness,e, aquery thathasa skewed click count on a certain url may exclusively in uence the click graph, such as navigational queries. ect on learning algorithms, previous work presented in simply identi ed some navigational queries and removed them from the click graph. unfortunately, the deletion of such queries leads to the loss of some information. another related problem is that the raw click frequencycanbeeasilymanipulatedasitispronetospamby some malicious clicks. to deal with these critical problems, weexploreanovel entropy biasedframework whichincorporates raw click frequencies and other information with the entropy information of the connected urls. the basic idea of the entropy biased model is that various query url pairs should be treated di erently. let us look atthequery map and its connected urls, which is shown in figure #. the click frequency from to is the same as the count from to. there is a critical question when only consider the raw click frequency: is a single click on di erent urls in the click graph equally important clearly not in this case, at an intuitive level, one click on may capture more meaningful information, or be more important than one click on. the key difference is that the connected urls are di erent: one url is www mapquest com, which is connected with queries; while anotherurlis www yahoo com, whichis connected with queries. suppose there is a url which is commonly clicked and connected with most of thequeries, this tends to increase the ambiguity of the url. however, if the url is clicked and connected with fewer queries, this tends to increase the speci city of the url. a frequently clicked url thus functions in retrieval as a nonspeci curl, eventhoughits meaning maybequitespeci. url is most likely to be more important for distinguishing the speci city of the query than another click on an ambiguous url. based on the above intuition, we introduce a new concept, denoted as the inverse query frequency, to weigh the importance of a click on a certain url, which can be extended and used for other bipartite graphs. consequently, we propose a novel entropy biased model, namely cf iqf model, torepresentthequery, which simultaneously combinestheinversequery frequency information with the raw click frequency. as the raw click frequency can be easily manipulated, we develop and use the number of users associated with the query url pair, namely the user frequency, instead of the raw click frequency toimprovethe resistanceagainst maliciousclick data. moreover, the inverse query frequency can be incorporated with the user frequency, as another entropy biased uf iqf model, toachievebetterperformance. toillustrate our methodology, we apply the entropy biased models to query similarity analysis and query suggestion tasks using the real world aol query log data. the main concern is to increase the precision of the topretrieved results. for thequery similarity analysis, wecomparesixdi erent models, includingfour models based ontheclickgraph and two models based on the query terms. it is shown that cf iqf model improvesovercf modelby up to, whileuf iqf over uf by up to. as expected, uf iqf and uf outperform cf iqf and cf respectively. in addition, uf iqf model signi cantly improves the traditional tf idf model by up to. for the query suggestion task, evaluation results also show that the entropy biased models outperform thebaseline models, indicatingthattheimprovementsinour proposed models are consistent and promising. the rest of this paper is organized as follows. in section # we present the proposed query representation models. section # describes two basic applications of these models, which are the query similarity analysis and query suggestion. we then describe and report the experimental evaluation in section #. finally, we present our conclusions and future work in section #. a typical type of imperfection is the preference misalignment between search engines and end users, eg, from time to time, web users skip higher ranked documents and click on lower ranked ones. although search engines have been aggressively incorporating clickthrough data in their ranking, it is hard to eliminate such misalignments across millions of queries. therefore, we, in this paper, propose to accompany a search engine with an always on component that reorders documents on a per query basis, based on user click patterns. because of positional bias and dependencies between clicks, we show that a simple sort based on click counts, albeit intuitive and useful, is not precise enough. in this paper, we put forward a principled approach to reordering documents by leveraging existing click models. specifically, we compute the preference probability that a lower ranked document is preferred to a higher ranked one from the click chain model, and propose to swap the two documents if the probability is sufficiently high. because ccm models positional bias and dependencies between clicks, this method readily accounts for many twisted heuristics that have to be manually encoded in sort based approaches. for this approach to be practical, we further devise two approximation schemes that make online computation of the preference probability feasible. we carried out a set of experiments based on real world data from a major search engine, and the result clearly demonstrates the effectiveness of the proposed approach. the task of learning to rank has emerged as an active and growing area of research both in information retrieval and machine learning. the goal is to design and apply methods to automatically learn a function from training data, such that the function can sort objects according to their degrees of relevance, preference, or importance as defined in a specific application. generating alternative queries, also known as query suggestion, has long been proved useful to help a user explore and express his information need. in many scenarios, such suggestions can be generated from a large scale graph of queries and other accessory information, such as the clickthrough. however, how to generate suggestions while ensuring their semantic consistency with the original query remains a challenging problem. in this work, we propose a novel query suggestion algorithm based on ranking queries with the hitting time on a large scale bipartite graph. without involvement of twisted heuristics or heavy tuning of parameters, this method clearly captures the semantic consistency between the suggested query and the original query. empirical experiments on a large scale query log of a commercial search engine and a scientific literature collection show that hitting time is effective to generate semantically consistent query suggestions. the proposed algorithm and its variations can successfully boost long tail queries, accommodating personalized query suggestion, as well as finding related authors in research. the explosive growth of web information has not only created a crucial challenge for search engine companies to handle large scale data, but also increased the di culty for a user to manage his information need. it has become increasingly di cult for a user to compose a succinct and precise query to present his search need. instead of pushing this burden to the users, it is common practice for a search engine to provide some types of query suggestions. this work was done when the rst author was on a summer internship at microsoft research. permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies bear this notice and the full citation on the rst page. to copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speci. when a user types a query msg to the search engines, he will be provided with quite a few alternative potential queries. for example, he will be suggested msg chinese food, msg health, and other names for msg by google, and msg error, msg network, and msg seating chart by yahoo. there are also other query suggestion mechanisms which could automatically complete a query, and automatically correct spelling mistakes. such query suggestion mechanisms are usually developed based on morphological information of queries, or cooccurrence of one query word with other queries. although suchquery suggestions are proved useful in di erent ways, there is usually no guarantee that the suggested queries convey close semantic information with the original query. indeed, it is usually annoying for a researcher who searches for chris burges but is suggested with chris burgess or chris burge ministries. similarly, it is not very helpful to suggest kdd with kbb, kddi, ntt, and harry shum with harry potter. people searching for larry page maybe interested in sergey brin but not yellow page. a good query suggestion system should consider a handful of features, but in most cases it is important to ensure that the semantics of the suggested query do not drift too much from the original one. some users will issue the query msg to search for the sports center in newyork and others use it to search the food additive. msr could mean microsoft research, but also mountain safety research, or even mortgage servicing rights. without the constraint of semantics, a general suggestion to such ambiguous queries would easily be. another big challenge and opportunity for the current query suggestion systems lies in the suggestion of infrequent queries. it has been a well known theory in business that a company could sell less of more by boosting the long tail of the power law distribution. the same question lies in searchengine business, especially in advertising where customers bid for query terms. frequently clicked queries cost more and long tail queries cost less. if a well designed query suggestion system could route the traf all real examples are collected on feb. http: search yahoo com searchchris burges http: search live com results aspxchris burges http: search live com results aspxkdd http: search live com results aspxharry shum. and boost the clickthrough of long tail queries, there is a huge opportunity to maximize thebene ts forboth a search engine company and customers of its advertising system. is there a principled way to suggest semantically similar queries while also boosting long tail queries can such a method also provide a natural solution to personalization it is challenging because semantics is hard to de ne and both long tail queries andpersonalization usually su er from data sparsity. in this paper, we propose a uni ed approach to query suggestion, by computing the hitting time on a large scale bipartite graph of queries and clickthrough. despite its simplicity, this novel approach introduces quite a fewbene ts to query suggestion: the suggestions generated with the proposed algorithm are semantically similar to the original query; the suggestions generated do not have to occur with the original query; this approachboosts the long tail queries as suggestions; and this model provides a natural treatment for personalized query suggestion. empirical experiments on a large scale query log of a commercial search engine, as well as a public available scienti. bibliography dataset show that our proposed algorithm is. ective for semantically coherent query suggestion, which provides a potential new framework, or an important and novel feature for building a real query suggestion system. the approach of using hitting time is quite general, which could provide potential solutions to many other search related problems other than query suggestion. the rest of the paper is organized as follows. in section #, we formally introduce the concept of hitting time on a bipartite graph. in section #, we propose the algorithm of query suggestion using hitting time. we show our experiments and results in section #, introduce the related work in section #, and conclude in section #. net ix spends millions to look for an. ective way to suggest hard to nd movies. this paper presents a novel approach for using clickthrough data to learn ranked retrieval functions for web search results. we observe that users searching the web often perform a sequence, or chain, of queries with a similar information need. using query chains, we generate new types of preference judgments from search engine logs, thus taking advantage of user intelligence in reformulating queries. to validate our method we perform a controlled user study comparing generated preference judgments to explicit relevance judgments. we also implemented a real world search engine to test our approach, using a modified ranking svm to learn an improved ranking function from preference data. our results demonstrate significant improvements in the ranking given by the search engine. the learned rankings outperform both a static ranking function, as well as one trained without considering query chains. query suggestion has been an effective approach to help users narrow down to the information they need. however, most of existing studies focused on only popular head queries. in this paper, we propose an optimal rare query suggestion framework by leveraging implicit feedbacks from users in the query logs. our model resembles the principle of pseudo relevance feedback which assumes that top returned results by search engines are relevant. however, we argue that the clicked urls and skipped urls contain different levels of information and thus should be treated differently. unlike the rocchio algorithm, our learning process does not involve the content of the urls but simply leverages the click and skip counts in the query url bipartite graphs. experimental results on one month query logs from a large commercial search engine with over million rare queries demonstrate the superiority of our framework, with statistical significance, over the traditional random walk models and pseudo relevance feedback models. since rare queries possess much less information than popular queries in the query logs, it is much more difficult to efficiently suggest relevant queries to a rare query. hence, our framework optimally combines both the click and skip information from users and uses a random walk model to optimize the query correlation. our model specifically optimizes two parameters: the restarting rate of random walk, and the combination ratio of click and skip information. consequently, our model is capable of scaling up to the need of commercial search engines. web search engines have completely changed the way people acquire information during the last ten years. by providing a comprehensive portal between the internet users and the web, search engines are able to take a user query and return a ranked list of web pages according to the relevance between queries and the search engine index, which consists a subset of the entire web. the reason of failure is that the length of the queries is usually quite short, so that understanding user intents correctly has been a critical yet quite di cult task for search engines. among a variety of techniques, query suggestion related techniques have become an. among all query suggestion techniques, one of the most important and. speci cally, query logs are server end logs that record user activities in search engines. a typical query log entry contains timestamp, query, clicked urls as well as user personal information. in order to learn a query suggestion model, a commonly used approach is to leverage graph representation which forms query and url relationship into bipartite graphs. the edge between a queryand a urlindicates user clicks ofwhen issuing. as a matter of fact, a myriad of techniques have been proposed. while for rare queries that have only appeared a handful of times in the logs with very few clicks, click graph is unable to capture the underlying relationship between queries. for example, in figure #, and do not have commonly clicked urls, thus a random walk queries urls queries urls audipartstore com audipartstore com audiusa com audiusa com audi parts audi parts audirepair autorepairlocal com audirepair autorepairlocal com audi bodywork nwaaudidealers com audi bodywork nwaaudidealers com audi en wikipedia org wiki audi en wikipedia org wiki audi audi click graph skip graph figure #: an illustrative example of query url click graph and skip graph. while it is well known that in search engines, query frequencies follow a power law distribution where most queries are issued very few times by users, rare queries together constitute a great amount of search tra. ects the relevance and revenue of search engines signi cantly. motivation of our work figure # presents a motivation of our approach. ideally, audi parts should be a good suggested query for audi bodywork. however, after performing a random walk on the click graph, only the query audi can be suggested to audi parts because there is no commonly clicked urls between audi parts and audi bodywork so that their correlation is zero. however, if we leverage the top skipped urls for audi parts and audi bodywork as shown in figure #, it can be clearly observed that both queries skipped their top returned two urls: nwaaudidealers com and en wikipedia org wiki audi. however, for rare queries, many times the top skipped urls contain di erent levels of information than the clicked urls. because top returned urls are more likely to have high static rank scores which are representative of the highlevel topic that the query belongs to. eg, the url is a general entry about audi, while queries audi parts and audi bodywork address di erent aspects of user need of the speci. although users who issued these two queries clicked on more speci. ers a potential topic link between these queries. so if a user clicked the rd ranked url, then the st and nd urls are said to be skipped. fully analyzed query logs from a commercial search engine. figure # shows user session statistics in one of the data sets we use in the experiment which contains million unique queries. the gure compares the query frequency against the number of clicked and skipped urls. it can be observed that when the query frequency is low, more urls are skipped than clicked during the same user session. generally, users are tend to click more often on top returned results for popular queries, while for rare queries, the clicks are more random and thus have higher entropy scores. we further analyzed the quality of skipped urls for rare queries. figure # demonstrates the comparative ratings between skipped and clicked urls. overall, skipped urls indicate a little bit less relevance than clicked urls. this observation further supports our claim that skipped urls should be leveraged for rare queries in the context of relevance measurement. finally, combine two query correlation matrices to form the optimal query correlation matrix, which is used for query suggestion. url skipped url clicked urls clicked urls skipped of urls of urls year# year# query frequency query frequency average url rating figure #: number of urls clicked vs. number of urls skipped in the same user sessions from one week search log. there are more urls skipped than clicked for queries with lower frequencies. in pseudo relevance feedback models, this ratio is the same for both clicked and skipped urls, which is not optimal in practice for rare queries, as we shall see in the empirical analysis. recent study indicates that search is still quite di cult, approximately of times search engines fail to return relevant documents. ective way to interact between users and search engines, hence to improve the relevance of search results. a query url bipartite graph usually consists of two disjoint sets of nodes, corresponding to queries and urls respectively. an example of this bipartite representation has been shown in figure #, where the left hand set of nodes are queries and the righthand set are urls. the click graph possesses large amount of potential information that can be learnt for query suggestion, query clustering, query reformulation and so on. among them, random walk technique is one of the most. however, leveraging only the click information has a serious drawback. that is, the models learnt from click graph can only bene. popular queries which possess enough user click feedbacks. query audi parts and audi bodywork are not correlated if only performs random walk on the click graph, but will be highly correlation if random walk is performed on the skip graph. model which discovers query relationship according to their common clicks is unable to discover any correlation between and. ective proposals to deal with rare queries needs our immediate attentions. the left gure shows the click graph for three queries and ve urls that returned as top serp results. as a result, a random walk on the skip graph will assign a high correlation score to these two queries. our work is inspired by the principle of pseudo relevance feedback which assumes that the topk returned documents from search engines are always relevant to the queries, regardless of whether they are clicked or not. to further back up our argument regarding using both clicked and skipped urls for rare query suggestion, we care we de ne a url to be skipped if it was viewed by the user without being clicked. however, with the increase of query popularity, the click patterns become more stable. we selected, queries which have been issued less than times within a week and asked human judgers to judge the relevance on a scale. on average, clicked urls have a rating of while skipped urls have. contribution of this paper in this paper, we propose a novel graph combinationbased rare query suggestion framework. first, how to choose the optimal restarting rate for the random walk second, given two query url correlation matrices, how to optimally combine them the reason is that the restarting rate directly. ects the transition probability of random walk from nodes to nodes, which. ects the distribution of query relevance scores that is critical for determining the most relevant neighbor nodes. on the other hand, the combination rate decides the level of contributions from click and skip graphs respectively. to the best of our knowledge, we are among the rst to address the importance of the restarting rate of random walk, and optimize the parameter in a principled way. in other random walk like models, this rate is either pre xed, or empirically chosen without any support information. the rest of the paper is organized as follows: section # presents the literature in query suggestion, query clustering related research; section # introduces our framework for optimal rare query suggestions; section # provides empirical results on the performance of our model; nally, section # concludes our proposal with future work. existing work on mining such data has mostly attempted to discover knowledge at the level of queries. these two patterns can be used to address the mis specification and under specification problems of ineffective queries. experiment results on real search engine logs show that the mined context sensitive term substitutions can be used to effectively reword queries and improve their accuracy, while the mined context sensitive term addition patterns can be used to support query refinement in a more effective way. search engine logs are an emerging new type of data that offers interesting opportunities for data mining. in this paper, we propose to mine search engine logs for patterns at the level of terms through analyzing the relations of terms inside a query. we define two novel term association patterns and propose new methods for mining such patterns from search engine logs. such search engine logs contain a lot of valuable information such as patterns of query reformulation. thus the huge amount of search engine log data. indeed, mining search engine logs has recently attracted much attention. all these permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies bear this notice and the full citation on the rst page. to copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speci. studies have shown the promise of improving search accuracy through mining search engine logs. however, virtually all the previous work has treated a whole query as a unit for analysis; as a result, the discovered knowledge is mostly at the level of queries. existing query suggestion works such as and also consider a whole query as a unit and they further rely on other resources such as web snippets or human labeled training data to generate related queries. furthermore, most of the work only suggests related queries and does not consider the. a query is ine ective due to multiple reasons, but two of them are common: mis speci cation and under speci cation. the mis speci cation problem is caused by the fact that there may be multiple ways of expressing the same idea or describing the same thing, and a user may not know what exact terms have been used by the authors of the documents to be searched. for example, if a user wants to nd a place to wash his her vehicle, a good query would be car wash. this is because in most relevant web pages, the authors used car wash rather than vehicle wash or auto wash. this is an example of what we refer to as a contextsensitive term substitution pattern. the under speci cation problem in a query may be because the user does not know much about the content to be found or can not naturally think of additional speci. in such a case, it would be useful to suggest terms such as insurance and sale for a user to choose so as to make the query more discriminative. in order to do this, we need knowledge of the form insurance auto quotes and sale auto quotes. in this paper, we rst formally de ne the two novel term association patterns in search logs context sensitive term substitution and addition patterns. then we propose new probabilistic methods to discover these patterns through analyzing term co occurrences in query logs. such terms tend to co occur with the same or similar terms; for example, both auto and car often occur together with rental, pricing, etc. we propose to use probabilistic translation models for capturing quasi synonyms. for example, car and insurance often co occur in the queries and they can help each other to re ne a topic car insurance can be used to re ne both car and insurance. we propose to use probabilistic contextual models for capturing contextual terms. based on both translation models and contextual models, we cast our context sensitive term association pattern mining as probability estimation problems. patterns with high probabilities are with high con dence and then used for query reformulation. for example, car has a high probability in the translation model of auto and high probability to co occur with wash in contextual models, then the pattern auto car wash will have a high probability and thus is a pattern with high con dence. ectiveness of our proposed algorithms, we conduct experiments on a sample of search logs. these show that our proposed methods can discover useful knowledge based on the term relations inside queries. our methods are totally orthogonal to, and thus can be enhanced by, other techniques which use other information such as click through and user session data for query suggestions. the rest of the paper is organized as follows. we rst review the related work in section #. then we formally de ne our mining problem in section # and propose our models to discover term association patterns in section #. our search log data collection is described in section # and the experiments are presented in section #. finally we conclude this paper and discuss future work in section #. as search engines are being used, they naturally accumulate a lot of log data, including submitted queries, viewed search results, and clicked urls. in general, a web search engine answers millions of queries every day. for example, clustering search queries is studied in. the similarity of queries can be measured by the clicked documents or their temporal correlations. ectiveness of the suggested queries, which is very crucial for successful query suggestions. in this paper, we look into patterns at the level of terms through analyzing the relations of terms inside a query and use the discovered term association patterns for. our work is motivated from the following observations about what types of knowledge are useful to help a user formulate an. if the user uses a query such as auto wash or vehicle wash, the search results are generally not as good as those from using the query car wash even though all these queries have roughly the same meaning. in order to help a user in such a case, we need knowledge of the form auto car wash. for example, a query such as auto quotes can return mixed results with some about automobile insurance quotes and some about automobile sale prices. this is an example of what we refer to as a context sensitive term addition pattern. our basic idea is to analyze the co occurrences of terms within multi word queries in logs and obtain two kinds of term relations: quasi synonyms and contextual terms. quasi synonyms are words that are synonyms or that are syntactically substitutable. experimental results on the real search engine logs show that our proposed methods can. ectively mine term association patterns and all these patterns can be used for. the language modeling approach to retrieval has been shown to perform well empirically. one advantage of this new approach is its statistical foundations. however, feedback, as one important component in a retrieval system, has only been dealt with heuristically in this new retrieval approach: the original query is usually literally expanded by adding additional terms to it. such expansion based feedback creates an inconsistent interpretation of the original and the expanded query. in this paper, we present a more principled approach to feedback in the language modeling approach. specifically, we treat feedback as updating the query language model based on the extra evidence carried by the feedback documents. such a model based feedback strategy easily fits into an extension of the language modeling approach. we propose and evaluate two different approaches to updating a query language model based on feedback documents, one based on a generative probabilistic model of feedback documents and one based on minimization of the kl divergence over feedback documents. experiment results show that both approaches are effective and outperform the rocchio feedback approach. the language modeling approach to text retrieval was first introduced by ponte and croft in and later explored in. in this paper, we propose a model based approach to feedback that can be incorporated into the kl divergence retrieval framework introduced in. the model based approach to feedback is actually not new; indeed, it is the essence of the classical probabilistic model. however, it has been unclear how to incorporate model based methods into the query likelihood ranking function used in most existing work on the language modeling approach. we propose two different schemes for reestimating the query model based on a set of feedback documents: a generative model. assuming a generative model, we estimate the query topic model using the observed feedback documents based upon a maximum likelihood or regularized maximum likelihood criterion. the particular generative model we consider here is a simple mixture model, using the collection language model as one component, and the query topic model as the other.