entity linking deals with identifying entities from a knowledge base in a given piece of text and has become a fundamental building block for web search engines, enabling numerous downstream improvements from better document ranking to enhanced search results pages. a key problem in the context of web search queries is that this process needs to run under severe time constraints as it has to be performed before any actual retrieval takes place, typically within milliseconds. second, we leverage hashing and compression techniques to reduce the memory footprint. finally, to equip the algorithm with contextual knowledge without sacrificing speed, we factor the distance between distributional semantics of the query words and entities into the model. we show that our solution significantly outperforms several state of the art baselines by more than while being able to process queries in sub millisecond times at least two orders of magnitude faster than existing systems. in this paper we propose a probabilistic model that leverages user generated information on the web to link queries to entities in a knowledge base. there are three key ingredients that make the algorithm fast and space efficient. first, the linking process ignores any dependencies between the different entity candidates, which allows for a implementation in the number of query terms. such linking has to be performed on a very limited time and space budget as it needs to happen before any actual search process commences. ciency aspects of linking systems are not a focal point in the literature. the remainder of this paper is organized as follows. section # presents experiments and results comparing our approaches with state of the art baselines in terms of linking quality and speed. one critical step in this process is understanding the entities that are mentioned in queries and linking them to a reference knowledge base. linking free text to entities often referred to as entity linking typically comprises three steps: identifying candidate mentions, ie, which part of the text to link, identifying candidate entities for each mention, and disambiguating the candidate entities based on some notion of context and coherence. queries, on the other hand, are short, noisy, and full of shorthand and other ungrammatical text, and provide very limited context for the words they contain. in this paper we propose a new probabilistic model and algorithm for entity linking in web search queries that extracts a large number of candidate aliases for entities from click through information and anchor text. in order to keep these large amounts of data manageable, we compress all candidates using state of the art hashing and bit encoding techniques. this way, the algorithm is able to link entities with just a forward backward scanning procedure that can be implemented. ciently using dynamic programming in, whereis the number of query terms. section # reviews some works related to ours. commercial web search engines are presenting increasingly advanced and rich user experiences that include displays of answers, facts, entities, and other structured results. such web search user experiences are centered around understanding and displaying information pertinent to entities present in or meant by the query, since users increasingly expect to nd the actual answers and or entities that satisfy their information need, rather than merely the documents that mention them. recent research has made exten sive use of open kbs or entity repositories such as freebase, imdb, wikipedia, as well as private or proprietary ones. most linking methods from the literature, however, assume that the input text is relatively clean and grammatically correct and that it provides su cient context. hence, it is not obvious that automatic entity linking methods that have been shown to work well on news articles or web pages perform equally well on this domain. entity linking for web search queries poses some interesting technical challenges due to the sheer volume of the data, its dynamic nature, the creative language usage, and the required tradeo. entity linking for queries has not received considerable attention in the literature, except for type spotting for named entity recognition, linking queries to semantic web concepts, and providing a full structured representation of the query. our algorithm is able to swiftly detect the entities in the query because we drop all the dependence assumptions from potential candidate entities. in practice, this means that the model might not able to distinguish between situations such as brad pitt seven and brad pitt olympics if they are not present in our alias set however, we are able to impose contextual knowledge by introducing a new contextual relevance model that uses learned representations of query words and entities, and it is able to quickly compute a relevance measure between a string of text and an entity. section # intro duces the probabilistic model, along with the contextual model. we present a recommendation method based on the well known concept of center piece subgraph, that allows for the time space efficient generation of suggestions also for rare, ie, long tail queries. our method is scalable with respect to both the size of datasets from which the model is computed and the heavy workloads that current web search engines have to deal with. basically, we relate terms contained into queries with highly correlated queries in a query flow graph. this enables a novel recommendation generation method able to produce recommendations for approximately of the workload of a real world search engine. the method is based on a graph having term nodes, query nodes, and two kinds of connections: term query and query query. the first connects a term to the queries in which it is contained, the second connects two query nodes if the likelihood that a user submits the second query after having issued the first one is sufficiently high. on such large graph we need to compute the center piece subgraph induced by terms contained into queries. in order to reduce the cost of the above computation, we introduce a novel and efficient method based on an inverted index representation of the model. we experiment our solution on two real world query logs and we show that its effectiveness is comparable than state of the art methods for head queries. more importantly, the quality of the recommendations generated remains very high also for long tail queries, where other methods fail even to produce any suggestion. finally, we extensively investigate scalability and efficiency issues and we show the viability of our method in real world search engines. much of the literature on query recommendation is devoted topropose novel methods, or models, that enhance. although this is, clearly, a fundamental issue, the other side of the coin,ciency, has indeed been poorly addressed by the research community. the key idea behind query recommendation is that of exploiting the socalled wisdom of the crowds, ie, the knowledge mined from search engine query logs which store all the past interactions of users with the search system. ective when the information need of the user is a popular one, ie, the same query has been been frequently submitted by other users in the past. using common wording, these queries are head queries indicating that they are usually appearing in the head of the power law like curve typical of query popularity distribution. in this paper we introduce a novel recommendation method based on computing the center piece subgraph on a large graph model. our solution presents several enhancements with respect to the state of the art. it is scalable as the generation of the model is easily parallelizable and the model itself can be stored in a compressed form. furthermore, we represent the model in an inverted index and we show that several engineering practices used for inverted indexes are inherited by our model as well. the inverted index representation has several advantages as, for instance, the possibility of exploiting the existing index processing infrastructure of search engines with small, or no, modi cations. the suggestions generation time, also, is comparable to that taken by the query processing phase. thus, generating recommendations does not represent a bottleneck even when rare, uncached queries are processed. even if the main goal of this paper is that of designing an. cient and implementable system, we show that the quality of its suggestions is comparable with respect to state of the art method, query ow graph. interestingly, the quality of the suggestions produced by our system is stable, almost independently of the frequency of the query in the query log used to learn the model. this is a key property which does not hold for the query ow graph. query ow graph is, indeed, not able to generate suggestions for previously unseen or rare queries. more in details, our method is based on a graph model that we dub tqgraph. a tqgraph extends the well known query flow graph by considering two distinct sets of nodes: term and query nodes. arcs connect a term node to all the query nodes containing it, while arcs between two query nodes expresses the likelihood that a user submits the second query after having issued the rst one. we design such a structure so that we are able to generate recommendations for a query by extracting the center piece subgraph associated with terms of the query itself. it is important to remark that since we do not require a query to be present in the tqgraph, but only its terms, our method is able in principle to provide recommendations even for a never seen before query. it is this term centric perspective that allows us to provide a framework enabling suggestions to be. finally, let us resume the original contributions of this paper: a novel method for query recommendation based on center piece graph computation over the tqgraph model. being term centric, our center piece based method does not su er from the problem of sparsity of queries, being able to generate suggestions for previously unseen queries as far as terms have been previously seen. empirical assessment con rms that our method is able to generate suggestions for the vast majority of queries and with a quality that is comparable to the state of the art method based on query flow graph. ectiveness our method, we are faced with its major but only apparent drawback: any suggestion pass through the computation of the center piece subgraph from query terms. given the very large size of the underlying graph, this task is clearly unfeasible for any system claiming to be realtime. we overcome to this limitation by introducing a novel and. this comes at the small cost of storing precomputed vectors that need to be opportunely combined to obtain the nal results. the data structure we use is inverted list based and thus it is particularly suitable for web search environments. the inverted list based data structure is compressed by using a lossy compression method able to reduce by an average of the space occupancy of the uncompressed data structures. furthermore, caching is exploited at the term level to enable scalable generation of query suggestions. being term based, caching is able to attain hit ratios of approximately with a reasonable footprint furthermore, since the compression method is lossy, we have evaluated through a user study the loss in terms of suggestion quality, and we have found that this loss is negligible. we can claim that our method a preliminary presentation of the idea of the tqgraph, was given in a poster at www by the same authors: http: www www india com proceeding companion pdf. ective also when a very aggressive lossy compression strategy is applied. it should be noted that the last two research results, beyond enabling our model to be real time, represent a more general achievement for what concerns the computation of centerpiece subgraphs in very large graphs. section # details the tqgraph model and presents the methods used to compute suggestions. in section # we assess the quality of the recommendations computed by our method and we compare our results with stateof the art qfg. sections and present and experimentally evaluate our scalability and. finally, in section #, we discuss future work and conclude. we study the problem of anticipating user search needs, based on their browsing activity. given the current web pagethat a user is visiting we want to recommend a small and diverse set of search queries that are relevant to the content of, but also non obvious and serendipitous. we introduce a novel method that is based on the content of the page visited, rather than on past browsing patterns as in previous literature. our content based approach can be used even for previously unseen pages. we represent the topics of a page by the set of wikipedia entities extracted from it. to obtain useful query suggestions for these entities, we exploit a novel graph model that we call eqgraph, containing entities, queries, and transitions between entities, between queries, as well as from entities to queries. we perform personalized pagerank computation on such a graph to expand the set of entities extracted from a page into a richer set of entities, and to associate these entities with relevant query suggestions. we develop an efficient implementation to deal with large graph instances and suggest queries from a large and diverse pool. we perform a user study that shows that our method produces relevant and interesting recommendations, and outperforms an alternative method based on reverse ir. exploring the web is often a serendipitous experience, where users with no pre existing search ob jective meander from topic to topic, sometimes discovering unexpected, sur this work was done while the author was at yahoo research barcelona. permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies bear this notice and the full citation on the rst page. to copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speci. figure #: example of a suggestion produced by our method in our experiments: when reading the wikipedia page about machu picchu, a pre columbian inca site in peru, we suggest to the user a query about rafting the urubamba, the river that ows in the valley where machu picchu is located. such serendipitous search encounters can be extremely enriching for the users, as they may stimulate their thinking to arrive to particular creative insights. in this scenario, it is interesting to analyze the class of web search queries that are triggered by the content of a previously read web page. for example, while reading a news article about the year# presidential election results in france, the user might want to read more about the new president and his nancial policies, thus issuing a query such as francois hollande nancial policies. figure # shows a real example from our experiments. in this paper we tackle the problem of anticipating such newly created information needs. more concretely, given the current web pagethat a user is visiting we want to recommend a small and diverse set of search queries that are relevant to the content of, non obvious and serendipitous. observe that this problem is not just a web search problem in reverse, as we are not trying to identify queries that would lead to the pagebeing ranked highly in the result list. such queries are mostly obvious given the content of the page, and this is not desirable for our application. our goal is to identify queries that stem from the page, rather than queries that lead to the page. the problem of understanding users intent and supporting them in the formulation of web search queries has been studied extensively over the last years. however, the standard problem studied is that of recommending new related queries that re ne a given search query. in other terms, in the traditional context it is assumed that the user has already explicitly given an indication concerning her intent through a web search query. in this perspective the provided recommendations are passive, in the sense that they only come after a user has submitted one or more queries to a search engine. the reasons behind these queries and what triggered the information need are not taken into account. instead, in the scenario we consider in this paper, the user does not need to formulate a query that represents explicitly an information need. the idea is that the user is picked up at an earlier stage during the search process, when she is reading a web page and, potentially, she has not even yet conceived the thought of issuing a web search query at all. the motivation for considering such a scenario is that many information needs of web users are actually triggered by what they browse. this particularly holds for informative pages, such as news and blogs: whenever a user nds something interesting or unclear while reading a page, she might want to go deeper in the matter and, to obtain further information, she might formulate a query. a recent work by cheng et al has proposed to exploit data gathered from search logs and browsing logs to actively predict users query intent based on the web pages they browse. the model proposed by cheng et al is based on the frequent patterns of transitions. the basic idea is that of exploiting the wisdom of the crowd: if after visiting a particular page, many users continue with the same query then the original page is likely to trigger the query. one main limitation of this approach is that, being based on frequent patterns, it is more. ective for popular pages that have been seen many times by many di erent users, while it is inherently inapplicable to previously unseen pages. unfortunately, as discussed above, the kind of pages that are more likely to be an interesting playground for these recommendations are informative pages which are very dynamical in nature and usually have a short life: from few hours to few days. therefore it is important to develop methods for recommending queries even for new pages. in this paper we tackle such a goal, by focusing on the content of pages. in particular, given any web page, we build a succinct representation of its subject matter by extracting the main concepts described or discussed in it, in the form of wikipedia entities. with the aim of obtaining relevant and interesting query recommendations for the entities contained in a page, we devise a novel graph model, which we call eqgraph. our model extends the well known query flow graph. it consists of two distinct sets of nodes, namely wikipedia entity nodes and query nodes, and three di erent sets of arcs: entity entity, query query, and entity query. the query query connections are akin to their counterpart in the query flow graph: the presence of a directed arc between two query nodes indicates a su ciently high likelihood of submitting the second query after having issued the rst one. in the eqgraph each entity is connected to all the queries that contain it. finally, the entity entity transitions are equivalent to query ow transitions at the conceptual level of entities. we draw a directed arc between two entities if a user who issued a query related to the rst entity is likely to search for the second entity. we derive these entity entity transitions from the query ow transitions by aggregating transitions that are related to the same entities. we leverage the eqgraph to recommend interesting queries for web pages. we start from the seed set of entities contained in the page. to ensure that the seed set contains a su ciently large number of concepts, we expand the initial set of entities by performing personalized pagerank computations in the subgraph of the eqgraph induced by all the entity nodes. in the eqgraph, the entities of interest for a page are connected to the queries that contain them. however, we do not build our nal query recommendations for the page by simply looking at these queries. instead we perform a personalized pagerank computation for the expanded set of entities in the full eqgraph. we could use a textual representation of the entities to provide synthetically generated queries. however, we decide to employ real queries to leverage the wisdom of the crowd. the eqgraph naturally captures this intuition: if two entities are related, there will likely be a query that is pointed by both entities. for our experiments, we have built an instance of the graph containing several hundreds of millions nodes and arcs. running personalized pagerank computations on such a large graph is potentially a serious performance bottleneck of our query recommendation method. cient and scalable manner, we develop a giraph implementation of the personalized pagerank algorithm. giraph is a hadoopbased framework for running graph algorithms on large scale data in parallel by distributing the load on a large number of computers. it is based on the bulk synchronous parallel model of computation. we test our method on a large eqgraph extracted from a recent sample of a yahoo query log. we produce query recommendations for a set of pages sampled from wikipedia, yahoo news and yahoo finance. we evaluate the quality of the produced recommendations by performing a user study, and nd that our method produces relevant and non obvious suggestions. the main contributions of this paper are the following: we introduce the eqgraph as a novel object. this object enriches the standard query flow graph with entity nodes. we describe this graph in detail as it has interesting properties in its own right and could be applied to other problems. we present a novel method for anticipating information needs that arise from the content of pages that people are browsing. our method is based on personalized pagerank computation over the eqgraph. we use wikipedia entities to represent the information items contained in web pages. by leveraging entities, our model is able to generate query recommendations for previously unseen pages. we develop a giraph implementation of the personalized pagerank algorithm, which could be useful for many other applications. we perform a user study that shows that our recommendations are relevant for the content of the page, and that our method based on the eqgraph outperforms an alternative baseline based on reverse ir. the rest of this paper is organized as follows. section # introduces the basic concepts for the eqgraph, which is then http: giraph apache org presented in section #. section # describes how we extract entities from pages and queries, how we expand the initial set of entities extracted from a page, and how we produce the suggestions. in section # we assess the quality of the recommendations produced by our method via a user study. section # reviews related literature and section # concludes. queries that are pointed by multiple entities are more likely to be interesting because they are at the intersection of different topics in a page. cient implementation that can deal with very large graphs. we found that over of patterns and of instance annotations tested are judged to be correct by a majority of annotators. one popular form of semantic search observed in several modern search engines is to recognize query patterns that trigger instant answers or domain specific search, producing semantically enriched search results. this often requires understanding the query intent in addition to the meaning of the query terms in order to access structured data sources. a major challenge in intent understanding is to construct a domain dependent schema and to annotate search queries based on such a schema, a process that to date has required much manual annotation effort. we present an unsupervised method for clustering queries with similar intent and for producing a pattern consisting of a sequence of semantic concepts and or lexical items for each intent. furthermore, we leverage the discovered intent patterns to automatically annotate a large number of queries beyond those used in clustering. we evaluated our method on selected domains, discovering over year# intent patterns and automatically annotating queries. modern search engines are moving beyond this paradigm by more deeply analyzing the structure and semantics of search queries. these instant answers understand and directly address the information need of the user, obviating the step of clicking into and searching through an external document. one key issue for these applications is to connect the surface level query to a structured data source according to the intent of the user. doing so requires an intent understanding system, which makes use of a schema. we de ne a schema as consisting of a domain, a set of domain dependent intents, and slots or concepts. slots are often assumed to be shared among di erent intents in the same domain. the rst component can be viewed as identifying a coarse semantic class of query intent to limit the hypothesis space of the following components. next, intent detection and slot lling aim at nding more ne grained user intents within the domain of interest and extracting the slots related to that intent. the last two components are tightly coupled and are often modeled jointly. another approach is to use statistical models to classify queries by intent and to label sequences for slot lling. although semi supervised methods have been developed to reduce this cost, a reasonably large amount of labeled data is still needed as seeds to bootstrap learning. furthermore, by relying on a prede ned schema, both methods are susceptible to biases which can result in a mismatch to a userreal information need. for example, in the products domain, databases often contain elds like serial number which are rarely queried by users or used as search criteria. our approach discovers patterns that cover up to of the tra. within a domain, and this number can be easily adjusted at the cost of precision. in the traditional ir model of search, a search engine is responsible for returning documents relevant to a search query. ranking algorithms using surface level word statistics have been developed which have made keyword search the dominant form of web search today. doing so can not only improve ranking results, it can also allow domaindependent types of semantically enriched search results to be displayed in addition to the standard ranked list of relevant documents. for example, a search query that matches the pattern weather would trigger a weather forecast for that city, while one that matches showtimes would return an appropriate list of showtimes at cinemas near the speci ed location. a related trend is the development of structured search, which allows precise search within a domain. structured search requires a query understanding component to extract structured information that is matched with a back end database. a query may be in the form of a keyword search, which is relatively unstructured with free word order, such as hotel seattle february. or, a query may be in a more natural language form, as is often the case with virtual assistant applications on mobile devices. these applications take a voice command from a user, such as book a reservation at an italian restaurant for tonight, then perform the desired action, or automate a substantial portion of it, such as by lling in an online reservation form. given a schema, an intent understanding system consists of the following: domain classi cation, intent detection, and slot lling. for example, harry potter showtimes boston should be classi ed into the movie domain with the intent findshowtimes and slots including title harry potter and location boston. there have been two major approaches to doing schema discovery to enable such an intent understanding system. the rst is to use a grammar based approach, de ning rules in a domain and matching queries to these prede ned rules, often based on the schema of the back end database. while such an approach may work for simple domains and intents such as accessing weather reports, it is di cult to scale up to a larger number of domains. in addition, manually crafting grammar rules imposes a high cognitive load on humans and is often imprecise. while this eliminates the need to specify rules, it still requires, in addition to the prede ned schema, much annotation. ort in the form of labeled data to train supervised machine learning models. human designed schemata generally do not cover all intents and their associated slots; search engines to date know how to semantically interpret a subset of user requests that are popular or important like weather, but there are many more that are yet to be understood and answered. the goal of this work is to discover popular user intents and their associated slots, and to annotate query instances accordingly in a completely unsupervised manner. as in, we de ne intent as represented by a pattern or template consisting of a sequence of semantic concepts or lexical items. continuing the above example, a pattern that describes harry potter showtimes boston would be showtimes, and other queries that would be annotated with the same pattern might include madagascar showtimes sydney or planet of the apes showtimes london. we present a sequence clustering method for nding such clusters of queries with similar intent, and an intent summarization method for labeling clusters with such an intent pattern that describes the queries in the cluster. as such, our system not only discovers the patterns and slots in a domain, it also produces annotated instances of each pattern, and allows classi cation of new queries not used in clustering into the discovered patterns. figure # shows the components of our system. we evaluate our methods using mechanical turk judgments, and nd that over of patterns and over of instances within a pattern are correct according to a majority of judges. it can thus facilitate structured search, and is an important step toward fully automating query intent understanding. when generating query recommendations for a user, a natural approach is to try and leverage not only the user most recently submitted query, or reference query, but also information about the current search context, such as the user recent search interactions. we focus on two important classes of queries that make up search contexts: those that address the same information need as the reference query, and those that do not. we analyze the effects on query recommendation performance of using contexts consisting of only on task queries, only off task queries, and a mix of the two. using trec session track data for simulations, we demonstrate that on task context is helpful on average but can be easily overwhelmed when off task queries are interleaved a common situation according to several analyses of commercial search logs. to minimize the impact of off task queries on recommendation performance, we consider automatic methods of identifying such queries using a state of the art search task identification technique. our experimental results show that automatic search task identification can eliminate the effect of off task queries in a mixed context. we also introduce a novel generalized model for generating recommendations over a search context. while we only consider query text in this study, the model can handle integration over arbitrary user search behavior, such as page visits, dwell times, and query abandonment. in addition, it can be used for other types of recommendation, including personalized web search. query recommendation is a common tool used by search engines to assist users in reformulating queries. when an information need, or task, requires multiple searches, the sequence of queries form a context around which new queries can be recommended. figure # illustrates a series of queries issued by a user consisting of two tasks: nding information about the history of black powder rearms and preparing for the gmat standardized test. given this sequence, our goal is to generate a list of query suggestions with respect to the most recently submitted query, or reference query, which is black powder inventor in this example. notice, however, that the user has interleaved the two tasks such that no two adjacent queries are part of the same task. if we use the entire context to generate recommendations, two of the queries will be. task with respect to the reference query and three will be on task. while previous work has considered task aware query recommendation over logged user data, we are not aware of any work that systematically explores the. ects of on task, task, and mixed contexts on recommendation performance. figure # shows the likelihood of seeingtasks in any sequence ofqueries, eg, query sequences typically consist of search tasks. this means that a context consisting of the most recentqueries is very likely to consist of sub contexts for several disjoint tasks, none of which may be a part of the same task as the reference query. the goal of this paper is to better understand the. ects of on task, task, and mixed contexts on query recommendation quality. we also present and analyze several methods for handling mixed contexts. we address four questions concerning query recommendation: rq. ect query recommendation performance in a mixed context using only the reference query, using the most recentqueries, or using the most recentqueries with same task classi cation scores to weight the in uence of each query. to answer these questions, we perform a number of experiments using simulated search sequences derived from the trec session track. for recommendation, we rely on random walks over a query ow graph formed from a subset of the year# aol query log. we measure query recommendation performance by the quality of the results returned for a recommendation, focusing primarily on mean reciprocal rank. our results show that on task context is usually helpful, while. however, automatic search task identi cation is a reliable way of detecting and discarding. there are four primary contributions of this paper: an sequence length figure #: the distribution of seeingtasks in a sequence ofqueries as observed in a labeled sample of the aol query log. analysis of task aware query recommendation demonstrating the usefulness of on task query context, an analysis of the impact of automatic search task identi cation on taskaware recommendation, in which we show the state of the art works very well, an open source data set for evaluating context aware query recommendation, and a generalized model of combining recommendations across a search context, regardless of the recommendation algorithm. we present methods to automatically identify and recommend sub tasks to help people explore and accomplish complex search tasks. although web searchers often exhibit directed search behaviors such as navigating to a particular website or locating a particular item of information, many search scenarios involve more complex tasks such as learning about a new topic or planning a vacation. these tasks often involve multiple search queries and can span multiple sessions. current search systems do not provide adequate support for tackling these tasks. instead, they place most of the burden on the searcher for discovering which aspects of the task they should explore. particularly challenging is the case when a searcher lacks the task knowledge necessary to decide which step to tackle next. in this paper, we propose methods to automatically mine search logs for tasks and build an association graph connecting multiple tasks together. we then leverage the task graph to assist new searchers in exploring new search topics or tackling multi step search tasks. we demonstrate through experiments with human participants that we can discover related and interesting tasks to assist with complex search scenarios. search engines are the primary means by which people locate in formation online and complete search tasks. queries issued to search engines have be categorized as navigational, informational or transactional. this particular categorization has been useful for characterizing high level information search behavior and guid ing the development of appropriate support. however, as the range of tasks that are possible online grows, more complex search activi ties, such as exploratory search, and multi step search tasks have been identified. in exploratory search, people seek to learn about a topic of interest or discover new information. in multi step search tasks, searchers attempt to fulfill a complex information need involving multiple steps. despite some trials, search en gines today do not adequately support either of these scenarios. for searchers who are either unfamiliar with their problem domain, un familiar with the process to achieve their goal, or who lack a well defined goal, there is a pressing need for assistance in their search process. when attempting such tasks, searchers require support that extends beyond a list of search results. they need task completion systems that provide assistance by, among other things, outlining the necessary steps to explore or accomplish a complex task. some previous attempts have been made to support people engaged in complex tasks by allowing them to take notes and record results that they already examined, or to provide task continuation as sistance, whereby the search engine can predict that a searcher is likely to resume a task and hence preemptively save and retrieve the current search state on the searcherbehalf. while these are good ways to support long term tasks, they do not help searchers directly explore or identify potential next steps for their tasks. other research efforts have focused on building tours or trails to guide the searcher through their search process. while useful, the methods proposed to date have involved restricted domains or hy pertext corpora rather than web search, or have retrieved fo cused trails of urls rather than lists of search results. other attempts have been made to augment browsing with serendipity, but have been limited to social media or to named entities. in this paper, we present and evaluate methods to automatically identify and recommend tasks that allow searchers to explore and accomplish complex search tasks. we identify these suggestions by mining query logs from a popular commercial search engine to first identify complex tasks, and then automatically generate a graph connecting sub tasks that are likely to have common interest from searchers. in doing so we learn from the aggregated activity of many searchers and apply this collective knowledge to assist others with similar search objectives. our focus is to identify that a searcher is engaged in a complex search task and to help them explore different sub tasks related to permission to make digital or hard copies of all or part of this work for per sonal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. copyrights for components of this work owned by others than acm must be honored. to copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and or a fee. http: dx doi org year# their complex search task. to better understand this, consider the example query shown in figure #. when the searcher enters this query, the method detects that they are engaged in a complex search task and that they may be inter ested in exploring more or fulfilling more steps. the figure shows a graph where every node is a search task. search tasks are con nected if there is a high likelihood that both tasks can be steps in the same complex search task. the suggested tasks in figure # ap pear reasonable to help searchers identify other steps for a complex task involving a trip to grand cayman. note that this is a repre sentative set of tasks and there are many similar high quality rec ommendations in the task graph that we generate. since many searchers looking to fly to grand cayman have also been engaged in other activities to plan their trips, the proposed method automat ically identifies tasks about accommodation, car rental, trip planning and ac tivities of possible interest. we make the following contributions with this research: develop methods to automatically identify queries in large scale search logs that form part of complex search tasks. learn models to identify query intent and different aspects of the search tasks represented by each set of queries. construct a graph connecting tasks that are likely to be of inter est to searchers. this graph could be useful for a range of appli cations beyond task recommendation. apply the graph for the recommendation of a set of interesting and diverse tasks to support searchers during exploration. devise and apply metrics to measure aspects of task recommen dations, including novelty, diversity, and interestingness. the remainder of the paper is structured as follows. in section #, we describe related work in exploratory search, search trails, seren dipity and query suggestions. section # describes how we identify exploratory search intent. we describe the aspect extraction and graph construction in section #. our experiments and findings are summarized in section # and we conclude in section #. most queries in web search are ambiguous and multifaceted. identifying the major senses and facets of queries from search log data, referred to as query subtopic mining in this paper, is a very important issue in web search. through search log analysis, we show that there are two interesting phenomena of user behavior that can be leveraged to identify query subtopics, referred to as one subtopic per search and subtopic clarification by keyword. one subtopic per search means that if a user clicks multiple urls in one query, then the clicked urls tend to represent the same sense or facet. subtopic clarification by keyword means that users often add an additional keyword or keywords to expand the query in order to clarify their search intent. thus, the keywords tend to be indicative of the sense or facet. we propose a clustering algorithm that can effectively leverage the two phenomena to automatically mine the major subtopics of queries, where each subtopic is represented by a cluster containing a number of urls and keywords. the mined subtopics of queries can be used in multiple tasks in web search and we evaluate them in aspects of the search result presentation such as clustering and re ranking. we demonstrate that our clustering algorithm can effectively mine query subtopics with an measure in the range of. our experimental results show that the use of the subtopics mined by our approach can significantly improve the state of the art methods used for search result clustering. experimental results based on click data also show that the re ranking of search result based on our method can significantly improve the efficiency of users ability to find information. when compared side by side with human generated results, we also nd that our method is signi cantly better than the baseline. understanding the search intent of users is essential for satisfying a usersearch needs. how to best represent query intent is still an ongoing research problem. one consensus among the researchers is that the intents of queries can be characterized along multiple dimensions. the intents of a query can be represented by its search goals, such as informational, navigational, and transactional. it can also be represented by semantic categories or topics. furthermore, it can be represented by subtopics, denoting multiple senses or multiple facets of the query. for example, harry shum is an ambiguous query, which may refer to an american actor, a vice president of microsoft, or another person named harry shum. when people search for xbox, they may be looking for information on di erent facets of an xbox, such as online game, homepage, and marketplace. note that a query can be both ambiguous and multifaceted. the more frequent a query is, the more likely that it has multiple senses or facets. the major di erence between the topics and subtopics of a query is that the former is more coarsegrained and related to other queries, while the latter is negrained and is only about the query in question. identifying the major subtopics of a query is very important for many search tasks such as personalized search, query suggestion, and search result presentation including clustering, re ranking, and diversi cation. in this paper, we aim to automatically mine the major subtopics of queries from the search log data. although there is some related work, the subtopic mining problem as de ned in this paper does not seem to have been studied previously. we performed a comprehensive study of the two phenomena, referred to as one subtopic per search and subtopic clari cation by additional keyword respectively. we show that we can mine the subtopics of queries from search log data by. we then represent the senses or facets of a query by a number of urls and keywords. we observe that this can be done with high accuracy for head queries. although the phenomena have been observed or mentioned in previous work, there has not been a detailed study conducted on them, as far as we know. if a user clicks multiple urls after submitting a query, then the clicked urls tend to represent the same subtopic, which is called one subtopic per search. figure # shows an example of search results for the query harry shum on a web search engine. the result contains in figure #: search result for query harry shum. ditional keywords to a query to expand the query in order to clarify its subtopic. this phenomenon is called subtopic clari cation by additional keyword. as a result, the urls clicked after searching both with the original and the expanded queries tend to represent the same subtopic and the keyword also tends to be indicative of the subtopic. for example, people may submit harry shum microsoft as an expanded query to specify the subtopic. the urls clicked in searches for both harry shum and harry shum microsoft usually represent the same subtopic, harry shum from microsoft, and therefore microsoft becomes a keyword of the subtopic. we employ a clustering algorithm to group urls as well as keywords into clusters, where each cluster represents one subtopic of a query. for example, one cluster for query harry shum may contain the home page of the microsoft harry shum, his wiki pro le, and the keywords microsoft and bing. the clustering is performed based on the two phenomena of user behavior, as described above. speci cally, for each query and its expanded queries, the related click log data is collected. clustering is then carried out on all the clicked urls. if two urls are clicked together many times in the click data, then they are likely to be clustered together. if two urls are clicked both under the original and expanded queries, then they are likely to be clustered together. we employ a special data structure consisting of a pre. tree to facilitate recursive execution of the clustering algorithm on the log data. in this way, the mining of subtopics can be conducted very. we conducted experiments to measure the accuracy of our clustering method on a trec data set and a new data set in which the subtopics of both queries are labeled. for ambiguous subtopics, our method can achieve acubed from to. for multifaceted subtopics, our method can achieve acubed from to in terms ofcubed. we also evaluated our method in search result clustering. we compared our method with a state of the art method of search result clustering. experimental results show that our method can signi cantly improve accuracy. the improvements are in terms ofcubed precision and in terms ofcubed recall. we further evaluated our method on search result reranking, in which the user is con rmed with the subtopic she has in mind and re ranking of search results based on user feedback is performed. we used the average click position in the log data as the evaluation measure. the results show that our method can boost the average click position points higher, which implies a promising improvement in the user experience. there are three major contributions in our work: we have analyzed two phenomena in user search behavior that can be utilized to identify query subtopics. most analysis of web search relevance and performance takes a single query as the unit of search engine interaction. when studies attempt to group queries together by task or session, a timeout is typically used to identify the boundary. however, users query search engines in order to accomplish tasks at a variety of granularities, issuing multiple queries as they attempt to accomplish tasks. in this work we study real sessions manually labeled into hierarchical tasks, and show that timeouts, whatever their length, are of limited utility in identifying task boundaries, achieving a maximum precision of only. we report on properties of this search task hierarchy, as seen in a random sample of user interactions from a major web search engine log, annotated by human editors, learning that of tasks are interleaved, and are hierarchically organized. no previous work has analyzed or addressed automatic identification of interleaved and hierarchically organized search tasks. we propose and evaluate a method for the automated segmentation of users query streams into hierarchical units. our classifiers can improve on timeout segmentation, as well as other previously published approaches, bringing the accuracy up to for identifying fine grained task boundaries, and for identifying pairs of queries from the same task when tasks are interleaved hierarchically. this is the first work to identify, measure and automatically segment sequences of user queries into their hierarchical structure. the ability to perform this kind of segmentation paves the way for evaluating search engines in terms of user task completion. web search engines attempt to satisfy users information needs by ranking web pages with respect to queries. but the reality of web search is that it is often a process of querying, learning, and reformulating. a series of interactions between user and search engine can be necessary to satisfy a single information need. to understand the way users accomplish tasks and subtasks using multiple search queries, we exhaustively annotated day long query sequences for web searchers. we limited the duration to three days to allow complete annotation of every query sequence, with an extremely thorough approach. these spans of time allowed us to identify tasks which result in queries placed over multiple days, as well as multiple tasks which may occur over several days. we manually annotated these query sequences with tasks and subtasks, nding that many tasks contained subtasks, and many di erent tasks and subtasks were interleaved. while previous work has examined the way users interleave tasks, no previous work has examined the way tasks contain subtasks. if we are able to accurately identify sets of queries with the same information seeking intent, then we will be in a better position to evaluate the performance of a web search engine from the userpoint of view. for example, standard metrics of user involvement with a search engine or portal emphasize visits or time spent. however, each page view can constitute small pieces of the same information need and each visit could encompass some larger task. if we could instead quantify the number of information needs or tasks which a user addresses via a website, we would have a clearer picture of the importance of the site to that user. ort in terms of queries issued or time spent on a task, as the user attempts to satisfy an information need or ful ll a more complex objective. to this end, we built classi ers to identify task and subtasks boundaries, as well as pairs of queries which correspond to the same task, despite being interleaved with queries from other tasks. ectively to identify goal and mission boundaries, and pairs of non adjacent queries belonging to the same goal or mission. in section #, we discuss related work both in de ning sessions and automated segmentation of query logs into tasks and sessions. in section # we provide our de nitions, detail on the manual annotation of our data, statistics on the missions and goals we nd, and show that time based thresholds are of limited accuracy in identifying task boundaries. in section # we introduce the supervised classi cation which we perform to improve task identi cation, as well as the features and methods we use. in section # we show that a model combining feature types can identify goals and missions with extremely high accuracy, even when they are interleaved. we also discuss performance of the individual features on the classi cation tasks. lastly, in section #, we discuss conclusions and future directions for the work. we consider a search task as a set of queries that serve the same user information need. analyzing search tasks from user query streams plays an important role in building a set of modern tools to improve search engine performance. in this paper, we propose a probabilistic method for identifying and labeling search tasks based on the following intuitive observations: queries that are issued temporally close by users in many sequences of queries are likely to belong to the same search task, meanwhile, different users having the same information needs tend to submit topically coherent search queries. to capture the above intuitions, we directly model query temporal patterns using a special class of point processes called hawkes processes, and combine topic models with hawkes processes for simultaneously identifying and labeling search tasks. essentially, hawkes processes utilize their self exciting properties to identify search tasks if influence exists among a sequence of queries for individual users, while the topic model exploits query co occurrence across different users to discover the latent information needed for labeling search tasks. more importantly, there is mutual reinforcement between hawkes processes and the topic model in the unified model that enhances the performance of both. we evaluate our method based on both synthetic data and real world query log data. in addition, we also apply our model to query clustering and search task identification. by comparing with state of the art methods, the results demonstrate that the improvement in our proposed approach is consistent and promising. nowadays, search engines have become the most important and indispensable web portal, whereby people pursue a wide rangeof permission to make digital or hard copies of all or part of thiswork for personal or classroom use is granted without fee provided that copies arenot made or distributed for pro. or commercial advantage and that copies bear this notice and the full citation on the rst page. copyrights for components of this work owned by others than acm must be honored. tocopy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speci. searches in order to satisfy a variety of information needs to better understand users information needs and search behaviors, one important research direction is to detect and split users temporal sequences of queries into disjoint query sessions, which are often de ned as a sequence of queries issued within. xed period of time, ranging from to minutes. however, a usersingle session may contain queries with multiple intents, or consist ofseeking information on single or multiple topics. going beyond a search session, a search task, which is de ned as a set of queries serving for the same information need, has been recognized as a more suitable atomic unit than a single query or session, not only for better modeling user search intent but also for improving other downstream search engines applications, such as query suggestion and personalized search. additionally, analyzing the formation of search tasks also deepens our understanding of the simultaneous temporal diffusion of multiple memes, ie, intents or ideas, in social networks. therefore, how to effectively identify and label search tasks becomes an interesting and challenging problem. recently, there have been attempts to extract in session tasks, and cross session tasks from sequences of queries. they build clustering or classi cation methods to identify tasks based on time splitting, lexicon similarity, and queryreformulation patterns. even though the temporal submission patterns in query sequences carry valuable information for mining search tasks, those existing methods only use them for either simplysplitting sequences of queries into temporally demarcated sessions, or transforming them as features among queries. we believe that by directly modeling temporal information as part of extracting search tasks in a richer way, we can substantially improve search task mining. another key drawback of those existing methods is that most of them focus only on the query sequences of individual users instead of considering the wholequery log. only very recently, there has been an attempt which triesto take advantage of the collective intelligence of many users for discovering tasks. it is obvious that different users may have the same information need, and share the same search task, thus modeling query sequences across different users will be very valuable for capturing semantically similar search tasks in a global context. generally, two consecutive queries issued by a user are more likely to belong to the same search task than two non contiguous queries, but that is not necessary always the case. for example, as shown in figure #, the consecutive queries autotrader and ya hoo autos issued by user ua belong to the same search task, while the consecutive queries yahoo autos and wells fargo belong to two separate search tasks. another complicated case is that two non contiguous queries may belong to the same or different tasks figure #: an illustration of relationship between consecutive queries and search tasks. every circle represents a query issued by a user at time tn the blue arrow line indicates an in uence exists between queries. a set of queries linked by blue lines denotes a search task, and some topically coherent search tasks across three users are labeled by different colors. as well, eg, verizon wireless and autotrader issued byuser ua belong to two different search tasks, but yahoo autos and kbb cars issued by users ub belong to the same search task. these examples show that in reality we cannot simply rely on the time splitting or an individual user behavior for identifying search tasks. it makes more sense to take into account the explicit temporalinformation of query sequences exhibited by many different users in the whole query logs. the basic intuition is that if two consecutive or temporally close queries are issued many times by thesame user or many others users, it is more likely these two queries are semantically related to each other, ie, belong to the same search task. as we can see, the consecutive queries wells fargo and bank of america are issued by both ua and ub, while the consecutive queries yahoo autos and wells fargo are only issued by user ua therefore, according to the above intuition, wells fargo and bank of america are more likely to belong to the same search task compared with yahoo auto and wells fargo. similarly, for non contiguous queries, autotrader and kbb cars are issued temporally very closeby both ub and uc, which indicates they have higher chance of belonging to the same search task. moreover, different users may engage in different search patterns, eg, user ub searches more frequently than user ua, which indicates how likely the search tasks may change within a certain time period for different users, and then they should be treated differently based on their searchactivities. all in all, we choose to identify search tasks by leveraging the temporally weighted query co occurrence this not only guarantees sound performance by making full use of both textual and temporal information of the entire query sequences, but also enables the labeling of the identi ed search tasks since semantically related queries are clustered together through query links determined by co occurrence. to model temporally close query co occurrences, we turn to latent dirichlet allocation, one powerful graphicalmodel that exploits co occurrence patterns of queries in query sequences. existing temporal lda models learned distinguishedtopic distributions from temporal fragments of data, while ignored query co occurrence across different fragments, thus failed to make full use of the temporal information. recently, some spatial ldamodels encouraged queries that are very close in space to share similar topic distributions, ie, weighing the reliability of query co occurrence based on spatial closeness. however, there exists no uniform standards for measuring such closeness across different instances, especially in temporal data. our research, on theother hand, considers making full use of temporal information by weighing the reliability of each co occurrence of a pair of queriesbased on how likely an in uence exists between this pair of queries. here we de ne query in uence as: the occurrence of one query raises the probability that the other query will be issued in the near future. in uence, rather than closeness, enables us to distinguish temporally close query co occurrence from temporally regular query cooccurrence for each user based on his own propensity of query submission. the intensity function of hawkes includes a base intensity, along with a positive in uence of the past events on the current one. such a positive in uence isoriginated from the self exciting property that the occurrence of one event in the past increases the probability of events happening in the future. we nd that hawkesself exciting property coincides with the concept of in uence in our situation, and its base intensity captures the personal propensity. thus we employ hawkes processes to fully utilize temporal information in query sequences for identifying the existence of query in uence. from the perspective of hawkes processes, in uence generally exists between temporally close queries. however, for an observed query sequence, not all temporally close query pairs have the actual in uence in between, since in some cases the occurrence of the later queries may result from the base intensity rather than selfexciting property. nd it intractable to obtain an optimal solution of in uence existence based on temporal information only. last but the most important, it is unable to directly identify search tasks by either generating topics based on query co occurrence using lda, or estimating all in uence candidates by hawkes. to address the above issues, we concentrate on the in uence existence between semantically related queries, whose estimation can be simpli ed by the joint efforts of lda and hawkes and enable a direct identi cation of search tasks. according to the above intuition, a search task can be viewed as asequence of semantically related queries linked by in uence a query that does not satisfy userinformation need will self excite the submission of another semantically related query in the near future. on the other hand, a query rarely excites the submissionof another semantically unrelated query even if their timestamps are very close. thus we believe that those semantic in uence are the in uence that actually take effect, and our paper solves search task identi cation directly by identifying those in uence to limit the solution space of such in uence, we cast both in uence existence and query topic membership into latent variables, and identify the existence probability of pairwise in uence with the similarity of the memberships of associated two queries. this identi cation works as a bridge between lda and hawkes processes, as lda assigns high in uence quali ed co occurred queries to the same topic, while query co occurrence frequency narrows the solution space of in uence in this way, lda and hawkes mutually bene. each other in identifying search tasks using both temporaland textual information. to this end, we propose a probabilisticmodel that incorporates this equalization to combine the lda modelwith hawkes processes, and develop a mean eld variational inference algorithm to estimate the in uence by optimizing the data likelihood. we evaluate our method on synthetic data, and also applyit to mine search tasks in both aol and yahoo query log data. experimental results show that the proposed method can achieve signi cantly better performance than existing state of the art methods. in a nutshell, our major contributions include: we cast search task identi cation into the problem of identify semantic in uence in observed query sequences, and propose a probabilistic model by combining lda model with hawkes processes to address the problem. most importantly, there is mutual reinforcement between hawkes processes and the topic model in the uni ed model that enhances the performance of both. we employ hawkes processes to directly model temporal information as part of search taskidenti cation, which has never been explicitly exploited in the existing works. the rest of the paper is organized as follows. we rst introduce hawkes processes, and the proposed model by combining lda with hawkes processes in section #. in section #, we develop a fast mean eld variational inference algorithm for the resulting optimization problem. we then describe and report the experimental results in section #. finally, we introduce the related work in section #, and present our conclusions and future work in section. among all web search queries there is an important subset of queries containing entity mentions. in these queries, it is observed that users are most interested in requesting some attribute of an entity, such as obama age for the intent of age, which we refer to as the attribute intent. in this work we address the problem of identifying synonymous query intent templates for the attribute intent. for example, how old is and age are both synonymous templates for the age intent. successful identification of the synonymous query intent templates not only can improve the performance of all existing query annotation approaches, but also could benefit applications such as instant answers and intent based query suggestion. in this work we propose a clustering framework with multiple kernel functions to identify synonymous query intent templates for a set of canonical templates jointly. furthermore, signals from multiple sources of information are integrated into a kernel function between templates, where the weights of these signals are tuned in an unsupervised manner. we have conducted extensive experiments across multiple domains in freebase, and results demonstrate the effectiveness of our clustering framework for finding synonymous query intent templates for attribute intents. accurate understanding of the intent underlying a user query is a crucial problem in modern information retrieval. the understanding of userintent not only can improve the accuracy of the search results, but also enables new types of applications that help the user make decision and nish tasks directly. for example, for a query tom cruise age, an intelligent search engine would trigger the direct answer of years on top of the result page, which quickly ful ls the userinformation need for nding this fact about tom cruise. likewise, for a query map of chicago, it is more desirable to show a city map of chicago directly. another emerging application is the entity search, which returns the most relevant entities and attributes instead of relevant web pages. the examples mentioned above all require precise understanding of the intent of a user query. in this work we focus on the subset of queries containing entity mentions since they are one of the most important subset of queries. one previous research reported that of search queries contained named entities, another research found that of queries have entities or entity categories. we have observed from the query log of a major search engine that among the entity queries, other than querying the entity name users are most interested in requesting an attribute of an entity. we refer to such intent as attribute intent, which is the focus of this work. for example, obama age for the intent of age, the museum of modern arts phone number for the intent of phone number are attribute intents. an ultimate goal of the attribute intent understanding is that assume we have a gigantic database of all entities and attributes in the world, map all possible search queries to the corresponding attributes. this goal shares similarities with other researches on query annotation, in which they aim at annotating a query to a structured schema. note that the query intents in these works are not necessarily attribute intents. however, these approaches either require a lot of labeled data, or rely on a highly developed and structured domain database. most recently, unsupervised method does exist, yet it is limited in its ability to merge query patterns conveying same intent. not surprisingly, achieving the ultimate goal of attribute intent understanding automatically across many domains is very challenging. in some tail domain doing this mapping is not even possible because of the data sparsity. thus in this work we aim at mapping the attribute intent at the template level, where individual queries are aggregated into query intent templates, partly reducing the data sparsity issue. for example, for the attribute age in we have manually labeled randomly selected queries that have entity mentions. in which queries mention the entity name only, queries mention entity name and an attribute, and queries have other intents. person domain, age is a query intent template for the age intent, while obama age, tom cruise age are individual queries conforming to this template. we refer to the query intent templates conveying same underlying intent as synonymous query intent templates. table # shows two attribute intent templates as well as their synonymous templates. speci cally, in this work we seek to address the problem of identifying synonymous query intent templates for attribute intents. successful identi cation of query intent templates to their corresponding attribute intents can provide bene ts to several applications. first, it can potentially improve all exiting query intent annotation approaches by merging the synonymous templates. second, in the application of instant answers, it enlarges the questions that a system can answer. third, by knowing synonymous query intent templates, a search engine can recommend more queries based on rules between query templates for long tailed queries. table #: synonymous query intent templates domain attribute intent template synonymous query intent templates person age age how old is age of what age is institution phone number phone phone number for number to contact number to the best of our knowledge, there are no existing methods that directly address the synonymous query templates identi cation problem. for example, the above mentioned query annotation methods could be used to solve the problem. however, due to the structure and semantic difference between queries and query templates, these methods might not be feasible. we could also apply approaches for question paraphrasing in the question and answer research community. however, focuses on nding synonymous phrases on the question level, not on the template level. and aims at identifying alternative expression of the answers, while in this paper we focus on alternative ways people query attribute intents. thus these previous approaches can not be directly applied to the problem we are addressing. in addition, we can treat it as a string synonym problem, which previous researches have addressed with several similarity features such as distributional similarity, coclick similarity etc. however, from table # we can see that sometimes the synonymous templates may be different from the canonical template on small lexical variation and word orders. yet sometimes they are very different on lexicon. therefore, we can imagine that only relying on single similarity such as string similarity, it is very hard to discover templates that are synonymous to the canonical template in semantic level. in fact, the synonymous query intent templates share similarities among several independent, sometime complementary signals. for example, other than the lexicon similarity, they would manifest high similarity on the distribution of entities that occur in the templates. in addition, people tend to click on same set of documents when they issue queries conforming to semantic equivalent templates. for instance, itcommon that users who issue obama age and how old is obama will both land on the wikipedia page of barack obama. in this work we attempt to identify synonymous query intent templates by integrating multiple information sources. among multiple information sources, some are more important in determining synonym relations than others. moreover, the relative importance of these sources also depends on the domain: a feature that is crucial in the person domain might be only marginal in the location domain. therefore automatic determination of the weights of different information sources is critical. here we propose to automatically learn these weights via a novel clustering procedure with multiple kernel functions that cluster candidate query intent templates to the canonical templates and effectively determine the appropriate weights of the signals. other than the choice of information sources, there are different options for the mode of learning. we could identify the synonymous templates for a single canonical query intent template at a time, or learn the synonymous templates for all canonical templates jointly. handling single template at a time might lead to the dif culty of differentiating synonymous templates of close related ones. for example, for template height, weight could be identi ed as synonym mistakenly because they share a lot of coclicks. however if we learn synonymous templates from those two values jointly, this error could be corrected easily because of the awareness of each other. joint learning of synonymous templates also provides the must link and can not link constraints among canonical templates, which could effectively improve the results. in this work we address the problem of nding synonymous query intent templates for a set of canonical query intent templates jointly. we have proposed a clustering model with multiple kernel functions to take advantage of multiple heterogeneous information sources. qualitative and quantitative results on attribute intent templates from a large knowledge demonstrate that our method can identify synonymous query intent templates accurately. entity attribute values, such as lord of the rings for movie title or infant for shoe gender, are atomic components of entity expressions. discovering alternative surface forms of attribute values is important for improving entity recognition and retrieval. in this work, we propose a novel compact clustering framework to jointly identify synonyms for a set of attribute values. the framework can integrate signals from multiple information sources into a similarity function between attribute values. and the weights of these signals are optimized in an unsupervised manner. extensive experiments across multiple domains demonstrate the effectiveness of our clustering framework for mining entity attribute synonyms. the web contains a wealth of structured data, such as various entity databases, web tables, etc. there is a growing trend in commercial search engines to match unstructured user queries to these structured data sources. however, user expressions of such entities often do not match the canonical speci cations from the data providers. for example, in the movie domain, the full title the lord of the rings: the return of the king can be speci ed by users as lotr, lotr: return of the king, or the return of the king. for shoes, people may describe the standard gender value infant as baby or toddler. thus, entity synonym identi cation, the discovery of alternative ways people describe entities, has become a critical problem to bridge the above mentioned gap between data providers and consumers. traditionally, entity synonym research has focused on nding synonyms of named entities, where the entity itself is completely speci ed by the referent string. here we are interested in nding permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies bear this notice and the full citation on the rst page. copyrights for components of this work owned by others than acm must be honored. to copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speci. while the attribute values can be entity mentions, they can also be arbitrary strings. in fact, our problem de nition is a generalization of nding named entity synonyms, because the named entity expression is often just an attribute of the entity. figure # illustrates an example of such general cases collected from a product title and two user issued queries. here canon is a named entity, but it also matches attribute digital camera brand. and mega pixel is an attribute value; but it cannot be interpreted as a stand alone entity. as seen in figure #, there are a lot of variations in describing the same attribute values. successful identi cation of their surface forms will enable better query intent understanding and better normalization of products from different providers, etc. in the case figure #: entity attribute value variations the attribute value itself is an entity mention, our problem setup is the same as traditional entity synonym nding. previous research has addressed the synonym identi cation problem from multiple perspectives. for example, tried to reconcile different references to the same database record. other works identi ed alternative forms of a query for web search by measuring query similarity, query document click graphs and query entity click graphs. for non entity attribute values, there are also research efforts from the natural language processing community on nding semantic synonyms based on distributional similarity, syntactic patterns et. first, nding synonyms without context can not handle semantic ambiguity. there are recent research attempts to identify synonyms with additional context, such as paragraph context in. but for structured database, such information is not always available. second, previous approaches usually focus on utilizing a single signal, such as distributional similarity, syntactic patterns, or query entity clicks. however, the weights for combining these information sources are usually manually tuned largely based on experience. in this work we focus on nding synonyms for a set of entity attribute values simultaneously. our problem setup is a generalization of the entity synonym identi cation problem, in which the input can be an entity mention or an arbitrary string. to address the de ciencies of existing approaches discussed above, we propose a compact clustering model that enables the integration of multiple heterogeneous information sources. our main contributions are summarized as follows: joint synonym mining from a set of attribute values. most previous synonym identi cation methods search for synonyms one entity at a time. however, processing a set of entity attribute values simultaneously has several advantages. first, as the values are from the same attribute, they exhibit distinctive contextual patterns. mining such patterns allows us to de ne a novel categorical pattern similarity function to tackle the ambiguity problem. second, joint modeling of multiple attribute values also provides prior knowledge about the relationship among candidates. for example, for entity mention lord of the rings, lord of the rings could be identi ed as synonym mistakenly. but if we learn synonyms from those two values jointly, this error could be corrected easily because of the awareness of lord of the rings. synonym values generally exhibit similarities in more than one aspect. some synonym values only differ in a few characters, due to spelling errors or morphological differences. also, queries that differ only in synonym values tend to have clicks on similar sets of documents. in addition, synonym values generally have similar surrounding contexts within queries and documents. among these signals, some are more important than others in determining synonym relations. furthermore, the relative importance of these signals also depends on the domain: a feature that is crucial in the movie domain might be only marginal in the camera domain. therefore automatic determination of the weights of different information sources is critical. in this work we propose to automatically learn these weights via compact clustering a novel clustering procedure that maximizes the similarity of points within a cluster. we define task to be an atomic user information need. web search logs have been studied mainly at session or query level where users may submit several queries within one task and handle several tasks within one session. although previous studies have addressed the problem of task identification, little is known about the advantage of using task over session and query for search applications. in this paper, we conduct extensive analyses and comparisons to evaluate the effectiveness of task trails in three search applications: determining user satisfaction, predicting user search interests, and query suggestion. experiments are conducted on large scale datasets from a commercial search engine. experimental results show that: sessions and queries are not as precise as tasks in determining user satisfaction. tasks represent atomic user information needs, and therefore can preserve topic similarity between query pairs. task based query suggestion can provide complementary results to other models. in this paper, we introduce task trail as a new concept to understand user search behaviors. task trails provide higher web page utilities to users than other sources. the findings in this paper verify the need to extract task trails from web search logs and suggest potential applications in search and recommendation systems. we introduce an entity centric search experience, called active objects, in which entity bearing queries are paired with actions that can be performed on the entities. for example, given a query for a specific flashlight, we aim to present actions such as reading reviews, watching demo videos, and finding the best price online. in an annotation study conducted over a random sample of user query sessions, we found that a large proportion of queries in query logs involve actions on entities, calling for an automatic approach to identifying relevant actions for entity bearing queries. in this paper, we pose the problem of finding actions that can be performed on entities as the problem of probabilistic inference in a graphical model that captures how an entity bearing query is generated. we design models of increasing complexity that capture latent factors such as entity type and intended actions that determine how a user writes a query in a search box, and the url that they click on. given a large collection of real world queries and clicks from a commercial search engine, the models are learned efficiently through maximum likelihood estimation using an em algorithm. given a new query, probabilistic inference enables recommendation of a set of pertinent actions and hosts. we propose an evaluation methodology for measuring the relevance of our recommended actions, and show empirical evidence of the quality and the diversity of the discovered actions. the research challenge addressed in this paper is to devise effective techniques for identifying task based sessions, ie, sets of possibly non contiguous queries issued by the user of a web search engine for carrying out a given task. in order to evaluate and compare different approaches, we built, by means of a manual labeling process, a ground truth where the queries of a given query log have been grouped in tasks. our analysis of this ground truth shows that users tend to perform more than one task at the same time, since about of the submitted queries involve a multi tasking activity. we formally define the task based session discovery problem as the problem of best approximating the manually annotated tasks, and we propose several variants of well known clustering algorithms, as well as a novel efficient heuristic algorithm, specifically tuned for solving the tsdp. these algorithms also exploit the collaborative knowledge collected by wiktionary and wikipedia for detecting query pairs that are not similar from a lexical content point of view, but actually semantically related. the proposed algorithms have been evaluated on the above ground truth, and are shown to perform better than state of the art approaches, because they effectively take into account the multi tasking behavior of users. although web search engines still answer user queries with lists of ten blue links to webpages, people are increasingly issuing queries to accomplish their daily tasks. in this work, we propose a two step methodology for discovering tasks that users try to perform through search engines. first, we identify user tasks from individual user sessions stored in search engine query logs. in our vision, a user task is a set of possibly noncontiguous queries, which refer to the same need. second, we discover collective tasks by aggregating similar user tasks, possibly performed by distinct users. to discover user tasks, we propose query similarity functions based on unsupervised and supervised learning approaches. we present a set of query clustering methods that exploit these functions in order to detect user tasks. all the proposed solutions were evaluated on a manually built ground truth, and two of them performed better than state of the art approaches. to detect collective tasks, we propose four methods that cluster previously discovered user tasks, which in turn are represented by the bag of words extracted from their composing queries. these solutions were also evaluated on another manually built ground truth. people rely heavily on web search engines to organize their daily activities. a key reason for the popularity of todaysearch engines is their user friendly interface, which allows users to easily query for their needs by issuing their own lists of keywords. users exploit this simple query based interface to retrieve web information and resources, which in turn are used to perform one or more webmediated tasks, for example, nding a recipe, booking. this work has been partially supported by projects midas, ingeoclouds, and miur prin ars technomedia. tolomei, dais, universit a ca foscari venezia, italy; corresponding authoremail: gabriele tolomei unive it. permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies show this notice on the rst page or initial screen of a display along with the full citation. copyrights for components of this work owned by others than acm must be honored. to copy otherwise, to republish, to post on servers, to redistribute to lists, or to use any component of this work in other works requires prior speci. permissions may be requested from publications dept, acm, inc, penn plaza, suite, new york, ny year# usa, fax, or permissions acm org. year# acm year# year# art doi: http: dx doi org year#. our two step task discovery process: user task and collective task discovery. although search engines nowadays offer several mechanisms to help their users, in essence they are document retrieval systems that answer a user query with a simple list of ten blue links. if the results returned are not satisfactory, the user may decide to re ne his query, thereby getting a new list of results that is hopefully more relevant to his needs. however, this query look re ne paradigm is not effective for all the tasks to be accomplished. we believe next generation search engines should progress from being mere web document retrieval tools to becoming multifaceted systems which fully support users while they are interacting with the web. this creates novel and exciting research challenges ranging from the ability to recognize latent tasks from the issued queries, to the design of new recommendation strategies and user interfaces for showing relevant results. this manuscript focuses on this rst research challenge and proposes an effective methodology for discovering the tasks that users try to perform through queries they issue to search engines. interesting search behaviors and patterns can be revealed by analyzing and mining search engine query logs, which record the activities of many users. it has been discovered that query logs are suitable sources from which tasks can be extracted. in concrete terms, a very important aspect we can analyze from a query log is represented by query sessions, that is, speci. sets sequences of queries issued by a user while interacting with a search engine. there are two distinct levels of granularity to consider when detecting the set of tasks from a query log. the rst is the intra user level, where tasks are searched for within individual user query sessions. the challenge here is to nd relationships that go beyond lexical query similarity, for instance, the case of a query session for the user alice which contains the queries new york hotel and waldorf astoria, which are not necessarily issued consecutively. those two queries clearly refer to the task reserving a hotel room in new york, yet they do not share any common terms. the second level of granularity is the inter user level, where even more subtle problems may occur and need to be handled, for instance, let another user bob type the following two queries: hotels in new york and holiday inn ny. both users are clearly trying to achieve the same task, but by means of different queries. this second problem occurs because distinct users tend to phrase even the same task in several different ways. therefore, a task discovery methodology has to take into consideration these two preceding aspects in order to be effective. to this end, we divide the problem of discovering tasks into two subproblems, and we address them separately. first, we extract from each individual user session those sets of queries that were issued to achieve speci. we call each of those sets a user task, since they strictly depend on each individual user. second, we consider all the user sessions of the query log, and we identify all the queries related to a common task possibly performed by distinct users by grouping together similar user tasks. we refer to each agglomeration of similar user tasks as a collective task. figure # shows this two step task discovery process just described. the rationale behind this two step strategy is as follows. in a previous work, we already proved that user tasks can effectively be found by exploiting the lexical and semantic content similarity of queries issued by individuals within speci. conversely, the same approach would not be able to discover collective tasks if applied directly to users queries, because queries that are issued by two users, which are lexically or semantically similar, might refer to different latent needs. in addition, this two step method guarantees scalability, since the agglomeration needs to process a reduced number of objects, that is, groups of queries rather than single ones. finally, two kinds of contributions are presented in this manuscript: one concerns user task discovery while the other is related to collective task discovery, and both are analyzed in the following. in lucchese et al, we already showed that users perform multitasking search activities in the query streams issued to a search engine. multitasking refers to the way users interact with a search engine, by intertwining different tasks within the same time period. this makes it dif cult to identify user tasks by just splitting each user session into time based sequences of queries. thus, a more precise measure of the task relatedness between query pairs was needed. to this end, we proposed an unsupervised learning approach for measuring task based query similarity, which relied on a selection of both internal and external query log features. internal features are available from the original query log data, whereas external ones can be derived from other data sources. this approach resulted in two query similarity functions. the rst, wasa convex combination of the selected query log features. the second, combined typical lexical content similarity measures with the collaborative knowledge provided by wiktionary and wikipedia. these external knowledge bases were used to enrich the semantics of each query, that is, to wikify each query in order to make more accurate decisions during the actual user task discovery step. furthermore, the preceding notion of task relatedness between query pairs was used to discover the nal set of user tasks. to this end, we introduced a set of query clustering methods with the aim of grouping together task related queries, namely queries that are assumed to be part of the same user task on the basis of a speci ed task relatedness measure. in particular, we compared two techniques derived from well known clustering algorithms, that is, means and db scan with two other graph based methods. all four proposed solutions were evaluated on a ground truth, that is, a set of manually annotated user tasks. results showed that the latter two techniques performed better than the former, and they also improved other state of the art approaches noticeably. as an innovation contribution to this work, we also propose and evaluate a supervised learning approach for determining the task based similarity between query pairs. unlike the unsupervised learning approach introduced in lucchese et al, here the task relatedness is learned by training several classi ers in our ground truth. in particular, we exploit the binary classi ers introduced by jones and klinkner and use the prediction provided by these classi ers in order to determine whether two queries belong to the same task. the probability value associated to that prediction is in turn used as a measure of how strong the task relatedness is between each pair of queries. we train the classi ers over all the features that jones and klinkner claim to be the most suitable for predicting if two queries belong to the same search goal. http: www wiktionary org http: www wikipedia org. lucchese et al moreover, we expand these training features with both wikipedia, that is, the wiki cation of the query, as well as the url overlapping degree between the results returned by a search engine for each query, that is, the jaccard index between the top urls returned for each query. this supervised learning approach leads to a set of new task based query similarity functions, which are in turn exploited by the two best performing clustering methods for user task discovery introduced in our previous work, namely qc wcc and qc htc. experimental results have shown that combining supervised task relatedness learning with our query clustering methods does not substantially improve the overall effectiveness in discovering user tasks. however, the performance of the classi ers proposed by jones and klinkner improves signi cantly with the combined use of wiki cation and url overlapping along with the other features. furthermore, we test our two best performing user task discovery methods on a larger dataset. interestingly, we discover that the analysis conducted on both the smaller and the larger datasets are coherent, in other words, they result in similar conclusions. this means that we can be relatively con dent that replicating experiments on both datasets would also lead to similar quantitative results. the true innovation in this work, which completes the overall roadmap we sketched for nding tasks from search engine query logs, is based on the notion of collective task. in a similar way to discovering user tasks, we provide a second ground truth by manually grouping a set of user tasks into a set of collective tasks. in addition, we present and discuss four methods used to actually discover collective tasks. all of them are user task clustering techniques, where each user task is represented by the bag of words of its composing queries. each solution adopts a different clustering strategy and a different user task similarity measure. we quantitatively evaluate the four methods on the ground truth of collective tasks. the best results were obtained by a partitional clustering technique, which uses the cosine similarity measure. finally, this best performing technique is also run on a larger dataset of user tasks, and its performance is assessed by means of examples of evidence. the rest of the article is organized as follows. section # describes related work on query log analysis and mostly focuses on query session boundaries detection. section # provides the description and analysis of our benchmark dataset, that is, the year# aol query log. in section #, we propose our theoretical model and the statement of the user task discovery problem. section # presents the construction of our ground truth by manually grouping queries that are considered to be task related in a portion of our sample dataset. in addition, we propose some statistics relating to this corpus of manually identi ed user tasks. section # introduces several approaches for measuring the task relatedness between query pairs, that is, task based query similarity functions, which in turn are exploited by the user task discovery methods proposed and compared in section #. thus, section # shows the experiments we conducted on user task discovery as well as the results we obtained. section # bridges the gap between user task and collective task discovery by introducing the idea of collective tasks, and it introduces a set of four algorithms for nding collective tasks from the set of previously discovered user tasks. we test the quality of all the proposed solutions by comparing them with a common manually built ground truth. to test the strength of the best performing solution for collective task discovery, we apply it to a larger dataset and illustrate some resulting evidence. finally, section # presents our conclusions and indicates some possible future research. streams of microblogs are of great value because of their direct and real time nature. using a purpose built test collection of tweets, we show that recently proposed approaches for semantic linking do not perform well, mainly due to the idiosyncratic nature of microblog posts. microblogs have become an important source of information for the purpose of marketing, intelligence, and reputation management. determining what an individual microblog post is about, however, can be non trivial because of creative language usage, the highly contextualized and informal nature of microblog posts, and the limited length of this form of communication. we propose a solution to the problem of determining what a microblog post is about through semantic linking: we add semantics to posts by automatically identifying concepts that are semantically related to it and generating links to the corresponding wikipedia articles. the identified concepts can subsequently be used for, eg, social media mining, thereby reducing the need for manual inspection and selection. we propose a novel method based on machine learning with a set of innovative features and show that it is able to achieve significant improvements over all other methods, especially in terms of precision. or commercial advantage and that copies bear this notice and the full citation on the rst page. searching and mining microblog streams offers interesting technical challenges, because of the sheer volume of the data, its dynamic nature, the creative language usage, and the length of individual posts. here, it is important to be able to accurately retrieve tweets that are on topic, including all possible naming and other lexical variants. we propose an alternative approach, namely to determine what a microblog post is about by automatically identifying concepts in them. linking free text to knowledge resources, on the other hand, has received an increasing amount of attention in recent years. most, if not all, of the linking methods assume that the input text is relatively clean and grammatically correct and that it provides suf cient context for the purposes of identifying concepts. finally, we examine the relative effectiveness of the precision enhancing step on top of different initial concept ranking methods. in the conclusion to the paper we also discuss ef ciency considerations. our main contributions are: a robust, successful method for linking tweets to wikipedia articles, based on a combination of high recall concept ranking and high precision machine learning, including state of the art machine learning algorithms, insights into the in uence of various features and machine learning algorithms on the task, and a reusable dataset, with which we aim to facilitate follow up research. in section # we discuss related work, followed by a description of our method. in section # we discuss the experimental setup and, in section #, the experiments with which we answer our research questions. in recent years twitter has become one of the largest online microblogging platforms with over unique visitors and around tweets per day microblogging streams have become in http: blog twitter com year# million tweets per day html permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. to copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speci. valuable sources for many kinds of analyses, including online reputation management, news and trend detection, and targeted marketing and customer services. in many microblog search scenarios the goal is to nd out what people are saying about concepts such as products, brands, persons, et cetera. so, it is common to manually construct lengthy keyword queries that capture all possible variants. we take a concept to be any item that has a unique and unambiguous entry in a well known large scale knowledge source, wikipedia. little research exists on understanding and modeling the semantics of individual microblog posts. starting from the domain of named entity recognition, current approaches establish links not just to entity types, but to the actual entities themselves. in stead of merely identifying types, we also aim to disambiguate the found concepts and link them to wikipedia articles. with over million articles, wikipedia has become a rich source of knowledge and a common target for linking; automatic linking approaches using wikipedia have met with considerable success. microblog posts are short, noisy, and full of shorthand and other ungrammatical text and provide very limited context for the words they contain. hence, it is not obvious that automatic con cept detection methods that have been shown to work well on news articles or web pages, perform equally well on microblog posts. we present a robust method for automatically mapping tweets to wikipedia articles to facilitate social media mining on a semantic level. the rst research question we address is: what is the performance of state of the art approaches for linking text to wikipedia in the context of microblog posts our proposed approach involves a two step method for semantic linking. the rst step is recalloriented where the aim is to obtain a ranked list of candidate concepts. in the next step, we enhance precision and determine which of the candidate concepts to keep. our second research question concerns a comparison of methods for the initial concept ranking step; we consider lexical matching, language modeling, and other state of the art baselines and compare their effectiveness. our third tweet concepts is it me or does google instant ads, and, attention, encourage you to pay more at does, google, google tention to their ads and shop instant, is, it, links, me, ping links more, etc. keep your eyes out for an ac, about, actress, an, tress called judi dench. sheand, and, be, called, a promising talent andpre dench, for, hearing, dict we ll be hearing more her, predict, judi about her. table #: example tweets with concepts recognized using lexical matching on wikipedia article titles. research question concerns the second, precision enhancing step. we approach this as a machine learning problem and consider a broad set of features, some of which have been proposed previously in the literature on semantic linking, some newly introduced. in addition to multiple features, we also consider multiple machine learning algorithms and examine which of these are most effective for our problem. the paper focuses on the effectiveness of concept detection methods in the setting of microblog posts. the remainder of this paper is organized as follows. semantic search refers to a loose set of concepts, challenges and techniques having to do with harnessing the information of the growing web of data for web search. here we propose a formal model of one specific semantic search task: ad hoc object retrieval. we show that this task provides a solid framework to study some of the semantic search problems currently tackled by commercial web search engines. we connect this task to the traditional ad hoc document retrieval and discuss appropriate evaluation metrics. finally, we carry out a realistic evaluation of this task in the context of a web search application. in recent years the eld of web search has diversi ed, bringing new challenges beyond the traditional text based search problem studied by information retrieval researchers. among these new paradigms is the eld of semantic search, in which knowledge bases are used as the primary information source for search, or as a complement to text retrieval. the last two years in particular has seen an increase both in the number of knowledge bases published as linked data and in the availability of metadata embedded inside web pages, thanks to the support for metadata standards by major commercial search engines. www year#, april, year#, raleigh, north carolina, usa. the increase of size in the data that is handled rst led to signi cant research on scalable indexing techniques with much input from the database community and at the same time put a focus on the ranking of results. ranking is also motivated by a growing number of end user application scenarios where queries are given by ordinary users as keywords, and not in formal query languages such as sparql. despite the recent surge in semantic search research, there has been little work focusing on principled evaluation techniques for assessing the. components of semantic search technologies, as well as compare one system to another, a common evaluation methodology is needed. to semantic search has also been identi ed by the participants of the semantic search workshop series as one of the major stumbling blocks to future development of this research area. most current approaches to evaluating semantic search systems are adaptations of document evaluation techniques from the information retrieval community. in this setting, semantic search systems ultimately perform document retrieval, and the quality of documents returned is used as a metric of the quality of the entire system. these results make it di cult to interpret how well a semantic search system functions internally. we de ne the ad hoc object retrieval task for evaluating semantic search systems on the web of data. the task is based on answering arbitrary information needs related to particular aspects of objects, expressed in unconstrained natural language and resolved using a collection of structured data. we also explain the problems in mapping the current methodology for ad hoc document retrieval to ad hoc object retrieval. we analyse a real world web query log from a semantic search point of view, and propose a semantic search query classi cation based on this analysis. we propose a methodology for ad hoc semantic search evaluation. along the way, we discuss many of the di cult decisions that need to be made when designing a semantic search evaluation framework and the http: googlewebmastercentral blogspot com year# introducing rich snippets html figure #: overview of the semantic search process. a keyword query is used to identify relevant web objects. relevant objects are ranked, and for each object a set of connected objects is selected as the result. impact those decisions can have on the quality of the evaluation and the reusability of human judgments. we deploy our proposed evaluation methodology on a real world data set and query workload. we show experimentally that our proposal is stable for some popular evaluation metrics, and that it can reliably distinguish among the. background it is common to call any information retrieval system a semantic search system if it performs the matching of queries and potential results at a conceptual level, ie, by processing information beyond the surface forms of symbols. unfortunately, this de nition is hard to operationalize when it comes to semantic search evaluation, because it leaves open the type of queries processed by the system, the format of the content and the internal knowledge representation paradigm applied within the search system. to arrive at a comparable subset of search systems we will have to restrict the above de nition to systems that retrieve data from a knowledge base containing rdf data. rdf is the core part of the semantic web stack and de nes the abstract data model for the semantic web in the form of triples that express the connection between web resources and provide property values describing resources. broadly speaking, the goal of retrieval in this context is to retrieve parts of the knowledge base that best match the query entered by the user. we will use each of these notations in our discussion depending on the context. given the structured nature of the data, semantic search engines also bring new query capabilities to search. in practice, not all features of any structured query language would be equally necessary to perform common tasks. further, we expect that users will be limited by the capabilities of the input interface; in particular, we expect keyword queries to remain the prevalent form of input. to establish a realistic evaluation that covers the most commonly occurring query types, we will perform a study of keyword queries in a web search query log from the perspective of the semantic query functionality required to resolve the query. this will lead us to a simpli ed taxonomy of web queries as well as a measure of the commonality of each type of query, allowing semantic search engines to be evaluated on realistic work loads. relevant objects are ranked based on their content and relationships to other objects. finally, each object is explained by expanding a set of connected objects to provide the nal result. organization the remainder of the paper is organized as follows. in section # we outline the ad hoc object retrieval task and discuss the challenges and choices made in adapting the ad hoc document retrieval task. section # reports on the results of an analysis of a web query log which is then used to conduct an evaluation of a base line object ranking algorithm using our proposed evaluation task. in section # we contrast our approach with related work. we conclude in section # and discuss future work. distribution of these papers is limited to classroom use, and personal use by others. conservative estimates put the amount of structured data on the web at over billion triples today. note that resources in rdf describe objects in a web of data. since the semantic web is built upon such data models, it is also equivalent to think of these objects as semantic web entities. figure # illustrates a generic architecture for semantic search systems that perform object retrieval for keyword queries. in this setting, a keyword query is used to identify relevant web objects occurring in the wod. conventional search engines usually return a ranked list of web pages in response to a query. users have to visit several pages to locate the relevant parts. a promising future search scenario should involve: understanding user intents; providing relevant information directly to satisfy searchers needs, as opposed to relevant pages. in this paper, we present a search paradigm to summarize a query information from different aspects. query aspects could be aligned to user intents. the generated summaries for query aspects are expected to be both specific and informative, so that users can easily and quickly find relevant information. specifically, we use a composite query for summarization method, where a set of component queries are used for providing additional information for the original query. the system leverages the search engine to proactively gather information by submitting multiple component queries according to the original query and its aspects. in this way, we could get more relevant information for each query aspect and roughly classify information. by comparative mining the search results of different component queries, it is able to identify query aspect words, which help to generate more specific and informative summaries. the experimental results on two data sets, wikipedia and trec clueweb, are encouraging. our method outperforms two baseline methods on generating informative summaries. nowadays, accessing information on the internet through search engines has become a fundamental life activity. current web search engines usually provide a ranked list of urls to answer a query. this type of information access does a good job for dealing with simple navigational queries by leading users to speci. however, it is becoming increasingly insu cient for queries with vague or complex information need. many queries serve just as the start of an exploration of related information space. users may want to know about a topic from multiple aspects. organizing the web content relevant to a query according to user intents would bene. in addition, a list of urls couldndirectly satisfy user information need. users have to visit many pages and try to nd relevant parts within long pages, since the information may be scattered across documents. the long standing goal of search engines should be providing relevant information, as opposed to relevant documents, to directly satisfy searchers needs. this paper presents a novel search paradigm that the system should automatically discover information and present an informative overview for a query from multiple aspects. a query represents a centric topic, and the query aspects are aligned to user intents covering diverse information needs. the query aspects could be speci ed explicitly by users through an interface or automatically mined from search logs or other resources. in this paper, we use simple methods to do aspect mining and mainly focus on multi aspect oriented query summarization: given a query and a set of aspects, generate a summary for each query aspect, which is expected to provide speci. and informative content to users directly and helps for further exploration. figure # shows an example of the system output. we further formulate the multi aspect oriented query summarization into phases: information gathering and summary generation. di erent from traditional text summarization where a set of documents to be summarized is given as a system input, we propose a composite query for summarization method, which leverages the search engine to proactively gather related information. in addition to using the search result of the original query, we also composite a set of new queries and submit them to the search engine to figure #: an example output of multi aspect oriented query summarization. for example, by concatenating the original query and the keywords of an aspect as a query, we are able to get query dependent aspect information; by submitting the aspect keywords only as a query, we could get query independent aspect information. our motivations are: first, the search result of the original query may not contain enough information for all aspects that users care about, because the search engine returns documents only considering whether a document is relevant to the query keywords, rather than its aspects. second, for better aspect oriented exploration, the information for di erent query aspects should be as orthogonal as possible. it is important to distinguish the aspect speci. information from the general information about the whole query. by using the composite queries, we could get more speci. the exible information gathering also helps for summary generation phase. by comparing the search results of di erent types of composite queries, query aspect words can be identi ed without complex natural language processing, based on which more speci. and informative summaries could be generated, the contributions of this paper can be summarized as follows: we formulate the multi aspect based query summarization task. in this scenario, the system proactively discovers information and aims to provide multiple dimensional and direct information seeking in response to informational queries. we propose a composite query for summarization method for proactive information gathering, which is a key point for our task and di ers from traditional search result organization and textual summarization. and informative summaries to directly address searchers needs on di erent aspects. to achieve this, we propose a simple method to identify query aspect dependent words by comparing the search results of di erent types of composite queries. we conduct experiments on both real web queries and large scale pseudo queries based on wikipedia. automatic evaluation and human judgements are used for measuring the quality of generated summaries. the rest of the paper is organized as follows. first, we discuss related work in section #. in section #, we de ne the query aspect and brie. in section #, we detail the proposed composite query based method for both information gathering and aspect oriented summary generation. after that, we report our experimental results in section #. online reputation management is about monitoring and handling the public image of entities on the web. an important task in this area is identifying aspects of the entity of interest given a stream of microblog posts referring to the entity. in this paper we compare different ir techniques and opinion target identification methods for automatically identifying aspects and find that simple statistical methods such as tf idf are a strong baseline for the task, significantly outperforming opinion oriented methods, and only considering terms tagged as nouns improves the results for all the methods analyzed. the ability to aggregate huge volumes of queries over a large population of users allows search engines to build precise models for a variety of query assistance features such as query recommendation, correction, etc. yet, no matter how much data is aggregated, the long tail distribution implies that a large fraction of queries are rare. as a result, most query assistance services perform poorly or are not even triggered on long tail queries. we propose a method to extend the reach of query assistance techniques to long tail queries by reasoning about rules between query templates rather than individual query transitions, as currently done in query flow graph models. as a simple example, if we recognize that montezuma is a city in the rare query montezuma surf and if the rule city surf beach has been observed, we are able to offer montezuma beach as a recommendation, even if the two queries were never observed in a same session. we conducted experiments to validate our hypothesis, first via traditional small scale editorial assessments but more interestingly via a novel automated large scale evaluation methodology. our experiments show that general coverage can be relatively increased by using templates without penalizing quality. furthermore, for of the queries in our query flow graph, which have no out edges and thus could not be served recommendations, we can now offer at least one recommendation in of the cases. mining query logs on a large scale has been shown to be tremendously useful for web search and web applications. query logs have been successfully explored for a variety of copyright is held by the international world wide web conference committee. distribution of these papers is limited to classroom use, and personal use by others. purposes such as core ranking, automatic query expansion, web caching, user modeling, matching ads, and more. one of the most direct and visible applications of query log mining is query recommendations in its multiple forms, from dynamic query suggestions as you type to related searches displayed on the search engine results page. yet, in spite of their relative success, all query log based methods exhibit the same weakness: they cease being as useful when reaching the long tail. as a result, methods that operate at the level of individual queries cannot, as of today, handle rare or one time queries and this leads to a signi cant coverage issue on the long tail. one approach could be to simply ignore the long tail and concentrate on serving best head and torso needs. this approach, we believe, would probably be a mistake. indeed, goel et al conducted a thorough analysis of the anatomy of the long tail, and showed that most ordinary people. extraordinary tastes, ie, all of us exhibit a certain level of eccentricity. even more importantly, it turns out that supporting the tail boosts the head by providing users a convenient one stop shop for both their mainstream and niche interests. following this view, we believe that it is critical to appropriately handle long tail queries, especially in the query recommendation family of applications. in this paper, we focus on related query recommendation, one of the tasks for which the long tail issue is the most visible. we propose to address the long tail problem by leveraging query templates, which are query constructs that abstract and generalize queries. our key idea is to identify rules between templates as means for suggesting related queries. the rationale for our approach is based on the fact that many individual queries share the same query intent while focusing on di erent entities. hence, their related queries also share similar structures. as an example, assume that the queries los angeles hotels, new york hotels and paris hotels have been abstracted into the common query template hotels. in addition, if los angeles restaurants is a query recommendation for los angeles hotels and similarly new york restaurants is a recommendation for new york hotels, we can extract the general rule: hotels. restaurants using such a rule, we could then. er for the query yancheng restaurants, the suggested query yancheng hotels even if both are rare queries and had never been observed before. the key challenge in this approach is to ensure that while signi cantly improving coverage for query recommendations, we maintain a certain level of quality in order to satisfy users. we even argue that a small drop in quality would be acceptable as long as the user has enough valid recommendations to select from. ering any suggestion damages the user experience, as lack of coverage remains a signi cant issue: we have observed on a yahoo query log sample that queries, out of, had no consecutive query. thus, in our sample, any query recommendation system that leverages query reformulation would not be able to derive any information for more than of the queries. in this paper we make the following contributions: we introduce the concept of rules between query templates, which can be used to infer recommendations for rare or previously unseen queries. we apply the concept of template rules on the query ow graph. at a high level, the concept is general and can be used to enhance other query log constructs. we explain how to build templates and more speci cally how to extract template rules. note that unlike prior work on templates, which used semi supervision on restricted domains, we can. ord to work at a general, large scale level because we extract rules rather than stand alone templates and ambiguity is therefore automatically reduced. we introduce the query template ow graph as an enrichment of the query ow graph with templates. we then describe how to use the query template ow graph for the task of query recommendation. we provide an experimental evaluation, which shows that using a query template ow graph instead of a query ow graph construct consistently improves the quality of recommendations, especially for long tail queries. we verify our claims using manual evaluation, as well as a novel automated large scale evaluation process over millions of tested recommendations. identifying user tasks from query logs has garnered considerable interest from the research community lately. several approaches have been proposed to extract tasks from search sessions. current approaches segment a user session into disjoint tasks using features extracted from query, session or clicked document text. however, user tasks most often than not are entity centric and text based features will not exploit entities directly for task extraction. in this work, we explore entity specific task extraction from search logs. we evaluate the quality of extracted tasks with session track data. empirical evaluation shows that terms associated with entity oriented tasks can not only be used to predict terms in user sessions but also improve retrieval when used for query expansion. we evaluate the quality of extracted tasks in two ways: query term prediction and query expansion. users constantly interact with search engines to accomplish some tasks such as buy a car, plan a wedding etc. such broad requirements prompts the use of multiple queries, sometimes spanning multiple sessions. approximately of user search sessions involve multi tasking, which makes, task identi cation an important step towards understanding user goals. recent approaches use either search query or clicked documents to identify tasks. most of these approaches cluster queries from current or neighboring sessions into tasks based on lexical or semantic similarity. extracting and mining entity information from queries across users can provide insight into di erent tasks that can be accomplished permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro. or commercial advantage and that copies bear this notice and the full citation on the rst page. copyrights for components of this work owned by others than acm must be honored. to copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speci. however, current approaches do not directly leverage entities for task extraction. they use entity or entity type information as features. they semantically represent a query using features extracted, either from wikipedia or from some knowledge base. these representations do not concretely capture entity speci. for instance, two queries that share same or similar type of entities, may still have diverse concept representation. such queries will not be classi ed as part of the same task. for example, above approaches may not consider buy wedding owers and book wedding destinations to be part of the same task due to the topic drift that destination and ower induce in concept vectors, even though both queries represent the same task wedding planning. whereas the entities in these two queries ower, destination and wedding shall have high co occurrence in search logs. queries, such as these, can be easily mapped to the same task by leveraging their entities. by considering the entities and their associations one can extract better semantics from user queries. existing work extracts tasks from independent sessions, thus providing information only about a single user. such tasks have limited applications as they do not give a complete picture about tasks that exist globally. however, entity oriented tasks can be extracted from search sessions accross several users. such a global set of tasks can bene. for instance, it can be used to nd similar users by mining their task histories or for query suggestions. with this motivation, in this work we explore entity based task extraction from search logs. our system nds entity oriented tasks for each category by populating words that co occur with entities from that category. given a session, we use task terms related to entities in the rst query to predict terms of subsequent queries in the session. we further show that the proposed method can improve retrieval performance when used for query expansion. experiments on session track data indicate that terms associated with entity oriented tasks can not only predict query terms in a session but can also improve retrieval when used for query expansion. a significant portion of web search queries are name entity queries. the major search engines have been exploring various ways to provide better user experiences for name entity queries, such as showing search tasks and showing direct answers. in order to provide the search tasks or direct answers that can satisfy most popular user intents, we need to capture these intents, together with relationships between them. in this paper we propose an approach for building a hierarchical taxonomy of the generic search intents for a class of name entities. the proposed approach can find phrases representing generic intents from user queries, and organize these phrases into a tree, so that phrases indicating equivalent or similar meanings are on the same node, and the parent child relationships of tree nodes represent the relationships between search intents and their sub intents. three different methods are proposed for tree building, which are based on directed maximum spanning tree, hierarchical agglomerative clustering, and pachinko allocation model. our approaches are purely based on search logs, and do not utilize any existing taxonomies such as wikipedia. with the evaluation by human judges, it is shown that our approaches can build trees of phrases that capture the relationships between important search intents. until a few years ago, most major search engines return only ten result snippets to user, and let the user find useful results by reading the snippets. although this has been very successful, it costs much user effort in reading snippets, and it is not always possible for the search engine to accurately capture the userintent when it is not clearly indicated in the query. this problem is more obvious for name entity queries, since different users may search for different aspects of a name entity using the same query, and it is very difficult for the search engine to infer the exact search intent. name entity queries are a most popular type of queries. according to an internal study of microsoft, at least year# of queries submitted to bing search are simply name entities, and copyright is held by the international world wide web conference committee. distribution of these papers is limited to classroom use, and personal use by others. www year#, april year#, year#, raleigh, north carolina, usa. it is reported of queries contain name entities. for simplicity we will use the word entity to refer to name entity. recently there are some new methods used by different search engines to help users find the right information faster and more effectively for entity queries. the first method is to provide relevant search tasks. for example, when the user searches for an entity, bing usually shows several popular tasks for this entity. as shown in figure #, for query bing shows five tasks: songs, tickets, tour, albums, and biography, together with three result snippets for each task. the tasks are all generic ones for a certain class of entities, which are found through mining the search logs. the second method is to show direct answers for what the user might be searching for, which saves the efforts of inspecting result snippets. kosmix and wolframalpha show only such direct answers, while yahoo and google mix such information with regular results. given the query, kosmix shows her biography, similar artists, albums, genres, etc. and yahoo shows her image, videos, official site, songs, and links to albums, lyrics, photos and videos. although these methods bring more convenience to users, there exist two limitations. first, the direct answers only work well for certain classes of entities. for example, for query, yahoo provides no direct answer, while kosmix shows a simple list of direct answers without most popular query intents such as sports, admissions, etc. second, these approaches put the major generic search intents search tasks of bing top part of kosmix result page top part of yahoo result page figure #: the result pages containing search tasks or different aspects of information by bing, kosmix, and yahoo we use to represent a web search query. for a class of entities into a simple flat list. but these intents actually form a taxonomy, as some intents are related and some are subconcepts of others. albums, songs, lyrics, and music videos are all about her music, biography and profile are about information of her life and career, and tours and tickets are about her concerts. showing a flat list of search tasks or direct answers that mix up different aspects of information makes it difficult for users to find what he wants or get an overview of the entity. the purpose of our study is to organize the generic search intents for a class of entities into a taxonomy according to the relationship between different intents. a class of entities is a set of entities that are usually considered to be of the same type, such as musicians, movies, car models, cities, etc. we work on classes of entities instead of individual ones, because the sparseness and noises in the data prevent us from accurately inferring the relationships between intents of different queries involving a single entity. by aggregating data involving many entities we can better capture the relationships between intents. an example taxonomy of major generic search intents for musicians is shown in figure #, which is generated by our approach. our work can help search engines in three ways. first, it can help to organize the search tasks by selecting tasks for representative intents and avoiding redundancy. with the taxonomy of intents we can also easily create a tree of search tasks, so that a user can navigate in the tree to find the right task. second, our work can help to better organize the direct answers, so that their layout is consistent with the taxonomy of user intents. the direct answers can also be organized into a tree according to the taxonomy, whose nodes can be dynamically shown to users when necessary. third, our work can help web developers and users better understand queries containing name entities, and provide an overview of different search intents for a class of entities. outlineandcontributions baezayates et al propose the concept of query relationships, including equivalence, isa, and overlapping relationships. however, only equivalence relationship is studied in, which is also studied in. in this paper we study both equivalence and isa relationships between search intents, and how to build taxonomy of intents based on such relationships. the first challenge is how to identify generic search intents for a class of entities. for each class of entities, we can find the generic search intents from user queries. for example, if many users search for for many different musicians, we can know lyrics is an important search intent for musicians. song, albums song lyrics lyrics for there are usually many users explicitly indicating their search intents in queries, and thus we can capture almost every major generic search intent for a class of entities. we represent such generic intents using words and phrases coappearing with entities in user queries. if a word or phrase coappears with a number of entities in user queries, it usually represents a generic intent, and we call it an intent phrase. the second challenge is how to infer the relationship between two intent phrases. some intent phrases carry the same intent, such as pictures, pics, photos, images in queries for musicians. some intents are subconcepts of some other intents. for example, wallpapers are a type of pictures, and wikipedia is source of biography. we propose a method for inferring the relationship between two intent phrases based on user clicks, which indicate their intents. although it is often difficult to accurately infer the relationship between two queries, there are usually many entities that coappear with two intent phrases in queries, and we can aggregate the relationships between these queries to infer the relationship between the two intent phrases. our experiments show such aggregation improves accuracy significantly. the third challenge is how to organize intent phrases into a tree, so that each node contains intent phrases corresponding to the same intent, and the child nodes of a node correspond to subconcepts of this node. the first algorithm is based on directed maximum spanning tree. the second algorithm is adapted from hierarchical agglomerative clustering. the third algorithm is based on pachinko allocation models for building hierarchical topic models for documents. these algorithms are evaluated with humanlabeled data on ten classes of entities. the rest of this paper is organized as follows. section # presents the problem formulation, and section # describes how to infer the relationships between intent phrases. we present approaches for building intent trees in section #, and empirical study in section #.