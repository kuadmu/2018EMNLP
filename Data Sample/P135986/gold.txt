this work closely relates the following areas of computer architecture research: thread level speculation, dynamic optimization, energy ef cient computation, as well as heterogeneous multicore design. a large body of work has been done as to support tls. relatively little has addressed the energy ef ciency issues of tls execution. packirisamy et al compared and contrasted the energy ef ciency of smt and cmp in terms of supporting tls workload under the same die area constraints. they examined how the interactions between speculative threads affect their energy ef ciency in smt mode and cmp mode execution. renau et al presented various energy saving optimizations for a cmp based tls system. our work differs from that of renau et al in that the energy ef ciency improvement comes from successfully matching speculative threads with computation and caching components on which they are most energy ef cient. it is worth point out that many of the techniques proposed by them are orthogonal and can potentially complement our system to further improve energy ef ciency. managing speculative threads at runtime can reduce the unpredictability introduced by improper decisions made by the compiler when extracting parallel threads. luo et al proposed dynamic tuning mechanisms to enhance tls performance. novel hardware performance counters are introduced to monitor thread execution and enable quantitative evaluation of speculative threads. based on such evaluations, the runtime tuning system can decide how the speculative threads are extracted to improve performance. this work is based on a homogeneous cmp system and does not consider energy consumptions. however, these techniques can potentially be integrated to our heterogeneous system to extract more energy ef cient speculative threads from sequential applications. heterogeneous systems with same isa heterogeneous cores are proposed by kumar et al to improve energy ef ciency for sequential programs and multi programming workloads. our work is different because: we studied speculative threads that have unique sharing and interference patterns; our threads are managed at a much ner granularity level; and thus our runtime system must throttle the invocation of thread management operations; we have shown the bene. of incorporating heterogeneous cache components, which is not considered by kumar et al suleman et al proposed asymmetric chip multiprocessor to speed up lock based critical section execution in openmp applications. our work differs in that our workloads do not have explicit lock based critical sections and the runtime deals resource allocation for all program segments; moreover, we strive to balance performance and energy consumption, measured in energy delaysquared product, which is not considered in their work. yang et al proposed rst level cache designs that can be re sized during program execution. considerate energy delay product reduction has been observed by having the ability of resizing both sets and associativities. our work has shown that in the context of speculative threads that utilize cache ways as write buffers, resizing by sets is always a more energy ef cient choice. a large number of proposals have discussed dynamic tuning for improving energy ef ciency of microprocessors. wu et al presented the runtime optimizer framework that uses dvfs to manage energy performance tradeoffs. this framework is based on dynamic instrumentation: initial test instructions are inserted to hot code regions to collect execution pro le; then mode set reset instructions are inserted at the entry exit of candidate code segments. isci et al collected control ow, performance counters and live power measurement information from running applications, and found that performance counter based method consistently provided better representation of power behaviors. bhattacharjee et al proposed thread criticality predictor and then applied dynamic optimization and dvfs based on the criticality. while dvfs is not evaluated in this paper, it is certainly orthogonal to our approach. as more and more transistors are integrated onto a single die, ef ciently utilizing on chip resource under a certain workload becomes increasingly challenging. the work from studied thread migration for better resource utilization. however, their proposed schemes worked at coarse granularity and may not support speculative threads. our work focused on speculative threads and tackled ne grained thread management overheads. they presented policies for matching core sizes with application characteristics.